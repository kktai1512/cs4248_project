{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train = pd.read_csv('./raw_data/xtrain.csv', names=['Verdict', \"Text\"])\n",
    "X = train['Text']\n",
    "y= train['Verdict']\n",
    "\n",
    "x_train = X\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# You may load the pickle files from a google drive such that you do not need to run the feature engineering from scratch. \n",
    "# Because of the big size of pickle files, we are only demonstrating it using xtrain.csv and balancedtest.csv instead of full train.\n",
    "# You may then put the respective pickle files into the correct directory.\n",
    "\n",
    "\n",
    "\n",
    "train_df = pd.read_pickle(\"./pickles/compiled.pkl\")\n",
    "test_df = pd.read_pickle(\"./pickles/compiled_test.pkl\")\n",
    "train_df = train_df.loc[:,~train_df.columns.duplicated()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_from_df(df, columns):   \n",
    "    features = []\n",
    "    for col in columns:\n",
    "        features.append(list(df[col]))\n",
    "        \n",
    "    return features\n",
    "\n",
    "all_columns = ['sentiment_compound_score',\n",
    "       'number_of_words', 'number_of_characters', 'number_of_sentence',\n",
    "        'DATE',\n",
    "       'LANGUAGE', 'GPE', 'WORK_OF_ART', 'NORP', 'ORDINAL', 'LOC', 'CARDINAL',\n",
    "       'FAC', 'PERCENT', 'LAW', 'QUANTITY', 'EVENT', 'PERSON', 'PRODUCT',\n",
    "       'MONEY', 'ORG', 'TIME', 'total_entities', 'readability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(df_train, df_test, feature_columns_interested, classes_interested, class_weights=None):\n",
    "    df_train = df_train[train_df['Verdict'].isin(classes_interested)]\n",
    "    df_test = df_test[test_df['Verdict'].isin(classes_interested)]\n",
    "\n",
    "    features_train = get_feature_from_df(df_train, feature_columns_interested)\n",
    "    features_train = list(map(list, zip(*features_train)))\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    features_train = scaler.fit_transform(features_train)\n",
    "\n",
    "    X_train = features_train\n",
    "    y_train = df_train['Verdict']\n",
    "\n",
    "    if class_weights is not None:\n",
    "        model = LogisticRegression(class_weight=class_weights)\n",
    "    else:\n",
    "        model = LogisticRegression()\n",
    "        \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # test out\n",
    "    features_test = get_feature_from_df(df_test, feature_columns_interested)\n",
    "    features_test = list(map(list, zip(*features_test)))\n",
    "\n",
    "    features_test = scaler.transform(features_test)\n",
    "    X_test = features_test\n",
    "\n",
    "    y_test = df_test['Verdict']\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Investigating Length Related Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_words\n",
      "          count        mean          std  min     25%    50%      75%      max\n",
      "Verdict                                                                       \n",
      "1        3981.0  293.893243   249.185916  2.0  123.00  166.0   532.00   1255.0\n",
      "2        4014.0  194.705531    78.497109  2.0  147.00  185.0   233.00   1152.0\n",
      "3        4008.0  907.681138  1116.982475  2.0  250.75  682.0  1201.25  20894.0\n",
      "4        3997.0  444.215412   360.012765  3.0  194.00  347.0   616.00   4545.0\n",
      "number_of_characters\n",
      "          count         mean          std   min      25%     50%     75%       max\n",
      "Verdict                                                                           \n",
      "1        3981.0  1769.675961  1506.681982  16.0   737.00   994.0  3193.0    7599.0\n",
      "2        4014.0  1144.731440   458.957049  10.0   862.00  1097.0  1371.0    7418.0\n",
      "3        4008.0  5510.928393  6612.905755  10.0  1524.25  4203.5  7363.5  118990.0\n",
      "4        3997.0  2700.588692  2147.276997  14.0  1210.00  2124.0  3733.0   25820.0\n",
      "number_of_sentence\n",
      "          count       mean        std  min   25%   50%   75%     max\n",
      "Verdict                                                             \n",
      "1        3981.0  13.851545  12.836714  1.0   6.0   7.0  22.0    84.0\n",
      "2        4014.0  11.543597   5.201494  1.0   8.0  11.0  14.0    60.0\n",
      "3        4008.0  47.899451  61.740653  1.0  13.0  34.0  62.0  1241.0\n",
      "4        3997.0  25.121341  22.167463  1.0  10.0  18.0  34.0   333.0\n"
     ]
    }
   ],
   "source": [
    "columns =  [ 'number_of_words', 'number_of_characters', 'number_of_sentence']\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "for column in columns:\n",
    "    print(column)\n",
    "    print(train_df.groupby('Verdict')[column].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can very clearly see that, number of words, and number of characters and number of sentence has is quite distinct for class 3(propaganda) and 4(reliable news) in comparison to the rest. So ideally, if we use these features, we should be able to perform better for than random guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['number_of_words', 'number_of_characters', 'number_of_sentence']\n",
    "features_train = get_feature_from_df(train_df, columns)\n",
    "\n",
    "features_train = list(map(list, zip(*features_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import minmax\n",
    "scaler = MinMaxScaler()\n",
    "features_train = scaler.fit_transform(features_train)\n",
    "\n",
    "X_train = features_train\n",
    "y_train = train_df['Verdict']\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.24      0.07      0.11       750\n",
      "           2       0.19      0.27      0.22       750\n",
      "           3       0.50      0.68      0.58       750\n",
      "           4       0.28      0.24      0.26       750\n",
      "\n",
      "    accuracy                           0.32      3000\n",
      "   macro avg       0.30      0.32      0.29      3000\n",
      "weighted avg       0.30      0.32      0.29      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test out\n",
    "features_test = get_feature_from_df(test_df, columns)\n",
    "features_test = list(map(list, zip(*features_test)))\n",
    "\n",
    "features_test = scaler.transform(features_test)\n",
    "X_test = features_test\n",
    "y_test = test_df['Verdict']\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see clearly that with length related features, class 3 and 4 performs better than random guessing. Now we need to move on and find features that can better differentiate 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Investigating Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_compound_score\n",
      "          count      mean       std     min       25%      50%       75%     max\n",
      "Verdict                                                                         \n",
      "1        3981.0  0.244429  0.775245 -0.9994 -0.655200  0.63110  0.945900  0.9998\n",
      "2        4014.0 -0.177907  0.806081 -0.9989 -0.939500 -0.59455  0.777525  0.9998\n",
      "3        4008.0 -0.078397  0.852430 -1.0000 -0.985125 -0.12800  0.952150  1.0000\n",
      "4        3997.0  0.235083  0.819811 -0.9998 -0.768400  0.70960  0.976900  0.9999\n"
     ]
    }
   ],
   "source": [
    "columns =  ['sentiment_compound_score']\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "for column in columns:\n",
    "    print(column)\n",
    "    print(train_df.groupby('Verdict')[column].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From negatve to positive, we have hoax, propaganda, reliable news and satire. Analyzing it more qualitatively, this makes sense as hoaxes are usualy used to spread fear - which is associated with negativity, and satire uses humour, which may contribute to its higher score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =  ['sentiment_compound_score']\n",
    "features_train = get_feature_from_df(train_df, columns)\n",
    "features_train = list(map(list, zip(*features_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import minmax\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "features_train = scaler.fit_transform(features_train)\n",
    "\n",
    "X_train = features_train\n",
    "y_train = train_df['Verdict']\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.53      0.36       750\n",
      "           2       0.31      0.56      0.40       750\n",
      "           3       0.08      0.01      0.01       750\n",
      "           4       0.23      0.05      0.08       750\n",
      "\n",
      "    accuracy                           0.28      3000\n",
      "   macro avg       0.22      0.28      0.21      3000\n",
      "weighted avg       0.22      0.28      0.21      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test out\n",
    "features_test = get_feature_from_df(test_df, columns)\n",
    "features_test = list(map(list, zip(*features_test)))\n",
    "\n",
    "features_test = scaler.transform(features_test)\n",
    "X_test = features_test\n",
    "y_test = test_df['Verdict']\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, we can see that sentiment analysis is great at differentiating hoaxes(2) and satire(1), which is at the extreme ends of the sentiment analysis scale. We can verify by just training and testing on both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.62      0.61       750\n",
      "           2       0.60      0.58      0.59       750\n",
      "\n",
      "    accuracy                           0.60      1500\n",
      "   macro avg       0.60      0.60      0.60      1500\n",
      "weighted avg       0.60      0.60      0.60      1500\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.52      0.47      0.49       750\n",
      "           4       0.51      0.56      0.53       750\n",
      "\n",
      "    accuracy                           0.51      1500\n",
      "   macro avg       0.51      0.51      0.51      1500\n",
      "weighted avg       0.51      0.51      0.51      1500\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.61      0.57       750\n",
      "           3       0.54      0.47      0.50       750\n",
      "\n",
      "    accuracy                           0.54      1500\n",
      "   macro avg       0.54      0.54      0.54      1500\n",
      "weighted avg       0.54      0.54      0.54      1500\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.57      0.58      0.57       750\n",
      "           4       0.57      0.56      0.57       750\n",
      "\n",
      "    accuracy                           0.57      1500\n",
      "   macro avg       0.57      0.57      0.57      1500\n",
      "weighted avg       0.57      0.57      0.57      1500\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.53      0.52       750\n",
      "           4       0.51      0.49      0.50       750\n",
      "\n",
      "    accuracy                           0.51      1500\n",
      "   macro avg       0.51      0.51      0.51      1500\n",
      "weighted avg       0.51      0.51      0.51      1500\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.55      0.56      0.55       750\n",
      "           3       0.55      0.54      0.54       750\n",
      "\n",
      "    accuracy                           0.55      1500\n",
      "   macro avg       0.55      0.55      0.55      1500\n",
      "weighted avg       0.55      0.55      0.55      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_test(train_df, test_df, ['sentiment_compound_score'], [1,2])\n",
    "train_and_test(train_df, test_df, ['sentiment_compound_score'], [3,4])\n",
    "\n",
    "train_and_test(train_df, test_df, ['sentiment_compound_score'], [1,3])\n",
    "train_and_test(train_df, test_df, ['sentiment_compound_score'], [2,4])\n",
    "\n",
    "train_and_test(train_df, test_df, ['sentiment_compound_score'], [1,4])\n",
    "train_and_test(train_df, test_df, ['sentiment_compound_score'], [2,3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Investigating Readability Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readability\n",
      "          count       mean        std     min    25%     50%    75%     max\n",
      "Verdict                                                                    \n",
      "1        3981.0  55.548111  14.751342  -84.84  47.19  56.390  65.15  102.10\n",
      "2        4014.0  64.723787  11.430079 -227.85  58.72  64.810  72.05   96.18\n",
      "3        4008.0  53.064671  17.277307  -87.11  45.29  54.135  62.48  120.21\n",
      "4        3997.0  55.977611  16.221884 -426.90  47.52  56.390  64.34  111.07\n"
     ]
    }
   ],
   "source": [
    "columns =  ['readability']\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "for column in columns:\n",
    "    print(column)\n",
    "    print(train_df.groupby('Verdict')[column].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that class 2 (hoax) has the highest readability score - which is so that it caters a wider target audience, which a hoax aims to be.\n",
    "Class 3 (propaganda) on the other hand has the lowest readability score - this might be because it often involves a lot of fake technical terms etc and jargon to make it seem more plausible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =  ['readability']\n",
    "features_train = get_feature_from_df(train_df, columns)\n",
    "features_train = list(map(list, zip(*features_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-14 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-14 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-14 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-14 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-14 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-14 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-14 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-14 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-14 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-14 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-14 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-14 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-14 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-14 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-14 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import minmax\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "features_train = scaler.fit_transform(features_train)\n",
    "\n",
    "X_train = features_train\n",
    "y_train = train_df['Verdict']\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       750\n",
      "           2       0.32      0.63      0.43       750\n",
      "           3       0.48      0.73      0.58       750\n",
      "           4       0.29      0.16      0.20       750\n",
      "\n",
      "    accuracy                           0.38      3000\n",
      "   macro avg       0.27      0.38      0.30      3000\n",
      "weighted avg       0.27      0.38      0.30      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# test out\n",
    "features_test = get_feature_from_df(test_df, columns)\n",
    "features_test = list(map(list, zip(*features_test)))\n",
    "\n",
    "features_test = scaler.transform(features_test)\n",
    "X_test = features_test\n",
    "y_test = test_df['Verdict']\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can say that readability score helps in classifying class 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         count       mean        std    min      25%    50%     75%     max\n",
      "Verdict                                                                    \n",
      "1        750.0  61.983013  10.174617  19.24  55.7800  61.92  68.810   89.79\n",
      "2        750.0  63.642413  11.205983   3.40  56.6075  62.83  71.015  102.61\n",
      "3        750.0  49.603013  10.428659  16.59  42.6200  49.65  56.280   74.59\n",
      "4        750.0  60.284520  10.096960  33.28  53.3100  59.96  66.940   98.51\n"
     ]
    }
   ],
   "source": [
    "# distribution of test\n",
    "print(test_df.groupby('Verdict')['readability'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in the test dataset, class 2 and 3 still is the highest and lowest respectively, however class 1 and class 4 has increased quite a lot. Which does not really follow the distribution of the training dataset, hence this feature is only good enough to differentiate 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Investigating Custom Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Initialize a dictionary to hold our class-specific counters\n",
    "class_counters = {class_label: Counter() for class_label in train_df['Verdict'].unique()}\n",
    "\n",
    "# Populate the counters with token counts for each class\n",
    "for index, row in train_df.iterrows():\n",
    "    class_counters[row['Verdict']].update(row['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top 20 tokens for each class\n",
    "top_tokens_per_class = {class_label: counter.most_common(100) for class_label, counter in class_counters.items()}\n",
    "import nltk\n",
    "stop_words_and_punctuation = set(nltk.corpus.stopwords.words('english'))\n",
    "stop_words_and_punctuation.update(string.punctuation)\n",
    "\n",
    "# remove stop words\n",
    "top_tokens_per_class = {class_label: [(token, count) for token, count in top_tokens if token.lower() not in stop_words_and_punctuation] for class_label, top_tokens in top_tokens_per_class.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1:\n",
      "'s: 10050\n",
      "said: 9937\n",
      "n't: 3200\n",
      "time: 3163\n",
      "one: 3054\n",
      "would: 2945\n",
      "like: 2544\n",
      "year: 2022\n",
      "could: 1902\n",
      "even: 1755\n",
      "get: 1701\n",
      "new: 1522\n",
      "added: 1514\n",
      "Monday: 1454\n",
      "people: 1444\n",
      "know: 1413\n",
      "old: 1400\n",
      "nt: 1397\n",
      "really: 1393\n",
      "back: 1376\n",
      "first: 1354\n",
      "\n",
      "\n",
      "Class 3:\n",
      "nt: 10470\n",
      "would: 8852\n",
      "people: 8684\n",
      "one: 7466\n",
      "government: 7409\n",
      "like: 5927\n",
      "US: 5573\n",
      "also: 5242\n",
      "time: 4987\n",
      "even: 4788\n",
      "world: 4523\n",
      "could: 4278\n",
      "said: 4232\n",
      "many: 4155\n",
      "U.S.: 4077\n",
      "years: 3984\n",
      "us: 3920\n",
      "\n",
      "\n",
      "Class 4:\n",
      "'s: 19606\n",
      "said: 15814\n",
      "--: 5511\n",
      "would: 4377\n",
      "year: 3955\n",
      "percent: 3699\n",
      "one: 3499\n",
      "n't: 3245\n",
      "also: 3238\n",
      "two: 3117\n",
      "Taiwan: 2987\n",
      "people: 2898\n",
      "government: 2724\n",
      "first: 2563\n",
      "could: 2325\n",
      "new: 2321\n",
      "time: 2306\n",
      "years: 2255\n",
      "last: 2231\n",
      "China: 2208\n",
      "U.S.: 1992\n",
      "like: 1903\n",
      "million: 1878\n",
      "\n",
      "\n",
      "Class 2:\n",
      "Obama: 4110\n",
      "think: 3601\n",
      "nt: 2817\n",
      "Trump: 2714\n",
      "one: 1706\n",
      "According: 1682\n",
      "would: 1590\n",
      "people: 1575\n",
      "reports: 1495\n",
      "time: 1398\n",
      "President: 1304\n",
      "Clinton: 1289\n",
      "told: 1284\n",
      "also: 1251\n",
      "Hillary: 1235\n",
      "recent: 1215\n",
      "like: 1201\n",
      "country: 1192\n",
      "said: 1191\n",
      "American: 1184\n",
      "us: 1091\n",
      "video: 1061\n",
      "made: 1047\n",
      "support: 982\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the top tokens for each class\n",
    "for class_label, top_tokens in top_tokens_per_class.items():\n",
    "    print(f\"Class {class_label}:\")\n",
    "    for token, count in top_tokens:\n",
    "        print(f\"{token}: {count}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top tokens and put in a list\n",
    "top_tokens = []\n",
    "for class_label, top_tokens_class in top_tokens_per_class.items():\n",
    "    top_tokens.extend([token for token, count in top_tokens_class])\n",
    "\n",
    "# Get the unique tokens\n",
    "top_tokens = set(top_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikitionary - we get lists of words that are quite dramatic in nature, and try to see if we can use it to compare satire/hoax etc \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'comparative_forms.txt': ['wilder', 'touchier', 'weer', 'less', 'number', 'later', 'liver', 'damper', 'greater', 'hinder', 'archer', 'sooner', 'rasher', 'faster', 'worse', 'madder', 'further', 'lither', 'mazier', 'terser', 'higher', 'tamer', 'lighter', 'fresher', 'stranger', 'smaller', 'lesser', 'lamer', 'balder', 'fuller', 'longer', 'abler', 'cheaper', 'bummer', 'flatter', 'closer', 'taller', 'kinder', 'feller', 'bolder', 'liever', 'thinner', 'braver', 'duffer', 'wider', 'cooler', 'younger', 'farther', 'shorter', 'cleaner', 'planer', 'broker', 'camper', 'richer', 'nobler', 'happier', 'quicker', 'lower', 'absenter', 'purer', 'prettier', 'crapper', 'older', 'fancier', 'saucier', 'earlier', 'dafter', 'mangier', 'juster', 'newer', 'dishier', 'simpler', 'shitter', 'profaner', 'stupider', 'louder', 'clearer', 'dimmer', 'gamer', 'fruitier', 'holier', 'badder', 'plumper', 'achier', 'commoner', 'vaster', 'goodlier', 'shyer', 'buffer', 'fader', 'tarrier', 'hotter', 'remoter', 'broader', 'funner', 'furrier', 'littler', 'idler', 'fouler', 'worse-off', 'better-off', 'deader', 'doper', 'gayer', 'riper', 'tenderer', 'shittier', 'tinier', 'weirder', 'sounder', 'warmer', 'hokier', 'sleeker', 'truer', 'sharper', 'vampier', 'woolier', 'slower', 'odder', 'minuter', 'angrier', 'rarer', 'finer', 'defter', 'mirier', 'ruder', 'prompter', 'meaner', 'stouter', 'moister', 'paler', 'whiter', 'slicker', 'plainer', 'keener', 'sadder', 'sorer', 'rounder', 'dotier', 'freer', 'firmer', 'crisper', 'fatter', 'trickier', 'snarkier', 'plusher', 'spinier', 'sticker', 'sicker', 'slier', 'shier', 'blither', 'wealthier', 'steeper', 'tougher', 'starker', 'peppier', 'soother', 'woollier', 'stiffer', 'tarter', 'gentler', 'pleasanter', 'stronger', 'chiller', 'blearier', 'craftier', 'denser', 'dowdier', 'livelier', 'blinder', 'bluer', 'pinker', 'rustier', 'blacker', 'purpler', 'grayer', 'sicklier', 'duller', 'unlikelier', 'bragger', 'naughtier', 'loftier', 'cleverer', 'realer', 'fiercer', 'surer', 'mankier', 'funnier', 'sunnier', 'gummier', 'bonier', 'noisier', 'luckier', 'phonier', 'viler', 'bronzer', 'kindlier', 'gaunter', 'gladder', 'apter', 'iller', 'weaker', 'wronger', 'blander', 'redder', 'looser', 'stonier', 'beautifuller', 'sloppier', 'friendlier', 'tinnier', 'busier', 'sorrier', 'blanker', 'riskier', 'wordier', 'barer', 'sleepier', 'waterier', 'frumpier', 'crappier', 'needier', 'rainier', 'pettier', 'girlier', 'likelier', 'straighter', 'hoarier', 'wackier', 'trendier', 'hairier', 'drier', 'healthier', 'headier', 'hastier', 'heartier', 'better_off', 'sweatier', 'barrener', 'handsomer', 'profounder', 'ruddier', 'swifter', 'smoother', 'coarser', 'seamier', 'crueler', 'shadier', 'dirtier', 'subtler', 'cheesier', 'meatier', 'snappier', 'tidier', 'phatter', 'hunkier', 'chicer', 'leakier', 'truthier', 'bouncier', 'creakier', 'savvier', 'doner', 'pulpier', 'iffier', 'gooder', 'tetchier', 'emptier', 'grittier', 'oilier', 'politer', 'cosier', 'clumsier', 'direr', 'eerier', 'leaner', 'acerber', 'abrupter', 'hungrier', 'hipper', 'bitterer', 'wearier', 'absurder', 'acrider', 'acuter', 'adepter', 'aerier', 'airier', 'adroiter', 'abstruser', 'huger', 'whinier', 'scarier', 'bustier', 'sturdier', 'saltier', 'kinkier', 'zanier', 'thirstier', 'feebler', 'randier', 'righter', 'meeker', 'pottier', 'stormier', 'lonelier', 'baggier', 'crasser', 'dodgier', 'bossier', 'brasher', 'bubblier', 'ebber', 'daintier', 'blunter', 'beakier', 'beerier', 'bilgier', 'blockier', 'bendier', 'brattier', 'brassier', 'brawnier', 'bronzier', 'brownier', 'chalkier', 'choosier', 'saintlier', 'saner', 'crankier', 'crispier', 'witchier', 'bulkier', 'burlier', 'crunchier', 'auntlier', 'danker', 'dewier', 'dizzier', 'dozier', 'drabber', 'dreamier', 'drearier', 'duskier', 'dustier', 'balkier', 'balmier', 'bawdier', 'bittier', 'blottier', 'boozier', 'botchier', 'boxier', 'braggier', 'boskier', 'brashier', 'brinier', 'brittler', 'broodier', 'brusker', 'brusquer', 'bulgier', 'chancier', 'chattier', 'chillier', 'choppier', 'comfier', 'costlier', 'cruder', 'crueller', 'crumblier', 'cuddlier', 'cagier', 'curlier', 'adverser', 'arider', 'artier', 'ashier', 'auguster', 'dickier', 'doughtier', 'doughier', 'dressier', 'dumpier', 'fattier', 'earthier', 'nuder', 'perkier', 'filmier', 'neater', 'closer-knit', 'stockier', 'coyer', 'uncannier', 'floppier', 'pissier', 'infirmer', 'shorter-term', 'wimpier', 'meeter', 'pithier', 'charrier', 'rawer', 'sourer', 'cozier', 'suppler', 'pricklier', 'posher', 'punier', 'stingier', 'frailer', 'nimbler', 'pickier', 'foxier', 'darker', 'gushier', 'gauzier', 'jammier', 'handier', 'wittier', 'lacier', 'waxier', 'yummier', 'rockier', 'frequenter', 'hillier', 'tauter', 'juicier', 'lordlier', 'squarer', 'devouter', 'mistier', 'mellower', 'mealier', 'muggier', 'mintier', 'dinkier', 'unfairer', 'unworthier', 'milkier', 'grislier', 'awesomer', 'poppier', 'queerer', 'lewer', 'rattier', 'fuglier', 'surlier', 'tipsier', 'thornier', 'tawnier', 'slimmer', 'shabbier', 'trashier', 'thriftier', 'shakier', 'sillier', 'skinnier', 'scarcer', 'worldlier', 'wintrier', 'wryer', 'wirier', 'wigglier', 'wifelier', 'wanner', 'princelier', 'throatier', 'shapelier', 'showier', 'sneakier', 'weepier', 'weightier', 'wobblier', 'wavier', 'wrier', 'whackier', 'perter', 'pokier', 'nerdier', 'vainer', 'unsounder', 'hookier', 'hippier', 'readier', 'scanter', 'pudgier', 'unsightlier', 'curter', 'dearer', 'verier', 'lankier', 'sootier', 'faultier', 'fussier', 'lanker', 'fustier', 'screechier', 'messier', 'fleeter', 'friskier', 'grainier', 'greasier', 'glitzier', 'fleshier', 'laxer', 'featherier', 'foolhardier', 'frizzier', 'ghostlier', 'perfecter', 'snarlier', 'unwarier', 'snakier', 'kitschier', 'artsier', 'awarer', 'tardier', 'dorkier', 'lumpier', 'tenser', 'testier', 'tireder', 'trustier', 'ghastlier', 'gorier', 'grungier', 'lengthier', 'liefer', 'obliquer', 'nosier', 'pitifuller', 'puttier', 'sager', 'raunchier', 'rangier', 'rapider', 'gloopier', 'easier', 'heavenlier', 'resoluter', 'limper', 'ornerier', 'opaquer', 'dungier', 'droller', 'pointier', 'dutchier', 'ganglier', 'gaudier', 'patchier', 'paltrier', 'gimpier', 'swisher', 'irater', 'innocenter', 'ickier', 'nicer', 'torchier', 'angstier', 'jitterier', 'snippier', 'timelier', 'jaggeder', 'meagrer', 'meagerer', 'jokier', 'smugger', 'suckier', 'doabler', 'tackier', 'soupier', 'shaggier', 'shriller', 'horsier', 'spindlier', 'sugarier', 'slyer', 'sprier', 'shitier', 'stinkier', 'wacker', 'staler', 'onionier', 'swankier', 'slipperier', 'robuster', 'kewler', 'dumptier', 'sprightlier', 'grodier', 'naifer', 'benigner', 'grottier', 'wussier', 'unfussier', 'crabbier', 'smarmier', 'intelligenter', 'urbaner', 'triter', 'stabler', 'wonkier', 'stumpier', 'poxier', 'jigglier', 'cakier', 'moodier', 'snazzier', 'soppier', 'spongier', 'statelier', 'eggier', 'soggier', 'suaver', 'swarthier', 'pinier', 'unhappier', 'cobwebbier', 'nobbier', 'gobbier', 'finnier', 'ditzier', 'unclearer', 'spammier', 'breadier', 'moldier', 'drippier', 'vapider', 'unluckier', 'downier', 'kitscher', 'vaguer', 'violeter', 'oozier', 'hinkier', 'crotchetier', 'clingier', 'gappier', 'skankier', 'peachier', 'stubborner', 'wishy-washier', 'dweebier', 'whizzier', 'orangier', 'floatier', 'rubblier', 'mushier', 'stompier', 'nearer', 'correcter', 'securer', 'spacier', 'brighter', 'deeper', 'poufier', 'cuter', 'tonier', 'crosser', 'goopier', 'weller', 'vulgarer', 'auntienter', 'driftier', 'outermore', 'grumpier', 'naïver', 'widdler', 'powerfuller', 'bashfuller', 'harmfuller', 'peacefuller', 'boofier', 'wiser', 'wonderfuller', 'joyfuller', 'dopier', 'oulder', 'schlubbier', 'vinier', 'fronter', 'doomier', 'moonier', 'bolshier', 'svelter', 'wiggier', 'choicer', 'cuntier', 'screamier', 'treaclier', 'wheatier', 'coalier', 'squooshier', 'crowdier', 'poutier', 'peatier', 'mumsier', 'wankier', 'drizzlier', 'grummer', 'sluggisher', 'hackier', 'clayier', 'crazier', 'gunkier', 'punkier', 'gungier', 'dimplier', 'smexier', 'colder', 'dolefuler', 'snider', 'larger', 'briefer', 'logier', 'evener', 'antsier', 'punnier', 'throbbier', 'quieter', 'meltier', 'strengthier', 'uncouther', 'shrimpier', 'bangier', 'sweller', 'hattier', 'heavier', 'bizarrer', 'greeker', 'greener', 'flatter-chested', 'bitier', 'whippier', 'joltier', 'sluttier', 'modester', 'staider', 'smarter', 'earnester', 'better-hung', 'eviller', 'in_shorter_order', 'lother', 'winninger', 'ropier', 'curmudgeonlier', 'drunker', 'leveler', 'steamier', 'sagier', 'pacier', 'janglier', 'jimper', 'goatier', 'wetter', 'mopier', 'souther', 'compacter', 'fairer', 'druggier', 'lardier', 'thicker', 'currenter', 'superber', 'furder', 'heathier', 'yiffier', 'widelier', 'raggeder', 'positiver', 'foolisher', 'doggier', 'draggier', 'ditsier', 'loungier', 'starier', 'sweeter', 'clangier', 'franker', 'rulier', 'graver', 'cruisier', 'sedater', 'yarer', 'screwier', 'user-friendlier', 'boggier', 'baser', 'beamier', 'pebblier', 'stricter', 'poorer', 'softer', 'rowdier', 'diddier', 'shoutier', 'flowier', 'gleamier', 'narrower', 'bullier', 'twattier', 'surfier', 'chaster', 'beggarlier', 'loamier', 'chumpier', 'ricketier', 'calmer', 'mundaner', 'slurrier', 'withier', 'maidlier', 'ruggeder', 'musclier', 'flutier', 'unriper', 'jowlier', 'fidgetier', 'uncommoner', 'solider', 'sinnier', 'grapier', 'shrubbier', 'horrider', 'scareder', 'humpier', 'pornier', 'paintier', 'lealer', 'clumpier', 'treblier', 'hurtier', 'eviler', 'toeyer', 'advantageouser', 'ambitiouser', 'figgier', 'terribler', 'uselesser', 'darklier', 'deeplier', 'preciser', 'accurater', 'feater', 'nastier', 'squintier', 'deffer', 'peakier', 'cuspier', 'better-known', 'wieldier', 'campier', 'techier', 'directer', 'uniformer', 'jauntier', 'mighter', 'fabbier', 'better-looking', 'rosier', 'cannier', 'niffier', 'fainter', 'sandier', 'supremer', 'windier', 'foggier', 'mothier', 'humbler', 'fonder', 'violenter', 'drossier', 'stodgier', 'flashier', 'wilier', 'chewier', 'uglier', 'rottener', 'grander', 'tighter', 'timider', 'greedier', 'stiller', 'ballsier', 'kookier', 'kludgier', 'pussier', 'yellower', 'sexier', 'widerspread', 'lousier', 'gloomier', 'miserabler', 'dangerouser', 'gloriouser', 'anxiouser', 'comfortabler', 'cautiouser', 'specificker', 'seriouser', 'gossipier', 'grimmer', 'quicker-and-dirtier', 'bluffer', 'greyer', 'blonder', 'mustier', 'grimier', 'nycer', 'grippier', 'twinklier', 'gaspier', 'teensier', 'loonier', 'shinier', 'frownier', 'bloodier', 'merrier', 'mingier', 'drowsier', 'grumblier', 'girthier', 'sudsier', 'sedgier', 'boomier', 'cloudier', 'droopier', 'mardier', 'unhandsomer', 'fickler', 'flappier', 'hazier', 'swottier', 'unstabler', 'uncleaner', 'unsafer', 'skinter', 'raggier', 'icier', 'unevener', 'tranquiler', 'sallower', 'huskier', 'barkier', 'lustier', 'cranker', 'cheerfuller', 'conciser', 'drabbier', 'gradelier', 'unsteadier', 'charier', 'nigher', 'forwarder', 'chubbier', 'lairier', 'backer', 'sleekier', 'huffier', 'shirtier', 'toeier', 'antienter', 'whorier', 'qualmier', 'spryer', 'speedier', 'gladlier', 'darlinger', 'hollower', 'tiddlier', \"drier_than_a_dead_dingo's_donger\", 'classier', 'lovelier', 'chippier', 'maltier', 'sheenier', 'wholesomer', 'nervier', 'spicier', 'snowier', 'gassier', 'runnier', 'roomier', 'pluckier', 'trimmer', 'crustier', 'dusker', 'frattier', 'skunkier', 'skeezier', 'shiftier', 'browner', 'groovier', 'zazzier', 'fleshlier', 'worthier', 'hornier', 'sterner', 'dumber', 'edgier', 'rougher', 'prouder', 'dicier', 'plummier', 'fishier', 'homier', 'completer', 'nitpickier', 'siltier', 'inkier', 'unhealthier', 'higher-risk', 'seedier', 'nubbier', 'guiltier', 'astuter', 'higher-quality', 'loudlier', 'quietlier', 'derpier', 'yolkier', 'froggier', 'shellier', 'smearier', 'dashier', 'oranger', 'ailer', 'fartier', 'puggier', 'stuffier', 'fuzzier', 'sublimer', 'sawcier', 'fluffier', 'slurpier', 'learier', 'dumber_than_a_bag_of_hammers', 'sulkier', 'sparer', 'craggier', 'absoluter', 'worse_off', 'creepier', 'curiouser', 'curvier', 'mightier', 'tastier', 'racier', 'shrewder', 'ampler', 'fleecier', 'sleigher', 'stauncher', 'warier', 'blurrier', 'brisker', 'bushier', 'barmier', 'battier', 'beadier', 'beechier', 'bitchier', 'bloomier', 'blowzier', 'beachier', 'beefier', 'blesseder', 'airworthier', 'blowsier', 'blousier', 'brickier', 'brothier', 'buggier', 'butterier', 'cheerier', 'chirpier', 'spendier', 'bramblier', 'branchier', 'broomier', 'burblier', 'cattier', 'chunkier', 'cornier', 'crummier', 'cushier', 'agiler', 'ancienter', 'austerer', 'awkwarder', 'comelier', 'awfuller', 'deafer', 'dottier', 'dingier', 'faddier', 'falser', 'fiddlier', 'fierier', 'grosser', 'hardier', 'filthier', 'flabbier', 'fizzier', 'bonnier', 'murkier', 'sprucer', 'tangier', 'naggier', 'banaler', 'smoggier', 'steadfaster', 'ranker', 'kittler', 'wifier', 'pricier', 'peskier', 'shallower', 'folksier', 'gnarlier', 'abjecter', 'gustier', 'grimlier', 'womanlier', 'gabbier', 'grouchier', 'gawkier', 'haughtier', 'slippier', 'junkier', 'jumpier', 'gooier', 'kinglier', 'knottier', 'intenser', 'milder', 'sassier', 'lusher', 'jazzier', 'poofier', 'puffier', 'nappier', 'folkier', 'unwiser', 'unfriendlier', 'unkinder', 'jollier', 'jerkier', 'maturer', 'manlier', 'marshier', 'measlier', 'quainter', 'queasier', 'weaklier', 'geekier', 'squeakier', 'flouncier', 'yeastier', 'laggier', 'possibler', 'yuckier', 'tinglier', 'teenier', 'serener', 'scuzzier', 'woodier', 'wheezier', 'weedier', 'wrigglier', 'woodsier', 'scrummier', 'leafier', 'scraggier', 'skimpier', 'sleazier', 'sleetier', 'wickeder', 'wispier', 'wrinklier', 'plushier', 'kickier', 'nuttier', 'niftier', 'homelier', 'nattier', 'hoarser', 'cutesier', 'crumbier', 'capabler', 'mirthfuller', 'playfuller', 'hopefuller', 'betterer', 'extremer', 'bleaker', 'crashier', 'rifer', 'ritzier', 'slighter', 'heftier', 'slimier', 'stagier', 'splashier', 'squirrellier', 'starchier', 'fremder', 'knobbier', 'spiffier', 'callower', 'podgier', 'smurfier', 'feistier', 'fearfuller', 'mousier', 'foamier', 'glummer', 'finickier', 'forlorner', 'flintier', 'flimsier', 'flakier', 'funkier', 'flourier', 'frothier', 'flowerier', 'freakier', 'giddier', 'gruffer', 'stroppier', 'stretchier', 'unruliest', 'leggier', 'oakier', 'steadier', 'honester', 'knobblier', 'tearier', 'tweedier', 'frostier', 'gamier', 'glossier', 'goofier', 'grubbier', 'loopier', 'tawdrier', 'toastier', 'frillier', 'frowzier', 'gluier', 'gristlier', 'groggier', 'gutsier', 'itchier', 'leerier', 'obscurer', 'pitchier', 'catchier', 'obscener', 'glassier', 'brainier', 'snugger', 'primmer', 'breathier', 'brushier', 'dandier', 'squiffier', 'clattier', 'raspier', 'fubsier', 'buxomer', 'bleepier', 'obtuser', 'muddier', 'plottier', 'pastier', 'paunchier', 'pimplier', 'punchier', 'portlier', 'muckier', 'grassier', 'grizzlier', 'glibber', 'godlier', 'gruesomer', 'tartier', 'snugglier', 'flightier', 'porkier', 'daggier', 'unsurer', 'nobblier', 'serer', 'silverier', 'trippier', 'smokier', 'soberer', 'jinglier', 'sultrier', 'junglier', 'sportier', 'chavvier', 'yellowier', 'sarkier', 'sparser', 'slenderer', 'slittier', 'quaggier', 'quakier', 'clankier', 'jankier', 'snobbier', 'massier', 'steelier', 'frowsier', 'lowlier', 'christmassier', 'lazier', 'lewder', 'scantier', 'flippier', 'blobbier', 'sniffier', 'corkier', 'hammier', 'spunkier', 'scalier', 'stringier', 'stubbier', 'swampier', 'faggier', 'knaggier', 'claggier', 'lippier', 'shoppier', 'naffer', 'zestier', 'yukkier', 'squelchier', 'unholier', 'untidier', 'unwieldier', 'mouldier', 'huggier', 'itsier', 'zingier', 'cruftier', 'grabbier', 'growlier', 'noteworthier', 'squigglier', 'splodgier', 'raggedier', 'squickier', 'chestier', 'rubberier', 'clickier', 'flickier', 'swishier', 'peepier', 'mouthier', 'snoutier', 'studlier', 'weaselier', 'wretcheder', 'glitchier', 'gloppier', 'sparklier', 'righter_than_rain', 'menschier', 'talkier', 'snoozier', 'syrupier', 'squawkier', 'chintzier', 'frizzlier', 'pallier', 'flossier', 'wafflier', 'quartzier', 'cheatier', 'whirlier', 'swirlier', 'buzzier', 'flirtier', 'googlier', 'flukier', 'pubbier', 'frecklier', 'newsier', 'spoonier', 'germier', 'scribblier', 'lulzier', 'glitterier', 'fudgier', 'parkier', 'heapier', 'fringier', 'threadier', 'marlier', 'twitchier', 'sappier', 'winier', 'smoochier', 'fraidier', 'yachtier', 'cruddier', 'zappier', 'stolider', 'seemlier', 'unseemlier', 'plaguier', 'scungier', 'jaggier', 'zoomier', 'unfunnier', 'crackier', 'flamier', 'slovenlier', 'shorter-lived', 'uneasier', 'sloshier', 'crêpier', 'wrathier', 'poncier', 'poddier', 'trampier', 'strappier', 'writ_larger', 'blabbier', 'stoopider', 'skeevier', 'yelpier', 'kvetchier', 'somberer', 'beardier', 'leatherier', 'waggier', 'hoppier', 'unmanlier', 'spoofier', 'burstier', 'yappier', 'better-built', 'knurlier', 'loathlier', 'sincerer', 'wartier', 'webbier', 'gigglier', 'stalkier', 'scurvier', 'stickier', 'bumpier', 'deadlier', 'discreeter', 'klutzier', 'breezier', 'muskier', 'zittier', 'hissier', 'harder-won', 'shoddier', 'pawkier', 'snootier', 'properer', 'smallerscale', 'nebbier', 'blingier', 'bristlier', 'bloodthirstier', 'baulkier', 'blotchier', 'blowier', 'cockier', 'clammier', 'draughtier', 'swearier', 'clunkier', 'jinkier', 'snottier', 'snatchier', 'bookier', 'cunninger', 'snaggier', 'foofier', 'priestlier', 'pongier', 'whiffier', 'tubbier', 'starrier', 'mossier', 'quirkier', 'stealthier', 'nippier', 'reedier', 'toothier', 'scrawnier', 'scummier', 'scruffier', 'showerier', 'slinkier', 'scratchier', 'winterier', 'slushier', 'scrappier', 'scrubbier', 'silkier', 'slangier', 'shadowier', 'wormier', 'woozier', 'hyer', 'pearlier', 'boy_crazier', 'ignoranter', 'boppier', 'spottier', 'praiseworthier', 'squirmier', 'skiddier', 'smuttier', 'slummier', 'unrulier', 'twiggier', 'daffier', 'piggier', 'privater', 'loster', 'smellier', 'preppier', 'prissier', 'stragglier', 'pushier', 'squishier', 'spookier', 'shonkier', 'sheerer', 'sketchier', 'swanker', 'soapier', 'schmalzier', 'springier', 'splotchier', 'scabbier', 'sullener', 'snoopier', 'slobbier', 'streakier', 'saggier', 'smudgier', 'spikier', 'squashier', 'stubblier', 'stripier', 'cheekier', 'prosier', 'tattier', 'rattlier', 'smirkier', 'schlumpier', 'preachier', 'bluesier', 'riffier', 'pinkier', 'spanglier', 'phlegmier', 'twistier', 'sneezier', 'outdoorsier', 'schmaltzier', 'sludgier', 'tricksier', 'smilier', 'dastardlier', 'queenlier', 'squattier', 'piddlier', 'beautifuler', 'twirlier', 'sheepier', 'ploppier', 'ungainlier', 'purdier', 'slabbier', 'washier', 'unreadier', 'untruer', 'untimelier', 'thankfuller', 'charminger', 'snittier', 'schlockier', 'slouchier', 'sissier', 'arranter', 'sightlier', 'lossier', 'meowier', 'prankier', 'chinnier', 'shiverier', 'pepperier', 'spinnier', 'squallier', 'uncomelier', 'gracefuller', 'bountifuller', 'fruitfuller', 'gratefuller', 'hatefuller', 'healthfuller', 'plentifuller', 'blissfuller', 'helpfuller', 'painfuller', 'mournfuller', 'higher-resolution', 'goutier', 'neighborlier', 'bleedier', 'cleanlier', 'snufflier', 'yakkier', 'handsier', 'horribler', 'viciouser', 'flaccider', 'narkier', 'squidgier', 'girl_crazier', 'hubbier', 'bitsier', 'longer-haired', 'straiter', 'boldlier', 'codgier', 'wibblier', 'shriekier', 'slaggier', 'zeitgeistier', 'sookier', 'sparkier', 'nellier', 'speckier', 'kissier', 'gruntier', 'pervier', 'crinklier', 'deathlier', 'bosomier', 'rummier', 'skippier', 'modisher', 'knightlier', 'cowardlier', 'beastlier', 'billowier', 'bunchier', 'chummier', 'brawlier', 'squeezier', 'lissomer', 'pillier', 'schmoozier', 'alonelier', 'crampier', 'mixeder', 'veinier', 'gainfuller', 'notchier', 'purtier', 'buffier', 'wristier', 'wooder', 'harder_put', 'long,_long_lost', 'willowier', 'zippier', 'ungodlier', 'yawnier', 'yechier', 'uppitier', 'scattier', 'clubbier', 'crunker', 'neutron-richer', 'courtlier', 'creamier', 'topsy-turvier', 'impurer', 'unlovelier', 'cracklier', 'uncleanlier', 'unkindlier', 'velvetier', 'delightfuller', 'dutifuller', 'frightfuller', 'doubtfuller', 'clashier', 'churchlier', 'solemner', 'distincter', 'genteeler', 'lonesomer', 'crookeder', 'eagerer', 'chaffier', 'douchier', 'bullshittier', 'purplier', 'bleachier', 'newer-fangled', 'droughtier', 'nubblier', 'moanier', 'pappier', 'posier', 'bigger-dicked', 'shtickier', 'slatier', 'swarter', 'ticklier', 'tuskier', 'oatier', 'severer', 'slopier', 'tosher', 'toshier', 'oomphier', 'ruffer', 'thrashier', 'unsexier', 'brightlier', 'softlier', 'plainlier', 'sweetlier', 'closelier', 'faintlier', 'strikter', 'elder', 'sadlier', 'worser', 'zooier', 'torquier', 'dryer', 'fallow-deer', 'fitter', 'frontier', 'haler', 'prower', 'wusser', 'willinger', 'weenier', 'poorlier', 'bigger', 'neapier', 'quackier', 'better', 'splendider', 'townier', 'excellenter', 'droolier', 'frowstier', 'scurfier', 'rimier', 'unworldlier', 'breastier', 'better_for_you', 'wolfier', 'stedfaster', 'squealier', 'stenchier', 'draftier', 'eliter', 'beiger', 'benter', 'mauver', 'fleeker', 'blippier', 'lambier', 'snortier', 'bester', 'stabbier', \"'appier\", 'leveller', 'limberer', 'dancier', 'titchier', 'str8er', 'demurer', 'dictier', 'panickier', 'slantier', 'curseder', 'succincter', 'savager', 'scragglier', 'seasicker', 'shalier', 'slaphappier', 'slimpsier', 'slitherier', 'slobberier', 'slumpier', 'snailier', 'sneerier', 'pinchier', 'sordider', 'spitefuller', 'spivvier', 'splurgier', 'sprauncier', 'sprawlier', 'spritelier', 'squalider', 'earthlier', 'jemmier', 'impoliter', 'toolsier', 'jivier', 'nakeder', 'savorier', 'savourier', 'scroungier', 'scrunchier', 'dykier', 'vastier', 'queefier', 'wantoner', 'weensier', 'wersher', 'winsomer', 'woodener', 'inaner', 'inepter', 'unfitter', 'unjuster', 'unquieter', 'naiver', 'nutsier', 'vivider', 'gnashier', 'frigider', 'wilfuller', 'powerfuler', 'plentifuler', 'lovinger', 'crooker', 'gladsomer', 'gemmier', 'ghostier', 'globbier', 'pallider', 'patienter', 'perverser', 'placider', 'plonkier', 'poachier', 'prickier', 'puddlier', 'lefter', 'rabider', 'garlickier', 'grotesquer', 'queenier', 'ignobler', 'immenser', 'laughier', 'lemonier', 'mixier', 'jettier', 'knowinger', 'knucklier', 'rheumier', 'slapstickier', 'unearthlier', 'twin_peaksier', 'uptighter', 'tanner', 'insaner', 'livider', 'longer-term', 'unmadder', 'worse-tempered', 'drouthier', 'humaner', 'unhandier', 'headachier', 'hedgier', 'hulkier', 'lucider', 'limbier', 'lurider', 'faggotier', 'cantier', 'candider', 'carefuller', 'certainer', 'chirker', 'chirkier', 'wagglier', 'waspier', 'waspier', 'whitier', 'woefuller', 'woofier', 'humider', 'rougher_around_the_edges', 'fendier', 'fervider', 'fitlier', 'debbier', 'dismaler', 'dismaller', 'dociler', 'doggeder', 'dolefuller', 'drawlier', 'dreggier', 'dribblier', 'faster-acting', 'slower-acting', 'bandier', 'better-informed', 'wider-spread', 'blusterier', 'worthlesser', 'buirdlier', 'sacreder', 'clerklier', 'cliquier', 'complexer', 'croakier', 'danglier', 'dapperer', 'noblier', 'dippier', 'drearer', 'neatlier', 'cackier', 'fulsomer', 'dronier', 'duckier', 'eelier', 'rickettier', 'ridgier', 'rigider', 'roilier', 'rootsier', 'rufflier', 'rumblier', 'larkier', 'faintier', 'fernier', 'butcher', 'flauntier', 'steepier', 'stillier', 'harder', 'gainlier', 'swingier', 'muzzier', 'pursier', 'racketier', 'shinglier', 'tinklier', 'safer', 'fragiler', 'chertier', 'cloggier', 'cliffier', 'contenter', 'fayrer', 'spumier', 'rummer', 'aulder', 'atterier', 'mirkier', 'seaworthier', 'shmaltzier', 'twiddlier', 'tremblier', 'teentsier', 'tanglier', 'soakier', 'longer-lasting', 'adultier', 'gasser', 'wyder', 'better-timed', 'headlier', 'fuggier', 'bunnier', 'moderner', 'englisher', 'britisher', 'frencher', 'foodier', 'runtier', 'goonier', 'toploftier', 'torrider', 'tranquiller', 'wofuller', 'feyer', 'thrillier', 'thymier', 'choicier', 'bogger', 'complicateder', 'peacefuler', 'damneder', 'fuckeder', 'dunnier', 'nettier', 'nesher', 'cuuuter', 'golder', 'churchier', 'jealouser', 'harder-earned', 'selfisher', 'gezelliger', 'gezelligst', 'fearfuler', 'lintier', 'loyaller', 'loyaler', 'quarer', 'nounier', 'liker', 'pizazzier', 'pizzazzier', 'quippier', 'diviner', 'onerier', 'lakier', 'wedgier', 'thoughtier', 'swacker', 'trustworthier', 'cloddier', 'cluckier', 'troutier', 'wheelier', 'turfier', 'twangier', 'toffier', 'taggier', 'better-behaved', 'peerier', 'shorter-haul', 'restfuller', 'rookier', 'rortier', 'rushier', 'coilier', 'gentlier', 'uppermore', 'unthriftier', 'fouser', 'weakier', 'subtiler', 'summerier', 'prophaner', 'moroser', 'benar', 'gimmickier', 'growthier', 'hootier', 'higher_functioning', 'higher-functioning', 'further-flung', 'further_flung', 'farther_flung', 'farther-flung', 'slashier', 'easier_than_falling_off_a_log', 'owlier', 'highest-resolution', 'stemmier', 'revvier', 'trappier', 'tuftier', 'typier', 'alerter', 'bassier', 'pouchier', 'lower-resolution', 'lowest-resolution', 'unpleasanter', 'tankier', 'goldener', 'chokier', 'couthier', 'cowier', 'coxier', 'crawlier', 'creekier', 'chiefer', 'fraughter', 'tunier', 'nookier', 'swalier', 'swannier', 'hashier', 'scowlier', 'pouffier', 'spazzier', 'welcomer', 'dourer', 'fewer_and_farther_between', 'fewer_and_further_between'], 'modal_adverbs.txt': ['truly', 'surely', 'certainly', 'most_certainly', 'assuredly', 'definitely', 'incontestably', 'undoubtably', 'unquestionably', 'doubtlessly', 'doubtless', 'ineluctably', 'inescapably', 'manifestly', 'transparently', 'necessarily', 'obviously', 'patently', 'plainly', 'unarguably', 'indisputably', 'verifiably', 'unavoidably', 'undeniably', 'undoubtedly', 'apparently', 'evidently', 'presumably', 'presumptively', 'seemingly', 'arguably', 'defensibly', 'defendably', 'likely', 'probably', 'conceivably', 'possibly', 'maybe', 'perhaps', 'allegedly', 'reportedly', 'purportedly', 'putatively', 'reputedly', 'hypothetically', 'conditionally', 'debatably', 'plausibly', 'believably', 'credibly', 'rumoredly', 'rumouredly', 'statistically', 'impossibly', 'inevitably', 'evitably', 'at_first_blush', 'unnecessarily', 'needlessly', 'positively', 'indeed', 'in_fact', 'in_point_of_fact', 'ipof', 'noticeably', 'actually', 'scarcely', 'observably', 'without_a_doubt', 'all_else_being_equal', 'as_a_matter_of_fact', 'at_first_glance', 'literally', 'all_in_all', 'ostensively', 'ostensibly', 'more_and_more', 'indubitably', 'at_first_sight', 'really', 'totally', 'sure', 'technically', 'loosely', 'in_essence', 'essentially', 'at_bottom', 'unfortunately', 'afaik', 'without_doubt', 'all_things_considered', 'fortunately', 'clearly', 'strictly'], 'act_adverbs.txt': ['accidentally', 'carefully', 'carelessly', 'cleverly', 'considerately', 'delicately', 'discreetly', 'foolishly', 'freely', 'immaturely', 'maturely', 'inconsiderately', 'peculiarly', 'unfreely', 'deliberately'], 'manner_adverbs.txt': ['accidentally', 'carefully', 'carelessly', 'cleverly', 'embarrassingly', 'considerately', 'delicately', 'discreetly', 'foolishly', 'freely', 'immaturely', 'maturely', 'inconsiderately', 'habitually', 'customarily', 'hard', 'alarmingly', 'plausibly', 'frankly', 'unbelievably', 'incredibly', 'positively', 'profoundly', 'noticeably', 'remarkably', 'honestly', 'horribly', 'truthfully', 'strikingly', 'suspiciously', 'seriously', 'briefly', 'summarily', 'exactly', 'precisely', 'purely', 'especially', 'economically', 'observably', 'accordingly', 'likewise', 'similarly', 'finally', 'otherwise', 'thus', 'well', 'chronologically', 'alphabetically', 'lexicographically', 'lexically', 'absent-mindedly', 'preoccupiedly', 'anyhow', 'anyway', 'like_the_clappers', 'differently', 'ostensively', 'disorganizedly', 'disorganisedly', 'more_and_more', 'staggeringly', 'acoustically', 'unwaveringly', 'consistently', 'hideously', 'slightly', 'cartographically', 'overweeningly', 'figuratively', 'whoopingly', 'accessorially', 'sufficiently', 'like_fun', 'abortively', 'ironically', 'casuistically', 'quite', 'boxily', 'waxily', 'hawkishly', 'tenably', 'dominantly', 'dolorously', 'doubtingly', 'mordantly', 'scarily', 'importantly', 'with_knobs_on', 'transitorily', 'procedurally', 'ratelessly', 'jingoistically', 'unmanly', 'metaphorically', 'equiprimordially', 'combinably', 'seasonably', 'panegyrically', 'serviceably', 'unrelatedly', 'vicariously', 'epidemically', 'epizootically', 'might_and_main', 'herostratically', 'peculiarly', 'terminally', 'centrally', 'nonstandardly', 'ruthfully', 'understandably', 'deservedly', 'solecistically', 'arse_about_face', 'pleasantly', 'flatling', 'palinspastically', 'yogically', 'visigothically', 'zoomorphically', 'unfreely', 'clearly', 'equally', 'completely', 'deliberately', 'well-behavedly', 'incidentally', 'simply'], 'superlative_forms.txt': ['best', 'least', 'worst', 'dearest', 'greatest', 'baddest', 'finest', 'nicest', 'closest', 'weest', 'outermost', 'farthest', 'fittest', 'strongest', 'widest', 'noblest', 'happiest', 'furthest', 'most_certainly', 'purest', 'highest', 'brightest', 'oldest', 'sexiest', 'newest', 'gayest', 'dishiest', 'dirtiest', 'earliest', 'youngest', 'chiefest', 'foggiest', 'holiest', 'heaviest', 'creamiest', 'tallest', 'bravest', 'fastest', 'best-off', 'hindmost', 'boggiest', 'firmest', 'deadliest', 'bluest', 'humblest', 'skeeziest', 'easiest', 'worstest', 'ablest', 'barest', 'choicest', 'warmest', 'moistest', 'snidest', 'truest', 'merest', 'worsest', 'saddest', 'poorest', 'sorest', 'surest', 'kindest', 'clearest', 'bitterest', 'strictest', 'snarkiest', 'stupidest', 'logiest', 'remotest', 'longest', 'shiest', 'grandest', 'boldest', 'greenest', 'smartest', 'tightest', 'timidest', 'woolliest', 'freest', 'commonest', 'handsomest', 'loftiest', 'roundest', 'thickest', 'softest', 'thinnest', 'blackest', 'liveliest', 'wiliest', 'grimiest', 'trickiest', 'severest', 'oddest', 'damnedest', 'gentlest', 'nebbiest', 'tiniest', 'mardiest', 'droopiest', 'busiest', 'muskiest', 'gauntest', 'chariest', 'leanest', 'kindliest', 'mightest', 'wealthiest', 'exactest', 'likest', 'calmest', 'awesomest', 'stoniest', 'hollowest', 'cruelest', 'blankest', 'dourest', 'frumpiest', 'rainiest', 'girliest', 'wackiest', 'cleanest', 'likeliest', 'heartiest', 'pleasantest', 'steadiest', 'horniest', 'mildest', 'dumbest', 'profoundest', 'cleverest', 'swiftest', 'ruddiest', 'rudest', 'minutest', 'diciest', 'hardest-won', 'dampest', 'seamiest', 'cheesiest', 'campest', 'highest-risk', 'tidiest', 'chicest', 'truthiest', 'goodest', 'grittiest', 'tetchiest', 'oiliest', 'achiest', 'eeriest', 'clumsiest', 'direst', 'absurdest', 'absolutest', 'airiest', 'weariest', 'acridest', 'adeptest', 'aeriest', 'sparest', 'sanest', 'curiousest', 'forwardmost', 'creepiest', 'hugest', 'sickest', 'sincerest', 'thirstiest', 'soundest', 'rightest', 'shrewdest', 'amplest', 'cloudiest', 'soonest', 'loneliest', 'murkiest', 'daintiest', 'divinest', 'aptest', 'bluntest', 'shallowest', 'burliest', 'oftenest', 'ebbest', 'dodgiest', 'balmiest', 'barmiest', 'beastliest', 'blessedest', 'bloomiest', 'booziest', 'bronziest', 'brusquest', 'coarsest', 'crispest', 'bristliest', 'brashest', 'bulkiest', 'crumbliest', 'crunchiest', 'cuddliest', 'curtest', 'cagiest', 'adversest', 'archest', 'aridest', 'auntliest', 'austerest', 'awfullest', 'awkwardest', 'daftest', 'dickiest', 'dingiest', 'dizziest', 'dottiest', 'doughtiest', 'doughiest', 'drabbest', 'dreariest', 'dressiest', 'dumpiest', 'dustiest', 'feeblest', 'fiddliest', 'earthiest', 'baulkiest', 'beefiest', 'bilgiest', 'bitchiest', 'blandest', 'bruskest', 'choppiest', 'cosiest', 'perkiest', 'crudest', 'cushiest', 'agilest', 'dewiest', 'doziest', 'dreamiest', 'duskiest', 'falsest', 'neatest', 'scaliest', 'scantest', 'closest-knit', 'uncanniest', 'stockiest', 'wrongest', 'squiffiest', 'punkest', 'wimpiest', 'banalest', 'rawest', 'sluttiest', 'prickliest', 'foxiest', 'filthiest', 'flattest', 'pickiest', 'palest', 'puniest', 'grouchiest', 'jammiest', 'handiest', 'shyest', 'laciest', 'waxiest', 'yummiest', 'knottiest', 'foofiest', 'juiciest', 'sassiest', 'lushest', 'steamiest', 'devoutest', 'unwisest', 'unfairest', 'mistiest', 'mealiest', 'milkiest', 'maturest', 'muggiest', 'worst_off', 'dinkiest', 'gamest', 'nippiest', 'queerest', 'laggiest', 'yeastiest', 'tipsiest', 'toothiest', 'thriftiest', 'teeniest', 'double-plus_good', '++ungood', 'throatiest', 'leafiest', 'shabbiest', 'squeakiest', 'surliest', 'tingliest', 'thorniest', 'shapeliest', 'skimpiest', 'sleetiest', 'sneakiest', 'worldliest', 'wintriest', 'wriest', 'wiriest', 'plumpest', 'plushiest', 'nattiest', 'niftiest', 'slushiest', 'darkest', 'shakiest', 'slangiest', 'weightiest', 'wormiest', 'wryest', 'whackiest', 'wiggliest', 'wannest', 'nudest', 'nerdiest', 'homeliest', 'unsoundest', 'ungodliest', 'hookiest', 'readiest', 'latest', 'splashiest', 'hautest', 'ruliest', 'biggest', 'firstmost', 'feistiest', 'grainiest', 'flouriest', 'mousiest', 'fellest', 'floweriest', 'foamiest', 'forlornest', 'featheriest', 'filmiest', 'flushest', 'fruitiest', 'sagest', 'ghostliest', 'stroppiest', 'leggiest', 'slummiest', 'ginchiest', 'kitschiest', 'tautest', 'tiredest', 'gluiest', 'gooiest', 'gutsiest', 'leeriest', 'loopiest', 'tensest', 'testiest', 'tangiest', 'tardiest', 'teariest', 'toastiest', 'dorkiest', 'frowziest', 'ghastliest', 'kookiest', 'lithest', 'smallest', 'oftest', 'cheapest', 'vastest', 'fubsiest', 'raunchiest', 'idlest', 'wariest', 'rapidest', 'opaquest', 'obscenest', 'orneriest', 'dungiest', 'prissiest', 'dutchiest', 'portliest', 'paltriest', 'gimpiest', 'pastiest', 'paunchiest', 'muckiest', 'gaudiest', 'cutest', 'snuggliest', 'angstiest', 'meagerest', 'coziest', 'rummest', 'tannest', 'squishiest', 'lowest', 'shitiest', 'serest', 'shrillest', 'spindliest', 'swankest', 'trippiest', 'nighest', 'soupiest', 'sheerest', 'silveriest', 'yellowiest', 'slenderest', 'stalest', 'dumptiest', 'supplest', 'sugariest', 'sultriest', 'grodiest', 'wussiest', 'naifest', 'pissiest', 'snobbiest', 'smarmiest', 'jankiest', 'massiest', 'unfussiest', 'crabbiest', 'tarriest', 'buffest', 'tritest', 'laxest', 'limpest', 'poxiest', 'cakiest', 'drollest', 'stringiest', 'sturdiest', 'subtlest', 'swarthiest', 'saggiest', 'faggiest', 'poppiest', 'lippiest', 'nobbiest', 'soppiest', 'spikiest', 'swampiest', 'cheekiest', 'foulest', 'eggiest', 'dryest', 'finniest', 'ditziest', 'squelchiest', 'unclearest', 'unholiest', 'moldiest', 'mouldiest', 'spammiest', 'drippiest', 'downiest', 'ooziest', 'swishest', 'unlikeliest', 'miriest', 'squiggliest', 'violetest', 'tattiest', 'hinkiest', 'kitschest', 'planest', 'primmest', 'splodgiest', 'gappiest', 'peachiest', 'stubbornest', 'wishy-washiest', 'dopest', 'squickiest', 'dweebiest', 'screamingest', 'mushiest', 'clickiest', 'flickiest', 'charmest', 'correctest', 'spaciest', 'nearest', 'slightest', 'abjectest', 'toniest', 'deepest', 'sweetest', 'eldest', 'broadest', 'fairest', 'extremest', 'auntientest', 'wretchedest', 'driftiest', 'foolishest', 'levelest', 'grumpiest', 'syrupiest', 'widdlest', 'dopiest', 'chintziest', 'ouldest', 'frontest', 'doomiest', 'cheatiest', 'buzziest', 'treacliest', 'googliest', 'flukiest', 'crowdiest', 'wankiest', 'newsiest', 'mumsiest', 'drizzliest', 'fullest', 'darlingest', 'lulziest', 'glitteriest', 'gungiest', 'dotiest', 'limiest', 'smexiest', 'dimpliest', 'coldest', 'heapiest', 'dolefulest', 'fringiest', 'gladdest', 'jaggedest', 'punniest', 'marliest', 'snellest', 'quietest', 'goutiest', 'palmiest', 'uncouthest', 'shrimpiest', 'largest', 'hardest', 'bangiest', 'slaggiest', 'ungainliest', 'greekest', 'directest', 'illest', 'flattest-chested', 'scaredest', 'bitiest', 'whippiest', 'goldiest', 'honestest', 'staidest', 'best-hung', 'evillest', 'purdiest', 'nycest', 'fanciest', 'lothest', 'lardiest', 'fumiest', 'cleanliest', 'paciest', 'drunkest', 'sagiest', 'bizarrest', 'jangliest', 'jimpest', 'mopiest', 'goodliest', 'wonderfullest', 'flamiest', 'lamest', 'wisest', 'completest', 'weakest', 'currentest', 'druggiest', 'veriest', 'cowiest', 'awfulest', 'ignorantest', 'swellest', 'cunningest', 'onliest', 'uneasiest', 'whoriest', 'wideliest', 'arrantest', 'sovereignest', 'raggedest', 'famousest', 'wrathiest', 'draggiest', 'notablest', 'prankiest', 'doggiest', 'ditsiest', 'poddiest', 'loungiest', '++good', 'double_plus_good', 'double_plus_ungood', 'mainest', 'positivest', 'briefest', 'trampiest', 'tamest', 'hottest', 'fightingest', 'cruisiest', 'narkiest', 'yarest', 'tenderest', 'kvetchiest', 'quickest', 'user-friendliest', 'somberest', 'beardiest', 'deadest', 'richest', 'loveliest', 'ugliest', 'chastest', 'worthiest', 'freshest', 'angriest', 'maddest', 'fattest', 'slowest', 'funniest', 'diddiest', 'hokiest', 'flowiest', 'shiftiest', 'sleekest', 'evenest', 'expertest', 'brownest', 'steadfastest', 'wooliest', 'liefest', 'best-built', 'yappiest', 'surfiest', 'loamiest', 'fabbest', 'fadest', 'abstractest', 'mundanest', 'maidliest', 'flutiest', 'jowliest', 'freakiest', 'fidgetiest', 'shittest', 'wartiest', 'fakest', 'solidest', 'rarest', 'webbiest', 'giggliest', 'securest', 'antiquest', 'prettiest', 'woodest', 'feyest', 'humpiest', 'porniest', 'fliest', 'lealest', 'hurtiest', 'evilest', 'benmost', 'figgiest', 'deepliest', 'longest-haired', 'lostest', 'naïvest', 'featest', 'squintiest', 'hissiest', 'codgiest', 'campiest', 'meanest', 'seasonabliest', 'faithiest', 'faintest', 'mutest', 'steeziest', 'cuspiest', 'blingiest', 'sweariest', 'zeitgeistiest', 'bookiest', 'tortest', 'eeliest', 'handsiest', 'best-looking', 'strangest', 'keenest', 'niffiest', 'harshest', 'pongiest', 'hungriest', 'supremest', 'sandiest', 'safest', 'winningest', 'grievousest', 'flashiest', 'spiniest', 'sliest', 'rottenest', 'friendliest', 'fiercest', 'coolest', 'toughest', 'greediest', 'simplest', 'properest', 'precisest', 'piggiest', 'soothest', 'privatest', 'stiffest', 'kludgiest', 'yellowest', 'bleariest', 'lousiest', 'lightest', 'urbanest', 'gloomiest', 'whitest', 'modestest', 'dowdiest', 'blossomiest', 'noirest', 'quickest-and-dirtiest', 'gossipiest', 'greyest', 'grayest', 'sickliest', 'mustiest', 'stickiest', 'grimmest', 'vaguest', 'bumpiest', 'narrowest', 'unkindest', 'teensiest', 'shiniest', 'pinkiest', 'grippiest', 'bloodiest', 'frowniest', 'juniorest', 'seniorest', 'mingiest', 'sunniest', 'drowsiest', 'bulliest', 'girthiest', 'boomiest', 'smiliest', 'sudsiest', 'scariest', 'grumbliest', 'powerfullest', 'ficklest', 'gummiest', 'crinkliest', 'flappiest', 'breeziest', 'iciest', 'luckiest', 'faustiest', 'unevenest', 'uncleanest', 'velvetiest', 'thankfullest', 'washiest', 'haziest', 'uniformest', 'unsafest', 'unstablest', 'tranquilest', 'boniest', 'phoniest', 'barkiest', 'concisest', 'sharpest', 'compactest', 'drabbiest', 'snittiest', 'gradeliest', 'vilest', 'quippiest', 'rashest', 'chubbiest', 'bosomiest', 'sissiest', 'extreamest', 'huffiest', 'lossiest', 'reddest', 'wellest', 'qualmiest', 'spryest', 'driest', 'crossest', 'trickest', 'skillfulest', 'gloriousest', 'tinniest', 'dullest', 'jumpiest', 'sheeniest', 'wholesomest', 'mightiest', 'tersest', 'sleighest', 'sensiblest', 'chirkest', 'riskiest', 'ripest', 'oldermost', 'wateriest', 'sleepiest', 'healthfullest', 'neediest', 'nerviest', 'spiciest', 'snowiest', 'crappiest', 'gassiest', 'furthermost', 'stillest', 'straightest', 'sorriest', 'furriest', 'hoariest', 'hairiest', 'screwiest', 'plushest', 'healthiest', 'headiest', 'hastiest', 'touchiest', 'crustiest', 'murkest', 'jazziest', 'duskest', 'greasiest', 'bleakest', 'wildest', 'weirdest', 'barrenest', 'gravest', 'grooviest', 'fleshliest', 'jauntiest', 'plainest', 'sternest', 'grossest', 'edgiest', 'roughest', 'basest', 'fondest', 'fishiest', 'craziest', 'cowardliest', 'littlest', 'nitpickiest', 'inkiest', 'unhealthiest', 'meatiest', 'seediest', 'phattest', 'hunkiest', 'derpiest', 'guiltiest', 'pitchiest', 'meerest', 'leakiest', 'bounciest', 'pappiest', 'savviest', 'loudliest', 'unfortunatest', 'iffiest', 'froggiest', 'emptiest', 'most_dread', 'eathest', 'litest', 'ailest', 'fartiest', 'miserablest', 'nastiest', 'smoothest', 'politest', 'stuffiest', 'patientest', 'dreadest', 'fuzziest', 'orangest', 'silentest', 'sublimest', 'butchest', 'reefest', 'notchiest', 'purtiest', 'carefullest', 'obliquest', 'happeningest', 'fluffiest', 'gratefullest', 'slurpiest', 'chaffiest', 'fabbiest', 'wristiest', 'moaniest', 'abruptest', 'sulkiest', 'abstrusest', 'craggiest', 'acutest', 'adroitest', 'hippest', 'brainiest', 'silliest', 'slackest', 'canniest', 'proudest', 'curviest', 'whiniest', 'zaniest', 'naughtiest', 'tastiest', 'chewiest', 'dimmest', 'merriest', 'looniest', 'randiest', 'justest', 'meekest', 'steepest', 'pottiest', 'starkest', 'baggiest', 'baldest', 'stormiest', 'wittiest', 'windiest', 'fleeciest', 'blindest', 'frankest', 'staunchest', 'most_widespread', 'blurriest', 'bossiest', 'briskest', 'bonniest', 'bubbliest', 'balkiest', 'beachiest', 'beeriest', 'blockiest', 'bendiest', 'blotchiest', 'blowsiest', 'bluffest', 'bushiest', 'bustiest', 'battiest', 'bawdiest', 'beadiest', 'beechiest', 'bittiest', 'blithest', 'airworthiest', 'blottiest', 'blowziest', 'blowiest', 'botchiest', 'braggest', 'branchiest', 'boskiest', 'brattiest', 'brassiest', 'brawniest', 'briniest', 'bulgiest', 'bummest', 'cattiest', 'chalkiest', 'chattiest', 'cheeriest', 'chirpiest', 'chunkiest', 'boxiest', 'braggiest', 'brambliest', 'brashiest', 'brawliest', 'breathiest', 'brittlest', 'broodiest', 'brothiest', 'browniest', 'brushiest', 'burbliest', 'chanciest', 'chilliest', 'choosiest', 'chummiest', 'costliest', 'creakiest', 'crispiest', 'dandiest', 'clammiest', 'cockiest', 'classiest', 'comeliest', 'comfiest', 'corniest', 'courtliest', 'crankiest', 'cruellest', 'crummiest', 'curliest', 'ancientest', 'artiest', 'ashiest', 'dankest', 'deftest', 'faddiest', 'deafest', 'densest', 'draughtiest', 'fattiest', 'fieriest', 'mangiest', 'hardiest', 'scabbiest', 'sauciest', 'sallowest', 'bitchinest', 'snottiest', 'sprucest', 'coyest', 'floppiest', 'pithiest', 'smoggiest', 'sourest', 'rankest', 'kittlest', 'yiffiest', 'nimblest', 'peskiest', 'priciest', 'poshest', 'priestliest', 'stingiest', 'modishest', 'gnarliest', 'folksiest', 'frailest', 'unsightliest', 'trimmest', 'shortest', 'grimliest', 'womanliest', 'gushiest', 'gabbiest', 'gawkiest', 'gauziest', 'haughtiest', 'junkiest', 'rockiest', 'hilliest', 'snootiest', 'kingliest', 'kinkiest', 'lordliest', 'shittiest', 'poofiest', 'puffiest', 'nappiest', 'folkiest', 'backest', 'squarest', 'unfriendliest', 'tubbiest', 'frequentest', 'jolliest', 'starriest', 'manliest', 'mossiest', 'mintiest', 'jerkiest', 'marshiest', 'measliest', 'quirkiest', 'grisliest', 'wettest', 'quaintest', 'queasiest', 'weakliest', 'realest', 'reediest', 'rattiest', 'geekiest', 'snatchiest', 'flounciest', 'trashiest', 'yuckiest', 'corruptest', 'tawniest', 'scummiest', 'scrappiest', 'scrubbiest', 'silkiest', 'showiest', 'skinniest', 'sleaziest', 'scarcest', 'serenest', 'scuzziest', 'shadowiest', 'showeriest', 'zippiest', 'weepiest', 'woodiest', 'wobbliest', 'wheeziest', 'wickedest', 'wriggliest', 'woodsiest', 'pertest', 'scrawniest', 'plummiest', 'scraggiest', 'scruffiest', 'slickest', 'slinkiest', 'waviest', 'willowiest', 'wooziest', 'winteriest', 'wispiest', 'weediest', 'wifeliest', 'wrinkliest', 'pokiest', 'pearliest', 'kickiest', 'nuttiest', 'hoarsest', 'cutesiest', 'crumbiest', 'capablest', 'outmost', 'stickest', 'earnestest', 'absentest', 'vainest', 'darkliest', 'huskiest', 'loudest', 'peppiest', 'boppiest', 'craftiest', 'hippiest', 'rifest', 'numbest', 'pinkest', 'blondest', 'rustiest', 'slimiest', 'heftiest', 'scurviest', 'intensest', 'mankiest', 'pudgiest', 'noisiest', 'lustiest', 'squidgiest', 'stagiest', 'spottiest', 'squirrelliest', 'squirmiest', 'starchiest', 'crassest', 'smuggest', 'pussiest', 'speediest', 'lankiest', 'lankest', 'spiffiest', 'knobbiest', 'callowest', 'halest', 'sootiest', 'screechiest', 'podgiest', 'smurfiest', 'fussiest', 'sloppiest', 'faultiest', 'fearfullest', 'messiest', 'fleetest', 'glitziest', 'glummest', 'finickiest', 'flimsiest', 'flintiest', 'fustiest', 'fleshiest', 'funkiest', 'flakiest', 'frothiest', 'flabbiest', 'foolhardiest', 'giddiest', 'friskiest', 'frizziest', 'gruffest', 'wordiest', 'trendiest', 'pettiest', 'runniest', 'pluckiest', 'gustiest', 'skiddiest', 'smuttiest', 'snakiest', 'snarliest', 'unwariest', 'oakiest', 'artsiest', 'knobbliest', 'fizziest', 'daffiest', 'frostiest', 'glossiest', 'goofiest', 'groggiest', 'grungiest', 'itchiest', 'lengthiest', 'lumpiest', 'trustiest', 'twiggiest', 'frilliest', 'goriest', 'gristliest', 'grubbiest', 'loosest', 'rosiest', 'siltiest', 'shadiest', 'rowdiest', 'shoddiest', 'seemliest', 'snappiest', 'catchiest', 'saltiest', 'smeariest', 'acerbest', 'glassiest', 'nosiest', 'raciest', 'spookiest', 'witchiest', 'beakiest', 'spendiest', 'saintliest', 'augustest', 'antsiest', 'scattiest', 'naggiest', 'raspiest', 'snaggiest', 'rangiest', 'gloopiest', 'buxomest', 'heavenliest', 'slippiest', 'obtusest', 'obscurest', 'muddiest', 'smelliest', 'yawniest', 'plottiest', 'pimpliest', 'pointiest', 'punchiest', 'puttiest', 'patchiest', 'grassiest', 'gangliest', 'godliest', 'grizzliest', 'glibbest', 'gruesomest', 'ritziest', 'uppitiest', 'ickiest', 'iratest', 'snippiest', 'tartest', 'timeliest', 'tartiest', 'jitteriest', 'flightiest', 'meagrest', 'porkiest', 'jokiest', 'daggiest', 'pushiest', 'unsurest', 'tackiest', 'shonkiest', 'tawdriest', 'shaggiest', 'smokiest', 'sweatiest', 'soberest', 'jungliest', 'jingliest', 'sketchiest', 'swankiest', 'soapiest', 'sportiest', 'horsiest', 'slyest', 'slimmest', 'cruftiest', 'slipperiest', 'spriest', 'stinkiest', 'chavviest', 'sarkiest', 'robustest', 'sparsest', 'kewlest', 'slittiest', 'quaggiest', 'quakiest', 'benignest', 'sprightliest', 'grottiest', 'springiest', 'steeliest', 'frowsiest', 'sullenest', 'snoopiest', 'lowliest', 'laziest', 'christmassiest', 'lewdest', 'wonkiest', 'stumpiest', 'scantiest', 'blobbiest', 'flippiest', 'slobbiest', 'jiggliest', 'infirmest', 'corkiest', 'sniffiest', 'hammiest', 'moodiest', 'stodgiest', 'smudgiest', 'snazziest', 'spongiest', 'squashiest', 'snuggest', 'soggiest', 'spunkiest', 'stateliest', 'stubbliest', 'streakiest', 'posiest', 'stubbiest', 'suavest', 'stripiest', 'piniest', 'unhappiest', 'clubbiest', 'shoppiest', 'naffest', 'knaggiest', 'prosiest', 'gobbiest', 'zestiest', 'yukkiest', 'untidiest', 'huggiest', 'itsiest', 'zingiest', 'rattliest', 'vapidest', 'smirkiest', 'unluckiest', 'crotchetiest', 'grabbiest', 'growliest', 'noteworthiest', 'pulpiest', 'schlockiest', 'preachiest', 'raggediest', 'chestiest', 'bluesiest', 'riffiest', 'rubbliest', 'orangiest', 'floatiest', 'stompiest', 'swishiest', 'peepiest', 'vulgarest', 'mouthiest', 'snoutiest', 'studliest', 'goopiest', 'weaseliest', 'gloppiest', 'glitchiest', 'talkiest', 'twistiest', 'vampiest', 'icklest', 'sneeziest', 'schlubbiest', 'frizzliest', 'palliest', 'crackliest', 'flossiest', 'mooniest', 'viniest', 'pooiest', 'waffliest', 'cuntiest', 'screamiest', 'swirliest', 'whirliest', 'sludgiest', 'flirtiest', 'charriest', 'coaliest', 'poutiest', 'peatiest', 'tricksiest', 'freckliest', 'sluggishest', 'hackiest', 'clayiest', 'prowest', 'crunkest', 'unsexiest', 'dastardliest', 'thrashiest', 'scribbliest', 'gunkiest', 'punkiest', 'fudgiest', 'homiest', 'parkiest', 'fugliest', 'maltiest', 'threadiest', 'profanest', 'meltiest', 'twirliest', 'sheepiest', 'twitchiest', 'sappiest', 'winiest', 'hattiest', 'smoochiest', 'ploppiest', 'fraidiest', 'yachtiest', 'maziest', 'colliest', 'joltiest', 'sveltest', 'flippest', 'cruddiest', 'zappiest', 'triggest', 'in_shortest_order', 'loathest', 'unseemliest', 'ropiest', 'jaggiest', 'goatiest', 'ruttiest', 'zoomiest', 'unfunniest', 'crackiest', 'lewest', 'shortest-lived', 'slouchiest', 'superbest', 'grummest', 'heathiest', 'sloshiest', 'sightliest', 'ponciest', 'writ_largest', 'blabbiest', 'stoopidest', 'sombrest', 'beamiest', 'leatheriest', 'pebbliest', 'waggiest', 'hoppiest', 'unmanliest', 'squalliest', 'gleamiest', 'twattiest', 'beggarliest', 'guttiest', 'knurliest', 'ricketiest', 'loathiest', 'withiest', 'ruggedest', 'loathliest', 'muscliest', 'deffest', 'stablest', 'unripest', 'kissiest', 'gauchest', 'unhandsomest', 'double-plus_ungood', 'stoutest', 'grapiest', 'shrubbiest', 'horridest', 'stalkiest', 'tweediest', 'paintiest', 'pitifullest', 'clumpiest', 'discreetest', 'klutziest', 'roomiest', 'best_off', 'peakiest', 'best-known', 'niggardliest', 'wieldiest', 'carelessest', 'techiest', 'pawkiest', 'mauvest', 'astutest', 'downest', 'buggiest', 'butteriest', 'brickiest', 'jinkiest', 'jasest', 'purplest', 'chumpiest', 'whiffiest', 'impurest', 'mellowest', 'fremdest', 'mothiest', 'randomest', 'possiblest', 'utterest', 'scrummiest', 'scratchiest', 'princeliest', 'jettest', 'boy_craziest', 'breadiest', 'praiseworthiest', 'stretchiest', 'awarest', 'gamiest', 'promptest', 'clattiest', 'resolutest', 'bleepiest', 'preppiest', 'straggliest', 'nobbliest', 'suckiest', 'onioniest', 'splotchiest', 'claggiest', 'skankiest', 'clingiest', 'schlumpiest', 'rubberiest', 'stealthiest', 'twinkliest', 'poufiest', 'spangliest', 'phlegmiest', 'perviest', 'snooziest', 'sparkliest', 'torchiest', 'squawkiest', 'boofiest', 'outdoorsiest', 'schmaltziest', 'quartziest', 'wheatiest', 'squooshiest', 'pubbiest', 'queenliest', 'sedgiest', 'piddliest', 'squattiest', 'strengthiest', 'stolidest', 'curmudgeonliest', 'plaguiest', 'zittiest', 'scungiest', 'slabbiest', 'raggiest', 'swottiest', 'uncleanliest', 'unreadiest', 'crankest', 'cheerfullest', 'charmingest', 'unsteadiest', 'peacefullest', 'slovenliest', 'lairiest', 'dashiest', 'sleekiest', 'meowiest', 'shiveriest', 'pepperiest', 'miserliest', 'antientest', 'strappiest', 'skeeviest', 'yelpiest', 'crêpiest', 'spinniest', 'straitest', 'shoutiest', 'spoofiest', 'burstiest', 'uncomeliest', 'gracefullest', 'stiddiest', 'slurriest', 'tiddliest', 'uncommonest', 'bullshittiest', 'towardliest', 'trebliest', 'clashiest', 'chippiest', 'servilest', 'throbbiest', 'neighborliest', 'bleediest', 'grousest', 'selectest', 'churchliest', 'ballsiest', 'unthriftiest', 'intimatest', 'auldest', 'pengest', 'profitablest', 'necessariest', 'stariest', 'saltest', 'girl_craziest', 'hubbiest', 'lakiest', 'sinniest', 'broomiest', 'bitsiest', 'wibbliest', 'duffest', 'shriekiest', 'sookiest', 'sparkiest', 'speckiest', 'nelliest', 'plentifullest', 'mitiest', 'gruntiest', 'wifiest', 'deathliest', 'cursedest', 'nubbiest', 'rummiest', 'skippiest', 'knightliest', 'skunkiest', 'zazziest', 'lovingest', 'billowiest', 'bloodthirstiest', 'blousiest', 'bunchiest', 'troublesomest', 'squeeziest', 'lissomest', 'yolkiest', 'shelliest', 'pilliest', 'schmooziest', 'aloneliest', 'comfortablest', 'veiniest', 'squattest', 'shortest-term', 'puggiest', 'skintest', 'swartest', 'stanchest', 'suddenest', 'dreadfulest', 'fearfulest', 'dreadfullest', 'violentest', 'rearest', 'bangingest', 'sawciest', 'buffiest', 'strikingest', 'leariest', 'mournfullest', 'unworthiest', 'hardest_put', 'crashiest', 'wackest', 'schmalziest', 'clankiest', 'cobwebbiest', 'unwieldiest', 'whizziest', 'bolshiest', 'neutron-richest', 'clunkiest', 'clangiest', 'hopefullest', 'topsy-turviest', 'untruest', 'voluntariest', 'unloveliest', 'compleatest', 'untimeliest', 'unkindliest', 'snuffliest', 'favourablest', 'goddamnedest', 'lonesomest', 'genteelest', 'solemnest', 'primest', 'faithfulest', 'faithfullest', 'decentest', 'distinctest', 'crookedest', 'vividest', 'loyalest', 'cussedest', 'fruitfullest', 'eagerest', 'delicatest', 'demurest', 'fruitfulest', 'cheerfulest', 'splendidest', 'dismallest', 'dismalest', 'sacredest', 'savagest', 'gimmickiest', 'skilfulest', 'frattiest', 'fortunatest', 'crampiest', 'seriousest', 'concretest', 'namby-pambiest', 'douchiest', 'dictiest', 'purpliest', 'bleachiest', 'newest-fangled', 'seasickest', 'okayest', 'oatiest', 'curstest', 'droughtiest', 'drapiest', 'freashest', 'koolest', 'nubbliest', 'menschiest', 'pranciest', 'prawniest', 'biggest-dicked', 'rookiest', 'shirtiest', 'shtickiest', 'slatiest', 'snackiest', 'songiest', 'spivviest', 'spumiest', 'stedfastest', 'tickliest', 'titchiest', 'tuskiest', 'viewiest', 'vastiest', 'wiggiest', 'workiest', 'wysest', 'slopiest', 'fucked-upest', 'toshest', 'toshiest', 'oomphiest', 'ruffest', 'germiest', 'spooniest', 'softliest', 'leastest', 'striktest', 'damndest', 'goddamndest', 'muggest', 'impolitest', 'bestest', 'zooiest', 'torquiest', 'funnest', 'furtherest', 'rockingest', 'mostest', 'overest', 'willingest', 'weeniest', 'poorliest', 'gamesomest', 'quackiest', 'towniest', 'drooliest', 'frowstiest', 'muslimest', 'scurfiest', 'oneriest', 'rimiest', 'gonest', 'unworldliest', 'breastiest', 'best_for_you', 'wolfiest', 'laughiest', 'squealiest', 'stenchiest', 'crushingest', 'affectedest', 'civilest', 'bleachest', 'draftiest', 'elitest', 'beigest', 'bentest', 'lavishest', 'fleekest', 'perfectest', 'blippiest', 'lambiest', 'chocolatiest', 'snortiest', 'stabbiest', 'joyfullest', 'unearthliest', 'limberest', 'danciest', 'wenchest', 'str8est', 'docilest', 'doggedest', 'drossiest', 'panickiest', 'putridest', 'slantiest', 'complexest', 'meetest', 'succinctest', 'tinkliest', 'scraggliest', 'shaliest', 'skyiest', 'slaphappiest', 'slimpsiest', 'slitheriest', 'slobberiest', 'slumpiest', 'snailiest', 'sneeriest', 'pinchiest', 'sordidest', 'specialest', 'spickest', 'spideriest', 'spitefullest', 'splurgiest', 'spraunciest', 'sprawliest', 'spriteliest', 'squalidest', 'modernest', 'earthliest', 'jemmiest', 'toolsiest', 'inanest', 'indecentest', 'inertest', 'ineptest', 'insanest', 'jiviest', 'nakedest', 'gingerest', 'fallowest', 'savoriest', 'savouriest', 'scroungiest', 'scrunchiest', 'sedatest', 'dykiest', 'boringest', 'validest', 'queefiest', 'chinniest', 'clerkliest', 'wantonest', 'weensiest', 'wershest', 'winsomest', 'woodenest', 'unchanciest', 'unfittest', 'unjustest', 'unkingliest', 'unquietest', 'unshapeliest', 'naivest', 'nutsiest', 'neapiest', 'gnashiest', 'frigidest', 'wilfullest', 'powerfulest', 'plentifulest', 'crookest', 'gladsomest', 'gorsiest', 'gemmiest', 'ghostiest', 'globbiest', 'painfulest', 'painfullest', 'pallidest', 'patentest', 'peacockiest', 'peeriest', 'perversest', 'placidest', 'plonkiest', 'poachiest', 'powderiest', 'prickiest', 'priviest', 'fulliest', 'puddliest', 'rabidest', 'rancidest', 'rascalliest', \"'appiest\", 'flyest', 'flashest', 'gallantest', 'garlickiest', 'grotesquest', 'queeniest', 'ignoblest', 'rapiest', 'immensest', 'recentest', 'innocentest', 'lemoniest', 'levellest', 'lucidest', 'luridest', 'maggotiest', 'mixiest', 'morbidest', 'morosest', 'jettiest', 'joyfulest', 'knowingest', 'knuckliest', 'obesest', 'rheumiest', 'slapstickiest', 'uptightest', 'twin_peaksiest', 'leftest', 'lividest', 'excellentest', 'foodiest', 'longest-term', 'unmaddest', 'broodingest', 'worst-tempered', 'drouthiest', 'humanest', 'unhandiest', 'headachiest', 'hedgiest', 'herbiest', 'hulkiest', 'limbiest', 'faggotiest', 'ghettoest', 'cantiest', 'candidest', 'carrotiest', 'certainest', 'chertiest', 'chirkiest', 'waggliest', 'waspiest', 'waspiest', 'whitiest', 'williest', 'woefullest', 'woofiest', 'hyest', 'humidest', 'roughest_around_the_edges', 'fendiest', 'fertilest', 'ferventest', 'fervidest', 'fitliest', 'forwardest', 'debbiest', 'doggonedest', 'doggonest', 'dolefullest', 'drawliest', 'dreggiest', 'dribbliest', 'fastest-acting', 'slowest-acting', 'bairnliest', 'best-informed', 'widest-spread', 'widestspread', 'blearest', 'blusteriest', 'worthlessest', 'buirdliest', 'cliquiest', 'croakiest', 'anxiousest', 'dangliest', 'dapperest', 'daubiest', 'nobliest', 'dippiest', 'drearest', 'featliest', 'neatliest', 'floridest', 'cackiest', 'fulsomest', 'droniest', 'duckiest', 'rickettiest', 'ridgiest', 'rigidest', 'roiliest', 'rootsiest', 'rotundest', 'ruffliest', 'rumbliest', 'larkiest', 'bitchingest', 'faintiest', 'ferniest', 'flauntiest', 'steepiest', 'stilliest', 'assiest', 'gainliest', 'swingiest', 'matiest', 'muzziest', 'pursiest', 'racketiest', 'shingliest', 'feintest', 'fragilest', 'frouziest', 'cliffiest', 'cloggiest', 'whackest', 'fayrest', 'fenniest', 'futilest', 'atteriest', 'adultiest', 'leewardmost', 'lievest', 'mirkiest', 'ordinariest', 'yakkiest', 'seaworthiest', 'shmaltziest', 'twiddliest', 'trembliest', 'teentsiest', 'tangliest', 'swingingest', 'soakiest', 'alertest', 'affablest', 'avidest', 'balefullest', 'balefulest', 'banefullest', 'banefulest', 'super-duperest', 'longest-lasting', 'viciousest', 'gassest', 'wydest', 'best-timed', 'headliest', 'heppest', 'fuggiest', 'bunniest', 'englishest', 'britishest', 'germanest', 'frenchest', 'russianest', 'runtiest', 'gooniest', 'waltziest', 'toploftiest', 'torridest', 'tranquillest', 'wofullest', 'foziest', 'fraughtest', 'ornatest', 'thrilliest', 'thymiest', 'gluggiest', 'choiciest', 'bandiest', 'boggest', 'complicatedest', 'peacefulest', 'fuckedest', 'dunniest', 'nettiest', 'neshest', 'cuuutest', 'goldenest', 'goldest', 'smilingest', 'ledgiest', 'churchiest', 'jealousest', 'crappest', 'hardest-earned', 'selfishest', 'lintiest', 'loyallest', 'barniest', 'baroquest', 'quarest', 'nouniest', 'mimsiest', 'nithermost', 'grewsomest', 'gaggiest', 'wedgiest', 'thoughtiest', 'croupiest', 'uselessest', 'wholest', 'swackest', 'most', 'trustworthiest', 'clartiest', 'cloddiest', 'cluckiest', 'quickliest', 'troutiest', 'wheeliest', 'turfiest', 'twangiest', 'toffiest', 'taggiest', 'best-behaved', 'shortest-haul', 'restfulest', 'restfullest', 'rortiest', 'rushiest', 'farthermost', 'coiliest', 'gentliest', 'uppermost', 'dangerousest', 'intelligentest', 'fousest', 'weakiest', 'subtilest', 'summeriest', 'prophanest', 'benat', 'wickest', 'glaziest', 'growthiest', 'niggliest', 'hootiest', 'highest_functioning', 'highest-functioning', 'furthest-flung', 'furthest_flung', 'farthest-flung', 'farthest_flung', 'slashiest', 'fineliest', 'scrawliest', 'horriblest', 'owliest', 'highest-resolution', 'stemmiest', 'revviest', 'trappiest', 'tuftiest', 'typiest', 'bassiest', 'pouchiest', 'preciousest', 'lowest-resolution', 'unpleasantest', 'tankiest', 'chokiest', 'couthiest', 'coxiest', 'crawliest', 'creekiest', 'cherriest', 'tuniest', 'nookiest', 'swaliest', 'swanniest', 'hashiest', 'scowliest', 'accuratest', 'pouffiest', 'spazziest', 'fewest_and_farthest_between', 'fewest_and_furthest_between']}\n"
     ]
    }
   ],
   "source": [
    "# Load custom vocabulary\n",
    "wikitionary_dir = \"./wiktionarylists\"\n",
    "\n",
    "# list all text files\n",
    "import os\n",
    "wikitionary_files = os.listdir(wikitionary_dir)\n",
    "\n",
    "# read all files\n",
    "wikitionary_words = {}\n",
    "for file in wikitionary_files:\n",
    "    if file == \".DS_Store\":\n",
    "        continue\n",
    "    category_words = []\n",
    "    with open(f\"{wikitionary_dir}/{file}\") as f:\n",
    "        category_words += f.read().splitlines()\n",
    "\n",
    "    # lowercase\n",
    "    category_words = [word.lower() for word in category_words]\n",
    "    wikitionary_words[file] = category_words\n",
    "\n",
    "# print\n",
    "print(wikitionary_words)\n",
    "\n",
    "# get all words\n",
    "all_words = set()\n",
    "for category, words in wikitionary_words.items():\n",
    "    all_words.update(words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from class counters, let's see how many words are in the wikitionary\n",
    "final = {}\n",
    "for i in [1,2,3,4]:\n",
    "    counter = class_counters[i]\n",
    "    total_words = sum(counter.values())\n",
    "    \n",
    "    words_in_wikitionary_separated_by_type = {category: 0 for category in wikitionary_words.keys()}\n",
    "    for word, count in counter.items():\n",
    "        for category, words in wikitionary_words.items():\n",
    "            if word.lower() in words:\n",
    "                words_in_wikitionary_separated_by_type[category] += count\n",
    "    final[i] = words_in_wikitionary_separated_by_type\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize it\n",
    "final_normalized = {}\n",
    "for i in [1,2,3,4]:\n",
    "    counter = class_counters[i]\n",
    "    total_words = sum(counter.values())\n",
    "    \n",
    "    final_normalized[i] = {category: 0 for category in wikitionary_words.keys()}\n",
    "    for category, count in final[i].items():\n",
    "        final_normalized[i][category] = (count / total_words * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'comparative_forms.txt': 0.27949180713781274,\n",
       "  'modal_adverbs.txt': 0.4680310736679911,\n",
       "  'act_adverbs.txt': 0.012055670088384469,\n",
       "  'manner_adverbs.txt': 0.32742914618748353,\n",
       "  'superlative_forms.txt': 0.2517423653367384},\n",
       " 2: {'comparative_forms.txt': 0.20980279216509917,\n",
       "  'modal_adverbs.txt': 0.3313390374646227,\n",
       "  'act_adverbs.txt': 0.00984511484269883,\n",
       "  'manner_adverbs.txt': 0.2774738114287072,\n",
       "  'superlative_forms.txt': 0.17404352446058388},\n",
       " 3: {'comparative_forms.txt': 0.3062648397237359,\n",
       "  'modal_adverbs.txt': 0.3554044377357323,\n",
       "  'act_adverbs.txt': 0.012925115504630331,\n",
       "  'manner_adverbs.txt': 0.32175081923489113,\n",
       "  'superlative_forms.txt': 0.24139767125657247},\n",
       " 4: {'comparative_forms.txt': 0.33562906291274935,\n",
       "  'modal_adverbs.txt': 0.16437021952226438,\n",
       "  'act_adverbs.txt': 0.006171058881947643,\n",
       "  'manner_adverbs.txt': 0.17967827256275465,\n",
       "  'superlative_forms.txt': 0.25837123272402496}}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for satire - adverbs appear the most times - modal_adverbs, manner_adverbs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which of the wikitionary words are most common in each class\n",
    "# from class counters, let's see how many words are in the wikitionary\n",
    "from collections import defaultdict\n",
    "final_words = {}\n",
    "for i in [1,2,3,4]:\n",
    "    counter = class_counters[i]\n",
    "    total_words = sum(counter.values())\n",
    "    \n",
    "    words_in_wikitionary_separated_by_type = {category: {} for category in wikitionary_words.keys()}\n",
    "    for word, count in counter.items():\n",
    "        for category, words in wikitionary_words.items():\n",
    "            if word.lower() in words:\n",
    "                if word not in words_in_wikitionary_separated_by_type[category]:\n",
    "                    words_in_wikitionary_separated_by_type[category][word] = 0\n",
    "                words_in_wikitionary_separated_by_type[category][word] += count\n",
    "    final_words[i] = words_in_wikitionary_separated_by_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'comparative_forms.txt': {'faster': 39,\n",
       "   'crapper': 1,\n",
       "   'number': 441,\n",
       "   'better': 475,\n",
       "   'lower': 98,\n",
       "   'commoner': 1,\n",
       "   'deeper': 33,\n",
       "   'harder': 33,\n",
       "   'Further': 26,\n",
       "   'darker': 6,\n",
       "   'greater': 108,\n",
       "   'further': 208,\n",
       "   'longer': 237,\n",
       "   'easier': 44,\n",
       "   'shitter': 3,\n",
       "   'Earlier': 16,\n",
       "   'Lower': 11,\n",
       "   'littler': 1,\n",
       "   'younger': 75,\n",
       "   'higher': 92,\n",
       "   'closer': 71,\n",
       "   'older': 83,\n",
       "   'cooler': 9,\n",
       "   'later': 417,\n",
       "   'worse': 80,\n",
       "   'quicker': 8,\n",
       "   'dryer': 10,\n",
       "   'louder': 10,\n",
       "   'meaner': 4,\n",
       "   'sharper': 3,\n",
       "   'bigger': 39,\n",
       "   'Bigger': 3,\n",
       "   'hotter': 5,\n",
       "   'Fuller': 21,\n",
       "   'stranger': 15,\n",
       "   'elder': 14,\n",
       "   'trickier': 2,\n",
       "   'less': 304,\n",
       "   'earlier': 140,\n",
       "   'cleaner': 10,\n",
       "   'broader': 13,\n",
       "   'nicer': 8,\n",
       "   'Sharper': 5,\n",
       "   'classier': 1,\n",
       "   'larger': 55,\n",
       "   'heavier': 6,\n",
       "   'sooner': 35,\n",
       "   'Better': 12,\n",
       "   'safer': 11,\n",
       "   'sticker': 12,\n",
       "   'happier': 15,\n",
       "   'thicker': 5,\n",
       "   'Safer': 1,\n",
       "   'Broker': 1,\n",
       "   'farther': 9,\n",
       "   'leaner': 3,\n",
       "   'healthier': 7,\n",
       "   'Kinder': 1,\n",
       "   'taller': 11,\n",
       "   'Dozier': 6,\n",
       "   'smaller': 45,\n",
       "   'stronger': 28,\n",
       "   'scarier': 4,\n",
       "   'yummier': 1,\n",
       "   'tighter': 4,\n",
       "   'shorter': 13,\n",
       "   'Elder': 4,\n",
       "   'Less': 12,\n",
       "   'wider': 9,\n",
       "   'weaker': 6,\n",
       "   'Later': 17,\n",
       "   'newer': 4,\n",
       "   'fatter': 7,\n",
       "   'tougher': 5,\n",
       "   'Lesser': 3,\n",
       "   'Worse': 6,\n",
       "   'brighter': 11,\n",
       "   'smoother': 2,\n",
       "   'liver': 8,\n",
       "   'spicier': 1,\n",
       "   'gentler': 1,\n",
       "   'slower': 8,\n",
       "   'truer': 2,\n",
       "   'Higher': 1,\n",
       "   'grosser': 1,\n",
       "   'archer': 1,\n",
       "   'lighter': 16,\n",
       "   'funnier': 6,\n",
       "   'Shorter': 1,\n",
       "   'lesser': 21,\n",
       "   'stricter': 5,\n",
       "   'bushier': 1,\n",
       "   'Snider': 2,\n",
       "   'fainter': 3,\n",
       "   'broker': 9,\n",
       "   'simpler': 17,\n",
       "   'Wilder': 2,\n",
       "   'Frontier': 1,\n",
       "   'fresher': 1,\n",
       "   'damper': 1,\n",
       "   'tamer': 2,\n",
       "   'Longer': 1,\n",
       "   'nuttier': 1,\n",
       "   'crazier': 2,\n",
       "   'Cooler': 1,\n",
       "   'smarter': 5,\n",
       "   'butcher': 6,\n",
       "   'Liver': 1,\n",
       "   'wiser': 3,\n",
       "   'Battier': 4,\n",
       "   'likelier': 1,\n",
       "   'swifter': 3,\n",
       "   'thinner': 5,\n",
       "   'Number': 6,\n",
       "   'prouder': 1,\n",
       "   'narrower': 1,\n",
       "   'buffer': 2,\n",
       "   'stupider': 1,\n",
       "   'Greater': 6,\n",
       "   'fancier': 1,\n",
       "   'grittier': 1,\n",
       "   'grimmer': 1,\n",
       "   'flashier': 1,\n",
       "   'trashier': 1,\n",
       "   'weer': 1,\n",
       "   'greener': 3,\n",
       "   'fairer': 2,\n",
       "   'cheaper': 6,\n",
       "   'cuter': 3,\n",
       "   'holier': 1,\n",
       "   'Older': 1,\n",
       "   'gamer': 1,\n",
       "   'prompter': 1,\n",
       "   'hungrier': 3,\n",
       "   'fuller': 1,\n",
       "   'quieter': 5,\n",
       "   'stiffer': 2,\n",
       "   'Happier': 1,\n",
       "   'finer': 2,\n",
       "   'crisper': 3,\n",
       "   'wilder': 1,\n",
       "   'subtler': 2,\n",
       "   'sleeker': 2,\n",
       "   'slimmer': 1,\n",
       "   'sweeter': 4,\n",
       "   'hinder': 2,\n",
       "   'kinder': 3,\n",
       "   'richer': 3,\n",
       "   'keener': 1,\n",
       "   'bolder': 4,\n",
       "   'Stranger': 3,\n",
       "   'flimsier': 1,\n",
       "   'soggier': 1,\n",
       "   'odder': 1,\n",
       "   'softer': 2,\n",
       "   'tinier': 1,\n",
       "   'moodier': 1,\n",
       "   'Cleaner': 5,\n",
       "   'hipper': 1,\n",
       "   'grayer': 1,\n",
       "   'weirder': 2,\n",
       "   'dirtier': 2,\n",
       "   'Archer': 1,\n",
       "   'rarer': 1,\n",
       "   'blander': 1,\n",
       "   'colder': 1,\n",
       "   'Tanner': 15,\n",
       "   'poorer': 2,\n",
       "   'rounder': 1,\n",
       "   'chunkier': 2,\n",
       "   'angrier': 1,\n",
       "   'bummer': 4,\n",
       "   'NUMBER': 1,\n",
       "   'Bummer': 1,\n",
       "   'friendlier': 2,\n",
       "   'nearer': 1,\n",
       "   'freer': 1,\n",
       "   'tastier': 1,\n",
       "   'clearer': 3,\n",
       "   'Easier': 1,\n",
       "   'zestier': 1,\n",
       "   'crunchier': 1,\n",
       "   'balmier': 1,\n",
       "   'toastier': 1,\n",
       "   'whiter': 4,\n",
       "   'shittier': 2,\n",
       "   'Larger': 1,\n",
       "   'warmer': 4,\n",
       "   'frontier': 1,\n",
       "   'Idler': 1,\n",
       "   'humbler': 1,\n",
       "   'beefier': 1,\n",
       "   'backer': 1,\n",
       "   'wealthier': 1,\n",
       "   'sorrier': 1,\n",
       "   'pushier': 1,\n",
       "   'Stiller': 2,\n",
       "   'Sooner': 2,\n",
       "   'Nearer': 1,\n",
       "   'pricier': 2,\n",
       "   'Swisher': 1,\n",
       "   'drunker': 1,\n",
       "   'Louder': 1,\n",
       "   'madder': 3,\n",
       "   'rougher': 1,\n",
       "   'redder': 1},\n",
       "  'modal_adverbs.txt': {'actually': 462,\n",
       "   'really': 1393,\n",
       "   'Maybe': 122,\n",
       "   'indeed': 51,\n",
       "   'totally': 234,\n",
       "   'probably': 329,\n",
       "   'sure': 471,\n",
       "   'maybe': 266,\n",
       "   'reportedly': 1115,\n",
       "   'perhaps': 103,\n",
       "   'truly': 163,\n",
       "   'Reportedly': 6,\n",
       "   'definitely': 209,\n",
       "   'believably': 1,\n",
       "   'Inevitably': 3,\n",
       "   'seemingly': 64,\n",
       "   'essentially': 25,\n",
       "   'apparently': 88,\n",
       "   'certainly': 152,\n",
       "   'Unfortunately': 54,\n",
       "   'likely': 237,\n",
       "   'possibly': 118,\n",
       "   'noticeably': 8,\n",
       "   'literally': 46,\n",
       "   'obviously': 65,\n",
       "   'Clearly': 22,\n",
       "   'Apparently': 25,\n",
       "   'clearly': 133,\n",
       "   'Sure': 94,\n",
       "   'evidently': 15,\n",
       "   'Perhaps': 39,\n",
       "   'purportedly': 7,\n",
       "   'Surely': 3,\n",
       "   'Indeed': 18,\n",
       "   'allegedly': 29,\n",
       "   'hypothetically': 3,\n",
       "   'positively': 15,\n",
       "   'inevitably': 18,\n",
       "   'undoubtedly': 7,\n",
       "   'surely': 22,\n",
       "   'Actually': 19,\n",
       "   'strictly': 22,\n",
       "   'undeniably': 8,\n",
       "   'transparently': 1,\n",
       "   'Really': 19,\n",
       "   'unfortunately': 50,\n",
       "   'assuredly': 3,\n",
       "   'Obviously': 37,\n",
       "   'conceivably': 11,\n",
       "   'presumably': 15,\n",
       "   'Hypothetically': 1,\n",
       "   'needlessly': 6,\n",
       "   'Certainly': 12,\n",
       "   'fortunately': 3,\n",
       "   'unnecessarily': 2,\n",
       "   'patently': 5,\n",
       "   'Definitely': 6,\n",
       "   'Fortunately': 11,\n",
       "   'Likely': 2,\n",
       "   'technically': 14,\n",
       "   'Probably': 7,\n",
       "   'loosely': 5,\n",
       "   'Totally': 1,\n",
       "   'ostensibly': 3,\n",
       "   'Truly': 5,\n",
       "   'necessarily': 14,\n",
       "   'Statistically': 1,\n",
       "   'Doubtless': 1,\n",
       "   'Seemingly': 2,\n",
       "   'Noticeably': 1,\n",
       "   'Literally': 3,\n",
       "   'unquestionably': 5,\n",
       "   'indisputably': 1,\n",
       "   'scarcely': 4,\n",
       "   'Essentially': 2,\n",
       "   'statistically': 6,\n",
       "   'Allegedly': 1,\n",
       "   'REALLY': 1,\n",
       "   'impossibly': 2,\n",
       "   'plausibly': 1,\n",
       "   'ACTUALLY': 1,\n",
       "   'plainly': 4,\n",
       "   'Necessarily': 1,\n",
       "   'Ostensibly': 1,\n",
       "   'doubtless': 1,\n",
       "   'Possibly': 1,\n",
       "   'arguably': 1,\n",
       "   'Evidently': 1,\n",
       "   'doubtlessly': 2},\n",
       "  'act_adverbs.txt': {'accidentally': 56,\n",
       "   'carefully': 76,\n",
       "   'freely': 15,\n",
       "   'deliberately': 12,\n",
       "   'foolishly': 1,\n",
       "   'Discreetly': 1,\n",
       "   'cleverly': 2,\n",
       "   'discreetly': 5,\n",
       "   'carelessly': 1},\n",
       "  'manner_adverbs.txt': {'hard': 432,\n",
       "   'Finally': 23,\n",
       "   'well': 868,\n",
       "   'incredibly': 73,\n",
       "   'briefly': 68,\n",
       "   'seriously': 90,\n",
       "   'Anyway': 23,\n",
       "   'finally': 344,\n",
       "   'Well': 180,\n",
       "   'especially': 150,\n",
       "   'Thus': 29,\n",
       "   'Especially': 31,\n",
       "   'profoundly': 10,\n",
       "   'unbelievably': 19,\n",
       "   'Similarly': 5,\n",
       "   'equally': 62,\n",
       "   'simply': 281,\n",
       "   'exactly': 185,\n",
       "   'Seriously': 40,\n",
       "   'accidentally': 56,\n",
       "   'similarly': 21,\n",
       "   'frankly': 46,\n",
       "   'completely': 383,\n",
       "   'slightly': 75,\n",
       "   'honestly': 72,\n",
       "   'noticeably': 8,\n",
       "   'purely': 14,\n",
       "   'Frankly': 48,\n",
       "   'Clearly': 22,\n",
       "   'carefully': 76,\n",
       "   'alarmingly': 4,\n",
       "   'quite': 135,\n",
       "   'chronologically': 3,\n",
       "   'clearly': 133,\n",
       "   'sufficiently': 12,\n",
       "   'consistently': 41,\n",
       "   'precisely': 17,\n",
       "   'otherwise': 69,\n",
       "   'thus': 54,\n",
       "   'understandably': 4,\n",
       "   'Honestly': 55,\n",
       "   'Completely': 6,\n",
       "   'ironically': 2,\n",
       "   'terminally': 1,\n",
       "   'pleasantly': 11,\n",
       "   'summarily': 5,\n",
       "   'anyway': 92,\n",
       "   'WELL': 1,\n",
       "   'freely': 15,\n",
       "   'Likewise': 4,\n",
       "   'positively': 15,\n",
       "   'economically': 9,\n",
       "   'deliberately': 12,\n",
       "   'Understandably': 1,\n",
       "   'vicariously': 3,\n",
       "   'Exactly': 3,\n",
       "   'Otherwise': 12,\n",
       "   'embarrassingly': 3,\n",
       "   'staggeringly': 1,\n",
       "   'importantly': 10,\n",
       "   'remarkably': 11,\n",
       "   'suspiciously': 4,\n",
       "   'hideously': 2,\n",
       "   'Simply': 9,\n",
       "   'Hard': 19,\n",
       "   'Incredibly': 2,\n",
       "   'differently': 9,\n",
       "   'accordingly': 5,\n",
       "   'anyhow': 3,\n",
       "   'Quite': 6,\n",
       "   'scarily': 1,\n",
       "   'centrally': 2,\n",
       "   'likewise': 5,\n",
       "   'foolishly': 1,\n",
       "   'horribly': 11,\n",
       "   'COMPLETELY': 1,\n",
       "   'metaphorically': 1,\n",
       "   'Noticeably': 1,\n",
       "   'Ironically': 4,\n",
       "   'alphabetically': 1,\n",
       "   'truthfully': 3,\n",
       "   'Discreetly': 1,\n",
       "   'habitually': 1,\n",
       "   'incidentally': 2,\n",
       "   'Equally': 1,\n",
       "   'plausibly': 1,\n",
       "   'cleverly': 2,\n",
       "   'discreetly': 5,\n",
       "   'customarily': 1,\n",
       "   'carelessly': 1,\n",
       "   'strikingly': 1,\n",
       "   'Incidentally': 2,\n",
       "   'Terminally': 1,\n",
       "   'Precisely': 1,\n",
       "   'Truthfully': 1,\n",
       "   'Remarkably': 1},\n",
       "  'superlative_forms.txt': {'least': 437,\n",
       "   'uppermost': 3,\n",
       "   'oddest': 1,\n",
       "   'best': 587,\n",
       "   'most': 1190,\n",
       "   'largest': 82,\n",
       "   'greatest': 95,\n",
       "   'highest': 83,\n",
       "   'latest': 151,\n",
       "   'closest': 23,\n",
       "   'worst': 132,\n",
       "   'hardest': 13,\n",
       "   'biggest': 86,\n",
       "   'deepest': 30,\n",
       "   'deadliest': 5,\n",
       "   'Best': 65,\n",
       "   'luckiest': 3,\n",
       "   'Most': 70,\n",
       "   'newest': 31,\n",
       "   'lowest': 16,\n",
       "   'youngest': 18,\n",
       "   'earliest': 17,\n",
       "   'grossest': 1,\n",
       "   'slightest': 31,\n",
       "   'darkest': 11,\n",
       "   'oldest': 16,\n",
       "   'coolest': 13,\n",
       "   'likeliest': 1,\n",
       "   'safest': 3,\n",
       "   'wildest': 5,\n",
       "   'toughest': 5,\n",
       "   'hottest': 12,\n",
       "   'nastiest': 1,\n",
       "   'Worst': 4,\n",
       "   'tallest': 5,\n",
       "   'fastest': 8,\n",
       "   'longest': 13,\n",
       "   'purest': 3,\n",
       "   'strongest': 9,\n",
       "   'Least': 2,\n",
       "   'Biggest': 6,\n",
       "   'finest': 20,\n",
       "   'coldest': 1,\n",
       "   'brightest': 5,\n",
       "   'nearest': 13,\n",
       "   'meanest': 1,\n",
       "   'funniest': 12,\n",
       "   'worldliest': 1,\n",
       "   'Greatest': 6,\n",
       "   'fullest': 5,\n",
       "   'simplest': 8,\n",
       "   'bloodiest': 1,\n",
       "   'cutest': 4,\n",
       "   'weirdest': 6,\n",
       "   'sturdiest': 1,\n",
       "   'faintest': 3,\n",
       "   'cleanest': 2,\n",
       "   'smallest': 7,\n",
       "   'basest': 3,\n",
       "   'Shiniest': 1,\n",
       "   'sexiest': 1,\n",
       "   'happiest': 5,\n",
       "   'heartiest': 1,\n",
       "   'lamest': 1,\n",
       "   'quickest': 1,\n",
       "   'richest': 9,\n",
       "   'sweetest': 2,\n",
       "   'blackest': 1,\n",
       "   'poorest': 4,\n",
       "   'trendiest': 1,\n",
       "   'hippest': 1,\n",
       "   'tiniest': 3,\n",
       "   'oiliest': 1,\n",
       "   'sincerest': 1,\n",
       "   'hugest': 2,\n",
       "   'merest': 1,\n",
       "   'eldest': 8,\n",
       "   'nicest': 3,\n",
       "   'thinnest': 1,\n",
       "   'soggiest': 1,\n",
       "   'craziest': 2,\n",
       "   'busiest': 1,\n",
       "   'easiest': 4,\n",
       "   'grandest': 1,\n",
       "   'strangest': 2,\n",
       "   'greenest': 1,\n",
       "   'strictest': 1,\n",
       "   'smartest': 2,\n",
       "   'stupidest': 2,\n",
       "   'ugliest': 2,\n",
       "   'sharpest': 2,\n",
       "   'fondest': 1,\n",
       "   'farthest': 3,\n",
       "   'spikiest': 1,\n",
       "   'noblest': 1,\n",
       "   'widest': 1,\n",
       "   'dumbest': 2,\n",
       "   'tensest': 1,\n",
       "   'creepiest': 1,\n",
       "   'harshest': 4,\n",
       "   'neatest': 1,\n",
       "   'wealthiest': 4,\n",
       "   'freakiest': 1,\n",
       "   'briefest': 1,\n",
       "   'staunchest': 2,\n",
       "   'Largest': 4,\n",
       "   'Finest': 1,\n",
       "   'shoddiest': 1,\n",
       "   'silliest': 1,\n",
       "   'saddest': 3,\n",
       "   'Sexiest': 1,\n",
       "   'smoothest': 1,\n",
       "   'Funniest': 4,\n",
       "   'freshest': 2,\n",
       "   'tastiest': 1,\n",
       "   'shortest': 2,\n",
       "   'narrowest': 1,\n",
       "   'juiciest': 1,\n",
       "   'healthiest': 1,\n",
       "   'whitest': 1,\n",
       "   'boldest': 1,\n",
       "   'scariest': 2,\n",
       "   'remotest': 1,\n",
       "   'spookiest': 1,\n",
       "   'loudest': 1,\n",
       "   'wettest': 1,\n",
       "   'loveliest': 1,\n",
       "   'Liveliest': 1,\n",
       "   'handiest': 1,\n",
       "   'stiffest': 1,\n",
       "   'weakest': 1,\n",
       "   'furthest': 2,\n",
       "   'shittiest': 1,\n",
       "   'bestest': 1,\n",
       "   'holiest': 1,\n",
       "   'gravest': 1,\n",
       "   'hindmost': 1,\n",
       "   'littlest': 1,\n",
       "   'fanciest': 1,\n",
       "   'loftiest': 1,\n",
       "   'Richest': 1,\n",
       "   'smuggest': 1,\n",
       "   'proudest': 1}},\n",
       " 2: {'comparative_forms.txt': {'older': 34,\n",
       "   'higher': 25,\n",
       "   'later': 240,\n",
       "   'Further': 31,\n",
       "   'bigger': 36,\n",
       "   'number': 180,\n",
       "   'worse': 84,\n",
       "   'Earlier': 49,\n",
       "   'less': 129,\n",
       "   'Later': 41,\n",
       "   'stricter': 15,\n",
       "   'safer': 12,\n",
       "   'better': 212,\n",
       "   'further': 122,\n",
       "   'longer': 104,\n",
       "   'stronger': 19,\n",
       "   'nearer': 4,\n",
       "   'larger': 18,\n",
       "   'lower': 25,\n",
       "   'Less': 19,\n",
       "   'Smarter': 2,\n",
       "   'closer': 33,\n",
       "   'Lower': 2,\n",
       "   'elder': 4,\n",
       "   'younger': 21,\n",
       "   'taller': 2,\n",
       "   'stranger': 18,\n",
       "   'Worse': 13,\n",
       "   'lesser': 14,\n",
       "   'scarier': 1,\n",
       "   'Number': 13,\n",
       "   'earlier': 70,\n",
       "   'Tanner': 2,\n",
       "   'Solider': 1,\n",
       "   'lighter': 2,\n",
       "   'Longer': 10,\n",
       "   'Shorter': 1,\n",
       "   'shorter': 1,\n",
       "   'SAFER': 1,\n",
       "   'easier': 18,\n",
       "   'cattier': 1,\n",
       "   'smarter': 5,\n",
       "   'hinder': 4,\n",
       "   'deeper': 16,\n",
       "   'greater': 22,\n",
       "   'fairer': 3,\n",
       "   'rarer': 1,\n",
       "   'healthier': 4,\n",
       "   'prouder': 2,\n",
       "   'sooner': 5,\n",
       "   'tougher': 8,\n",
       "   'Tougher': 2,\n",
       "   'solider': 3,\n",
       "   'Archer': 1,\n",
       "   'harder': 19,\n",
       "   'louder': 6,\n",
       "   'smaller': 7,\n",
       "   'Cooler': 1,\n",
       "   'cheaper': 7,\n",
       "   'cooler': 2,\n",
       "   'Safer': 2,\n",
       "   'thinner': 1,\n",
       "   'farther': 4,\n",
       "   'uglier': 1,\n",
       "   'Better': 6,\n",
       "   'richer': 2,\n",
       "   'Fuller': 1,\n",
       "   'sticker': 6,\n",
       "   'Sooner': 2,\n",
       "   'sweeter': 4,\n",
       "   'friendlier': 2,\n",
       "   'butcher': 2,\n",
       "   'shrewder': 1,\n",
       "   'Greater': 2,\n",
       "   'Bossier': 1,\n",
       "   'darker': 3,\n",
       "   'Camper': 3,\n",
       "   'camper': 3,\n",
       "   'savvier': 1,\n",
       "   'weirder': 2,\n",
       "   'slower': 1,\n",
       "   'Slower': 1,\n",
       "   'weaker': 2,\n",
       "   'barer': 1,\n",
       "   'wiser': 1,\n",
       "   'crazier': 2,\n",
       "   'broader': 5,\n",
       "   'fuller': 1,\n",
       "   'gentler': 1,\n",
       "   'holier': 1,\n",
       "   'Grander': 1,\n",
       "   'wealthier': 1,\n",
       "   'wider': 1,\n",
       "   'cleaner': 3,\n",
       "   'quicker': 2,\n",
       "   'colder': 1,\n",
       "   'faster': 7,\n",
       "   'bolder': 3,\n",
       "   'happier': 2,\n",
       "   'dumber': 1,\n",
       "   'Cheaper': 1,\n",
       "   'clearer': 2,\n",
       "   'smoother': 1,\n",
       "   'Higher': 1,\n",
       "   'Harder': 3,\n",
       "   'broker': 1,\n",
       "   'nicer': 1,\n",
       "   'lengthier': 1,\n",
       "   'Closer': 1,\n",
       "   'newer': 1,\n",
       "   'Lesser': 1,\n",
       "   'brighter': 1,\n",
       "   'keener': 1,\n",
       "   'liver': 1,\n",
       "   'Kinder': 1,\n",
       "   'Stranger': 1,\n",
       "   'tamer': 1},\n",
       "  'modal_adverbs.txt': {'actually': 298,\n",
       "   'allegedly': 61,\n",
       "   'truly': 108,\n",
       "   'likely': 180,\n",
       "   'sure': 233,\n",
       "   'clearly': 199,\n",
       "   'probably': 141,\n",
       "   'certainly': 64,\n",
       "   'Really': 23,\n",
       "   'Actually': 9,\n",
       "   'reportedly': 344,\n",
       "   'perhaps': 27,\n",
       "   'really': 336,\n",
       "   'obviously': 33,\n",
       "   'unfortunately': 30,\n",
       "   'Unfortunately': 111,\n",
       "   'Fortunately': 78,\n",
       "   'Perhaps': 38,\n",
       "   'technically': 3,\n",
       "   'Essentially': 23,\n",
       "   'Obviously': 12,\n",
       "   'Apparently': 69,\n",
       "   'definitely': 53,\n",
       "   'Certainly': 2,\n",
       "   'Clearly': 39,\n",
       "   'maybe': 48,\n",
       "   'arguably': 1,\n",
       "   'Maybe': 33,\n",
       "   'essentially': 31,\n",
       "   'apparently': 34,\n",
       "   'impossibly': 1,\n",
       "   'Reportedly': 32,\n",
       "   'Literally': 8,\n",
       "   'totally': 30,\n",
       "   'literally': 21,\n",
       "   'necessarily': 19,\n",
       "   'indeed': 18,\n",
       "   'Sure': 12,\n",
       "   'strictly': 9,\n",
       "   'surely': 11,\n",
       "   'Allegedly': 11,\n",
       "   'REALLY': 1,\n",
       "   'possibly': 14,\n",
       "   'noticeably': 17,\n",
       "   'Truly': 7,\n",
       "   'presumably': 2,\n",
       "   'Possibly': 2,\n",
       "   'seemingly': 6,\n",
       "   'Surely': 1,\n",
       "   'REPORTEDLY': 1,\n",
       "   'Evidently': 1,\n",
       "   'inevitably': 2,\n",
       "   'Likely': 9,\n",
       "   'undoubtedly': 5,\n",
       "   'fortunately': 2,\n",
       "   'Noticeably': 3,\n",
       "   'unnecessarily': 3,\n",
       "   'ostensibly': 1,\n",
       "   'statistically': 2,\n",
       "   'positively': 3,\n",
       "   'assuredly': 3,\n",
       "   'undeniably': 2,\n",
       "   'CLEARLY': 1,\n",
       "   'manifestly': 1,\n",
       "   'Technically': 1,\n",
       "   'Totally': 1,\n",
       "   'Undoubtedly': 1,\n",
       "   'Seemingly': 1,\n",
       "   'Unquestionably': 1,\n",
       "   'plainly': 1},\n",
       "  'act_adverbs.txt': {'deliberately': 9,\n",
       "   'carelessly': 3,\n",
       "   'carefully': 18,\n",
       "   'accidentally': 34,\n",
       "   'Accidentally': 13,\n",
       "   'freely': 8,\n",
       "   'cleverly': 1,\n",
       "   'Deliberately': 1},\n",
       "  'manner_adverbs.txt': {'deliberately': 9,\n",
       "   'well': 392,\n",
       "   'clearly': 199,\n",
       "   'simply': 146,\n",
       "   'differently': 15,\n",
       "   'frankly': 17,\n",
       "   'completely': 152,\n",
       "   'hard': 242,\n",
       "   'finally': 145,\n",
       "   'exactly': 122,\n",
       "   'honestly': 12,\n",
       "   'especially': 124,\n",
       "   'Unbelievably': 2,\n",
       "   'suspiciously': 3,\n",
       "   'carelessly': 3,\n",
       "   'equally': 12,\n",
       "   'Completely': 31,\n",
       "   'Understandably': 3,\n",
       "   'anyway': 12,\n",
       "   'quite': 99,\n",
       "   'Finally': 94,\n",
       "   'Well': 174,\n",
       "   'purely': 7,\n",
       "   'Clearly': 39,\n",
       "   'carefully': 18,\n",
       "   'incredibly': 26,\n",
       "   'seriously': 75,\n",
       "   'Likewise': 3,\n",
       "   'truthfully': 2,\n",
       "   'Thus': 7,\n",
       "   'thus': 17,\n",
       "   'accidentally': 34,\n",
       "   'Hard': 11,\n",
       "   'otherwise': 20,\n",
       "   'Accidentally': 13,\n",
       "   'Quite': 5,\n",
       "   'COMPLETELY': 2,\n",
       "   'consistently': 21,\n",
       "   'importantly': 10,\n",
       "   'noticeably': 17,\n",
       "   'profoundly': 3,\n",
       "   'horribly': 2,\n",
       "   'ironically': 1,\n",
       "   'Similarly': 4,\n",
       "   'Especially': 9,\n",
       "   'Ironically': 10,\n",
       "   'freely': 8,\n",
       "   'Honestly': 5,\n",
       "   'likewise': 2,\n",
       "   'sufficiently': 3,\n",
       "   'Exactly': 4,\n",
       "   'Anyway': 1,\n",
       "   'embarrassingly': 1,\n",
       "   'accordingly': 8,\n",
       "   'figuratively': 1,\n",
       "   'slightly': 7,\n",
       "   'Incredibly': 1,\n",
       "   'Accordingly': 1,\n",
       "   'Noticeably': 3,\n",
       "   'similarly': 2,\n",
       "   'FINALLY': 2,\n",
       "   'cleverly': 1,\n",
       "   'terminally': 2,\n",
       "   'Precisely': 1,\n",
       "   'Seriously': 5,\n",
       "   'precisely': 2,\n",
       "   'Incidentally': 1,\n",
       "   'unbelievably': 5,\n",
       "   'Simply': 2,\n",
       "   'positively': 3,\n",
       "   'Otherwise': 3,\n",
       "   'briefly': 5,\n",
       "   'Deliberately': 1,\n",
       "   'Frankly': 2,\n",
       "   'remarkably': 1,\n",
       "   'CLEARLY': 1,\n",
       "   'understandably': 2,\n",
       "   'habitually': 1,\n",
       "   'unwaveringly': 1},\n",
       "  'superlative_forms.txt': {'most': 546,\n",
       "   'largest': 45,\n",
       "   'Best': 27,\n",
       "   'best': 186,\n",
       "   'Most': 74,\n",
       "   'least': 146,\n",
       "   'worst': 67,\n",
       "   'biggest': 50,\n",
       "   'Bravest': 1,\n",
       "   'latest': 110,\n",
       "   'Worst': 29,\n",
       "   'greatest': 45,\n",
       "   'deepest': 8,\n",
       "   'darkest': 4,\n",
       "   'Happiest': 1,\n",
       "   'wealthiest': 3,\n",
       "   'nearest': 2,\n",
       "   'lowest': 11,\n",
       "   'happiest': 2,\n",
       "   'Biggest': 3,\n",
       "   'Latest': 9,\n",
       "   'saddest': 4,\n",
       "   'funniest': 5,\n",
       "   'fastest': 2,\n",
       "   'strongest': 11,\n",
       "   'smartest': 4,\n",
       "   'easiest': 1,\n",
       "   'hardest': 9,\n",
       "   'proudest': 1,\n",
       "   'Classiest': 1,\n",
       "   'highest': 28,\n",
       "   'Least': 5,\n",
       "   'closest': 10,\n",
       "   'longest': 2,\n",
       "   'busiest': 1,\n",
       "   'classiest': 1,\n",
       "   'horniest': 2,\n",
       "   'Longest': 1,\n",
       "   'oldest': 6,\n",
       "   'warmest': 1,\n",
       "   'sweetest': 1,\n",
       "   'Coldest': 1,\n",
       "   'strictest': 2,\n",
       "   'Largest': 6,\n",
       "   'loudest': 1,\n",
       "   'brightest': 1,\n",
       "   'finest': 2,\n",
       "   'Highest': 1,\n",
       "   'sexiest': 1,\n",
       "   'harshest': 1,\n",
       "   'squarest': 2,\n",
       "   'fullest': 3,\n",
       "   'truest': 1,\n",
       "   'dumbest': 3,\n",
       "   'newest': 5,\n",
       "   'Greatest': 2,\n",
       "   'weirdest': 1,\n",
       "   'scariest': 2,\n",
       "   'Cutest': 1,\n",
       "   'roughest': 1,\n",
       "   'slightest': 4,\n",
       "   'holiest': 1,\n",
       "   'toughest': 4,\n",
       "   'Youngest': 1,\n",
       "   'youngest': 4,\n",
       "   'Deadliest': 1,\n",
       "   'oddest': 1,\n",
       "   'craziest': 1,\n",
       "   'furthest': 1,\n",
       "   'weakest': 1,\n",
       "   'cruelest': 1,\n",
       "   'eldest': 1,\n",
       "   'shortest': 1,\n",
       "   'Toughest': 2,\n",
       "   'sickest': 1,\n",
       "   'hottest': 1,\n",
       "   'smallest': 1,\n",
       "   'Newest': 2,\n",
       "   'cheapest': 1,\n",
       "   'richest': 2,\n",
       "   'starkest': 1,\n",
       "   'clearest': 2,\n",
       "   'Lowest': 1}},\n",
       " 3: {'comparative_forms.txt': {'further': 976,\n",
       "   'worse': 637,\n",
       "   'Frontier': 70,\n",
       "   'number': 1531,\n",
       "   'bigger': 171,\n",
       "   'later': 642,\n",
       "   'Number': 43,\n",
       "   'Less': 32,\n",
       "   'less': 1124,\n",
       "   'higher': 628,\n",
       "   'better': 1175,\n",
       "   'safer': 104,\n",
       "   'Better': 69,\n",
       "   'weaker': 35,\n",
       "   'smaller': 167,\n",
       "   'lower': 396,\n",
       "   'earlier': 320,\n",
       "   'larger': 304,\n",
       "   'harder': 113,\n",
       "   'easier': 197,\n",
       "   'Further': 116,\n",
       "   'faster': 124,\n",
       "   'nimbler': 2,\n",
       "   'closer': 192,\n",
       "   'WORSE': 5,\n",
       "   'longer': 769,\n",
       "   'greater': 508,\n",
       "   'wider': 110,\n",
       "   'stronger': 91,\n",
       "   'heavier': 22,\n",
       "   'Worse': 40,\n",
       "   'older': 102,\n",
       "   'wealthier': 13,\n",
       "   'Earlier': 81,\n",
       "   'Higher': 27,\n",
       "   'healthier': 36,\n",
       "   'cheaper': 57,\n",
       "   'Later': 63,\n",
       "   'sooner': 92,\n",
       "   'clearer': 26,\n",
       "   'broker': 16,\n",
       "   'younger': 69,\n",
       "   'liver': 66,\n",
       "   'slower': 17,\n",
       "   'broader': 69,\n",
       "   'Buffer': 6,\n",
       "   'buffer': 71,\n",
       "   'deeper': 123,\n",
       "   'Easier': 6,\n",
       "   'richer': 27,\n",
       "   'elder': 9,\n",
       "   'Closer': 10,\n",
       "   'Warmer': 3,\n",
       "   'poorer': 38,\n",
       "   'lesser': 63,\n",
       "   'saner': 4,\n",
       "   'Dumber': 2,\n",
       "   'Lesser': 8,\n",
       "   'smarter': 34,\n",
       "   'fairer': 4,\n",
       "   'tighter': 22,\n",
       "   'Greater': 31,\n",
       "   'prettier': 1,\n",
       "   'cooler': 17,\n",
       "   'simpler': 19,\n",
       "   'nearer': 4,\n",
       "   'warmer': 15,\n",
       "   'drier': 2,\n",
       "   'darker': 26,\n",
       "   'FASTER': 1,\n",
       "   'plainer': 2,\n",
       "   'louder': 12,\n",
       "   'Safer': 5,\n",
       "   'lighter': 16,\n",
       "   'tougher': 22,\n",
       "   'nicer': 5,\n",
       "   'weirder': 4,\n",
       "   'greener': 9,\n",
       "   'happier': 12,\n",
       "   'quicker': 13,\n",
       "   'thinner': 6,\n",
       "   'finer': 7,\n",
       "   'crazier': 4,\n",
       "   'bolder': 3,\n",
       "   'smellier': 1,\n",
       "   'frontier': 8,\n",
       "   'shorter': 22,\n",
       "   'BETTER': 9,\n",
       "   'stricter': 14,\n",
       "   'looser': 2,\n",
       "   'Truer': 2,\n",
       "   'dryer': 8,\n",
       "   'heartier': 1,\n",
       "   'wiser': 10,\n",
       "   'freer': 7,\n",
       "   'Backer': 2,\n",
       "   'Tamer': 1,\n",
       "   'Wanner': 1,\n",
       "   'Sooner': 9,\n",
       "   'shallower': 2,\n",
       "   'SAFER': 3,\n",
       "   'sicker': 10,\n",
       "   'Deeper': 4,\n",
       "   'sharper': 2,\n",
       "   'grander': 6,\n",
       "   'NUMBER': 2,\n",
       "   'gooder': 1,\n",
       "   'farther': 15,\n",
       "   'busier': 2,\n",
       "   'cuddlier': 2,\n",
       "   'angrier': 4,\n",
       "   'hinder': 12,\n",
       "   'dumber': 7,\n",
       "   'gentler': 2,\n",
       "   'stranger': 24,\n",
       "   'Larger': 6,\n",
       "   'newer': 25,\n",
       "   'wearier': 1,\n",
       "   'smoother': 3,\n",
       "   'Darker': 1,\n",
       "   'Blinder': 7,\n",
       "   'fainter': 1,\n",
       "   'truer': 5,\n",
       "   'colder': 6,\n",
       "   'icier': 1,\n",
       "   'vaster': 2,\n",
       "   'brighter': 12,\n",
       "   'riskier': 3,\n",
       "   'softer': 4,\n",
       "   'keener': 1,\n",
       "   'Smaller': 8,\n",
       "   'gamer': 1,\n",
       "   'Longer': 10,\n",
       "   'hotter': 4,\n",
       "   'Stronger': 3,\n",
       "   'Fuller': 5,\n",
       "   'Sillier': 1,\n",
       "   'braver': 1,\n",
       "   'Butcher': 2,\n",
       "   'rougher': 2,\n",
       "   'Older': 5,\n",
       "   'creepier': 4,\n",
       "   'kinder': 2,\n",
       "   'Bigger': 7,\n",
       "   'uglier': 3,\n",
       "   'mightier': 2,\n",
       "   'commoner': 3,\n",
       "   'holier': 4,\n",
       "   'rasher': 1,\n",
       "   'fatter': 1,\n",
       "   'sticker': 3,\n",
       "   'denser': 2,\n",
       "   'cleaner': 20,\n",
       "   'Lower': 15,\n",
       "   'neater': 1,\n",
       "   'stupider': 2,\n",
       "   'scarier': 5,\n",
       "   'merrier': 2,\n",
       "   'Stricter': 2,\n",
       "   'BIGGER': 2,\n",
       "   'fuller': 4,\n",
       "   'graver': 2,\n",
       "   'HIGHER': 1,\n",
       "   'slicker': 3,\n",
       "   'Archer': 2,\n",
       "   'Cheaper': 1,\n",
       "   'Farther': 1,\n",
       "   'sweeter': 3,\n",
       "   'milder': 1,\n",
       "   'deadlier': 2,\n",
       "   'Scarier': 2,\n",
       "   'Newer': 2,\n",
       "   'whiter': 1,\n",
       "   'bummer': 1,\n",
       "   'Faster': 2,\n",
       "   'damper': 3,\n",
       "   'Thinner': 1,\n",
       "   'sneakier': 1,\n",
       "   'LATER': 1,\n",
       "   'badder': 1,\n",
       "   'Younger': 2,\n",
       "   'LOWER': 1,\n",
       "   'lazier': 1,\n",
       "   'Elder': 6,\n",
       "   'narrower': 1,\n",
       "   'murkier': 2,\n",
       "   'sturdier': 1,\n",
       "   'LESS': 2,\n",
       "   'gloomier': 2,\n",
       "   'Deadlier': 1,\n",
       "   'rarer': 1,\n",
       "   'Taller': 1,\n",
       "   'Saner': 1,\n",
       "   'sounder': 2,\n",
       "   'Harder': 2,\n",
       "   'Pinker': 2,\n",
       "   'bleaker': 1,\n",
       "   'deader': 1,\n",
       "   'sloppier': 1,\n",
       "   'slimmer': 2,\n",
       "   'huger': 1,\n",
       "   'backer': 3,\n",
       "   'loftier': 1,\n",
       "   'surer': 1,\n",
       "   'Tanner': 3,\n",
       "   'firmer': 5,\n",
       "   'briefer': 5,\n",
       "   'Odder': 1,\n",
       "   'solider': 1,\n",
       "   'straighter': 1,\n",
       "   'Ruder': 36,\n",
       "   'wilder': 1,\n",
       "   'costlier': 2,\n",
       "   'GREATER': 1,\n",
       "   'Sweeter': 1,\n",
       "   'camper': 2,\n",
       "   'thicker': 1,\n",
       "   'Simpler': 2,\n",
       "   'wetter': 1,\n",
       "   'dirtier': 1,\n",
       "   'Stranger': 1,\n",
       "   'dimmer': 1,\n",
       "   'odder': 1,\n",
       "   'cozier': 1,\n",
       "   'Louder': 2,\n",
       "   'Liver': 1,\n",
       "   'Smarter': 1,\n",
       "   'OLDER': 1,\n",
       "   'Broader': 1,\n",
       "   'Tougher': 1,\n",
       "   'nobler': 1,\n",
       "   'shinier': 1,\n",
       "   'steadier': 2,\n",
       "   'Healthier': 1,\n",
       "   'hardier': 2,\n",
       "   'fresher': 1,\n",
       "   'prouder': 1,\n",
       "   'trickier': 1,\n",
       "   'tastier': 1,\n",
       "   'tidier': 1,\n",
       "   'taller': 1,\n",
       "   'sadder': 1,\n",
       "   'shakier': 1,\n",
       "   'Weller': 2,\n",
       "   'starker': 1,\n",
       "   'Sounder': 1},\n",
       "  'modal_adverbs.txt': {'Perhaps': 362,\n",
       "   'Actually': 76,\n",
       "   'indeed': 377,\n",
       "   'maybe': 301,\n",
       "   'seemingly': 132,\n",
       "   'necessarily': 105,\n",
       "   'possibly': 301,\n",
       "   'probably': 583,\n",
       "   'Really': 91,\n",
       "   'really': 1568,\n",
       "   'sure': 760,\n",
       "   'Unfortunately': 450,\n",
       "   'actually': 1734,\n",
       "   'undoubtedly': 95,\n",
       "   'certainly': 465,\n",
       "   'surely': 125,\n",
       "   'essentially': 314,\n",
       "   'Literally': 19,\n",
       "   'perhaps': 559,\n",
       "   'obviously': 253,\n",
       "   'truly': 488,\n",
       "   'literally': 294,\n",
       "   'Probably': 185,\n",
       "   'presumably': 50,\n",
       "   'transparently': 12,\n",
       "   'reportedly': 185,\n",
       "   'likely': 1020,\n",
       "   'Possibly': 11,\n",
       "   'Clearly': 156,\n",
       "   'Indeed': 373,\n",
       "   'patently': 24,\n",
       "   'totally': 269,\n",
       "   'Maybe': 262,\n",
       "   'PROBABLY': 1,\n",
       "   'clearly': 573,\n",
       "   'allegedly': 243,\n",
       "   'Obviously': 103,\n",
       "   'ACTUALLY': 4,\n",
       "   'REALLY': 35,\n",
       "   'unfortunately': 103,\n",
       "   'Apparently': 151,\n",
       "   'PLAINLY': 1,\n",
       "   'Fortunately': 65,\n",
       "   'apparently': 401,\n",
       "   'Sure': 64,\n",
       "   'Truly': 20,\n",
       "   'Certainly': 44,\n",
       "   'inevitably': 82,\n",
       "   'scarcely': 26,\n",
       "   'Surely': 44,\n",
       "   'definitely': 181,\n",
       "   'ostensibly': 39,\n",
       "   'noticeably': 4,\n",
       "   'statistically': 18,\n",
       "   'Undoubtedly': 9,\n",
       "   'unquestionably': 19,\n",
       "   'Totally': 18,\n",
       "   'technically': 41,\n",
       "   'credibly': 4,\n",
       "   'Allegedly': 9,\n",
       "   'arguably': 34,\n",
       "   'strictly': 37,\n",
       "   'unnecessarily': 10,\n",
       "   'MAYBE': 3,\n",
       "   'conditionally': 1,\n",
       "   'DEFINITELY': 5,\n",
       "   'Undeniably': 3,\n",
       "   'Essentially': 53,\n",
       "   'conceivably': 12,\n",
       "   'Likely': 11,\n",
       "   'inescapably': 2,\n",
       "   'needlessly': 11,\n",
       "   'loosely': 21,\n",
       "   'TOTALLY': 2,\n",
       "   'Reportedly': 10,\n",
       "   'LITERALLY': 2,\n",
       "   'Indisputably': 1,\n",
       "   'plainly': 17,\n",
       "   'positively': 23,\n",
       "   'assuredly': 14,\n",
       "   'purportedly': 17,\n",
       "   'doubtlessly': 2,\n",
       "   'doubtless': 5,\n",
       "   'Statistically': 2,\n",
       "   'Definitely': 10,\n",
       "   'undeniably': 7,\n",
       "   'evidently': 11,\n",
       "   'fortunately': 9,\n",
       "   'Seemingly': 3,\n",
       "   'Presumably': 11,\n",
       "   'Inevitably': 2,\n",
       "   'putatively': 2,\n",
       "   'SURE': 2,\n",
       "   'APPARENTLY': 1,\n",
       "   'unavoidably': 2,\n",
       "   'Ostensibly': 3,\n",
       "   'Doubtless': 1,\n",
       "   'Technically': 9,\n",
       "   'Doubtlessly': 1,\n",
       "   'presumptively': 1,\n",
       "   'Evidently': 9,\n",
       "   'hypothetically': 4,\n",
       "   'impossibly': 1,\n",
       "   'AFAIK': 1,\n",
       "   'unarguably': 1,\n",
       "   'Arguably': 1,\n",
       "   'Unquestionably': 1,\n",
       "   'Plainly': 1,\n",
       "   'Patently': 1,\n",
       "   'Hypothetically': 2,\n",
       "   'verifiably': 1,\n",
       "   'TRULY': 3,\n",
       "   'POSSIBLY': 1,\n",
       "   'manifestly': 2,\n",
       "   'CLEARLY': 2,\n",
       "   'indubitably': 1,\n",
       "   'LIKELY': 1,\n",
       "   'SEEMINGLY': 1,\n",
       "   'CERTAINLY': 1,\n",
       "   'INDEED': 1,\n",
       "   'Purportedly': 1},\n",
       "  'act_adverbs.txt': {'accidentally': 39,\n",
       "   'freely': 184,\n",
       "   'carefully': 138,\n",
       "   'cleverly': 19,\n",
       "   'deliberately': 117,\n",
       "   'Carefully': 5,\n",
       "   'carelessly': 8,\n",
       "   'Accidentally': 5,\n",
       "   'Deliberately': 3,\n",
       "   'foolishly': 13,\n",
       "   'ACCIDENTALLY': 1,\n",
       "   'discreetly': 3},\n",
       "  'manner_adverbs.txt': {'accordingly': 26,\n",
       "   'importantly': 75,\n",
       "   'accidentally': 39,\n",
       "   'hard': 741,\n",
       "   'Well': 647,\n",
       "   'freely': 184,\n",
       "   'well': 3259,\n",
       "   'exactly': 569,\n",
       "   'Finally': 147,\n",
       "   'sufficiently': 42,\n",
       "   'carefully': 138,\n",
       "   'staggeringly': 2,\n",
       "   'simply': 974,\n",
       "   'quite': 616,\n",
       "   'otherwise': 342,\n",
       "   'thus': 485,\n",
       "   'especially': 721,\n",
       "   'Thus': 249,\n",
       "   'completely': 606,\n",
       "   'Similarly': 37,\n",
       "   'Clearly': 156,\n",
       "   'similarly': 54,\n",
       "   'finally': 357,\n",
       "   'anyway': 199,\n",
       "   'purely': 51,\n",
       "   'SERIOUSLY': 2,\n",
       "   'consistently': 94,\n",
       "   'clearly': 573,\n",
       "   'Hard': 37,\n",
       "   'cleverly': 19,\n",
       "   'seriously': 224,\n",
       "   'Exactly': 42,\n",
       "   'Seriously': 36,\n",
       "   'equally': 93,\n",
       "   'ironically': 31,\n",
       "   'precisely': 124,\n",
       "   'deliberately': 117,\n",
       "   'terminally': 4,\n",
       "   'Likewise': 83,\n",
       "   'incidentally': 12,\n",
       "   'differently': 35,\n",
       "   'Simply': 44,\n",
       "   'incredibly': 119,\n",
       "   'Frankly': 21,\n",
       "   'economically': 47,\n",
       "   'strikingly': 5,\n",
       "   'noticeably': 4,\n",
       "   'Otherwise': 43,\n",
       "   'profoundly': 34,\n",
       "   'likewise': 51,\n",
       "   'WELL': 21,\n",
       "   'remarkably': 18,\n",
       "   'Quite': 27,\n",
       "   'habitually': 5,\n",
       "   'Especially': 38,\n",
       "   'briefly': 42,\n",
       "   'Incidentally': 17,\n",
       "   'Carefully': 5,\n",
       "   'Precisely': 3,\n",
       "   'Ironically': 60,\n",
       "   'Understandably': 4,\n",
       "   'EXACTLY': 8,\n",
       "   'Honestly': 19,\n",
       "   'slightly': 88,\n",
       "   'Anyway': 23,\n",
       "   'honestly': 37,\n",
       "   'centrally': 14,\n",
       "   'Incredibly': 13,\n",
       "   'deservedly': 3,\n",
       "   'unbelievably': 17,\n",
       "   'metaphorically': 5,\n",
       "   'carelessly': 8,\n",
       "   'ESPECIALLY': 1,\n",
       "   'Equally': 6,\n",
       "   'positively': 23,\n",
       "   'Economically': 5,\n",
       "   'Completely': 13,\n",
       "   'figuratively': 7,\n",
       "   'frankly': 26,\n",
       "   'suspiciously': 12,\n",
       "   'embarrassingly': 4,\n",
       "   'Alarmingly': 4,\n",
       "   'Accidentally': 5,\n",
       "   'horribly': 21,\n",
       "   'Deliberately': 3,\n",
       "   'Remarkably': 3,\n",
       "   'foolishly': 13,\n",
       "   'Accordingly': 4,\n",
       "   'understandably': 12,\n",
       "   'vicariously': 5,\n",
       "   'COMPLETELY': 7,\n",
       "   'Briefly': 2,\n",
       "   'pleasantly': 4,\n",
       "   'truthfully': 7,\n",
       "   'ACCIDENTALLY': 1,\n",
       "   'alarmingly': 6,\n",
       "   'anyhow': 3,\n",
       "   'Importantly': 2,\n",
       "   'alphabetically': 2,\n",
       "   'procedurally': 1,\n",
       "   'HARD': 2,\n",
       "   'summarily': 6,\n",
       "   'discreetly': 3,\n",
       "   'DIFFERENTLY': 1,\n",
       "   'Truthfully': 1,\n",
       "   'Consistently': 1,\n",
       "   'epidemically': 1,\n",
       "   'Figuratively': 1,\n",
       "   'Anyhow': 3,\n",
       "   'Slightly': 1,\n",
       "   'chronologically': 2,\n",
       "   'CLEARLY': 2,\n",
       "   'PRECISELY': 1,\n",
       "   'QUITE': 1,\n",
       "   'SIMPLY': 1,\n",
       "   'hideously': 1,\n",
       "   'ANYWAY': 1,\n",
       "   'HONESTLY': 1,\n",
       "   'Centrally': 1},\n",
       "  'superlative_forms.txt': {'most': 3590,\n",
       "   'biggest': 319,\n",
       "   'Most': 576,\n",
       "   'least': 1312,\n",
       "   'worst': 402,\n",
       "   'best': 945,\n",
       "   'latest': 578,\n",
       "   'newest': 33,\n",
       "   'greatest': 293,\n",
       "   'MOST': 20,\n",
       "   'lowest': 101,\n",
       "   'slightest': 23,\n",
       "   'largest': 491,\n",
       "   'nicest': 1,\n",
       "   'highest': 293,\n",
       "   'wealthiest': 36,\n",
       "   'poorest': 45,\n",
       "   'truest': 3,\n",
       "   'strictest': 11,\n",
       "   'fastest': 18,\n",
       "   'LEAST': 3,\n",
       "   'easiest': 29,\n",
       "   'slipperiest': 3,\n",
       "   'richest': 44,\n",
       "   'Best': 62,\n",
       "   'longest': 22,\n",
       "   'nearest': 17,\n",
       "   'simplest': 16,\n",
       "   'brightest': 6,\n",
       "   'gravest': 6,\n",
       "   'cheapest': 9,\n",
       "   'Fittest': 1,\n",
       "   'finest': 18,\n",
       "   'proudest': 2,\n",
       "   'sternest': 2,\n",
       "   'warmest': 10,\n",
       "   'funniest': 2,\n",
       "   'oldest': 19,\n",
       "   'PUREST': 1,\n",
       "   'deepest': 10,\n",
       "   'basest': 3,\n",
       "   'lowliest': 2,\n",
       "   'safest': 17,\n",
       "   'youngest': 18,\n",
       "   'mildest': 2,\n",
       "   'thinnest': 1,\n",
       "   'surest': 3,\n",
       "   'smallest': 27,\n",
       "   'fittest': 9,\n",
       "   'strongest': 36,\n",
       "   'harshest': 5,\n",
       "   'Greatest': 17,\n",
       "   'fullest': 14,\n",
       "   'narrowest': 1,\n",
       "   'busiest': 2,\n",
       "   'straightest': 1,\n",
       "   'earliest': 15,\n",
       "   'tawdriest': 1,\n",
       "   'Latest': 17,\n",
       "   'weakest': 12,\n",
       "   'loudest': 6,\n",
       "   'quickest': 2,\n",
       "   'rawest': 1,\n",
       "   'healthiest': 16,\n",
       "   'kindest': 3,\n",
       "   'costliest': 1,\n",
       "   'sickest': 2,\n",
       "   'shortest': 1,\n",
       "   'wisest': 3,\n",
       "   'freakiest': 1,\n",
       "   'Highest': 8,\n",
       "   'direst': 2,\n",
       "   'Biggest': 11,\n",
       "   'eldest': 6,\n",
       "   'Worst': 28,\n",
       "   'darkest': 12,\n",
       "   'driest': 5,\n",
       "   'smartest': 3,\n",
       "   'hardest': 19,\n",
       "   'tiniest': 7,\n",
       "   'laziest': 1,\n",
       "   'barest': 2,\n",
       "   'slowest': 5,\n",
       "   'sloppiest': 1,\n",
       "   'lightest': 3,\n",
       "   'closest': 43,\n",
       "   'deadliest': 8,\n",
       "   'dumbest': 3,\n",
       "   'Longest': 3,\n",
       "   'slimiest': 1,\n",
       "   'Deadliest': 6,\n",
       "   'baldest': 1,\n",
       "   'Hardest': 2,\n",
       "   'Smallest': 1,\n",
       "   'haziest': 1,\n",
       "   'Fastest': 2,\n",
       "   'hottest': 8,\n",
       "   'crudest': 1,\n",
       "   'coolest': 4,\n",
       "   'saddest': 8,\n",
       "   'noblest': 1,\n",
       "   'Wackiest': 1,\n",
       "   'Least': 4,\n",
       "   'bravest': 4,\n",
       "   'Largest': 14,\n",
       "   'sharpest': 5,\n",
       "   'Lowest': 3,\n",
       "   'scariest': 4,\n",
       "   'widest': 2,\n",
       "   'sanest': 1,\n",
       "   'rarest': 2,\n",
       "   'Bestest': 1,\n",
       "   'dirtiest': 6,\n",
       "   'flimsiest': 2,\n",
       "   'heartiest': 1,\n",
       "   'farthest': 1,\n",
       "   'wildest': 4,\n",
       "   'purest': 3,\n",
       "   'staunchest': 2,\n",
       "   'furthest': 3,\n",
       "   'filthiest': 1,\n",
       "   'dimmest': 2,\n",
       "   'damndest': 1,\n",
       "   'creepiest': 3,\n",
       "   'scarcest': 1,\n",
       "   'Strongest': 1,\n",
       "   'BEST': 6,\n",
       "   'nastiest': 1,\n",
       "   'cleverest': 1,\n",
       "   'oddest': 2,\n",
       "   'Densest': 1,\n",
       "   'tallest': 3,\n",
       "   'whitest': 1,\n",
       "   'stingiest': 1,\n",
       "   'happiest': 1,\n",
       "   'heaviest': 5,\n",
       "   'toughest': 5,\n",
       "   'grandest': 2,\n",
       "   'neediest': 1,\n",
       "   'riskiest': 1,\n",
       "   'LOWEST': 1,\n",
       "   'coldest': 3,\n",
       "   'tastiest': 2,\n",
       "   'weirdest': 2,\n",
       "   'MOSTEST': 1,\n",
       "   'thickest': 1,\n",
       "   'boldest': 2,\n",
       "   'clearest': 7,\n",
       "   'broadest': 3,\n",
       "   'Youngest': 1,\n",
       "   'friendliest': 1,\n",
       "   'hastiest': 1,\n",
       "   'meanest': 2,\n",
       "   'Saddest': 1,\n",
       "   'dullest': 1,\n",
       "   'brownest': 1,\n",
       "   'likeliest': 1,\n",
       "   'vaguest': 1,\n",
       "   'stupidest': 2,\n",
       "   'Hottest': 2,\n",
       "   'densest': 2,\n",
       "   'ugliest': 2,\n",
       "   'minutest': 1,\n",
       "   'wettest': 1,\n",
       "   'Funniest': 1,\n",
       "   'Newest': 2,\n",
       "   'BIGGEST': 1,\n",
       "   'humblest': 1,\n",
       "   'Freest': 2,\n",
       "   'loosest': 1,\n",
       "   'silliest': 1,\n",
       "   'faintest': 1,\n",
       "   'fairest': 1,\n",
       "   'Poorest': 1,\n",
       "   'sweetest': 1,\n",
       "   'bloodiest': 2,\n",
       "   'holiest': 1,\n",
       "   'damnedest': 1,\n",
       "   'SICKEST': 1,\n",
       "   'fiercest': 2,\n",
       "   'steepest': 1,\n",
       "   'stanchest': 1,\n",
       "   'foulest': 1,\n",
       "   'HIGHEST': 1,\n",
       "   'freest': 2,\n",
       "   'blindest': 1,\n",
       "   'mightiest': 1,\n",
       "   'Closest': 1,\n",
       "   'dearest': 1}},\n",
       " 4: {'comparative_forms.txt': {'later': 607,\n",
       "   'better': 616,\n",
       "   'Earlier': 89,\n",
       "   'earlier': 504,\n",
       "   'higher': 385,\n",
       "   'less': 666,\n",
       "   'lower': 321,\n",
       "   'bigger': 109,\n",
       "   'larger': 126,\n",
       "   'Later': 49,\n",
       "   'number': 774,\n",
       "   'broader': 76,\n",
       "   'easier': 78,\n",
       "   'further': 398,\n",
       "   'older': 116,\n",
       "   'smaller': 114,\n",
       "   'greater': 145,\n",
       "   'thinner': 5,\n",
       "   'stronger': 98,\n",
       "   'tougher': 50,\n",
       "   'slimmer': 3,\n",
       "   'gaudier': 1,\n",
       "   'younger': 98,\n",
       "   'cheaper': 33,\n",
       "   'shorter': 17,\n",
       "   'punchier': 1,\n",
       "   'longer': 229,\n",
       "   'farther': 15,\n",
       "   'heavier': 13,\n",
       "   'deeper': 40,\n",
       "   'closer': 116,\n",
       "   'worse': 103,\n",
       "   'flatter': 2,\n",
       "   'faster': 59,\n",
       "   'costlier': 3,\n",
       "   'poorer': 11,\n",
       "   'Stronger': 1,\n",
       "   'Broader': 3,\n",
       "   'Sooner': 1,\n",
       "   'looser': 6,\n",
       "   'woolier': 1,\n",
       "   'harder': 83,\n",
       "   'lesser': 20,\n",
       "   'newer': 13,\n",
       "   'Number': 5,\n",
       "   'Less': 9,\n",
       "   'stiffer': 3,\n",
       "   'tighter': 16,\n",
       "   'wider': 40,\n",
       "   'Further': 13,\n",
       "   'Wilder': 2,\n",
       "   'Younger': 2,\n",
       "   'rounder': 6,\n",
       "   'weaker': 29,\n",
       "   'fuzzier': 1,\n",
       "   'backer': 4,\n",
       "   'drearier': 2,\n",
       "   'duskier': 1,\n",
       "   'grimmer': 1,\n",
       "   'straighter': 1,\n",
       "   'Newer': 1,\n",
       "   'lighter': 23,\n",
       "   'elder': 26,\n",
       "   'tinier': 2,\n",
       "   'sturdier': 1,\n",
       "   'buffer': 4,\n",
       "   'clearer': 14,\n",
       "   'sloppier': 1,\n",
       "   'Safer': 1,\n",
       "   'Lower': 12,\n",
       "   'Older': 2,\n",
       "   'taller': 3,\n",
       "   'safer': 21,\n",
       "   'Greater': 9,\n",
       "   'Frontier': 43,\n",
       "   'Worse': 6,\n",
       "   'Lighter': 1,\n",
       "   'cooler': 12,\n",
       "   'gentler': 4,\n",
       "   'stricter': 16,\n",
       "   'broker': 24,\n",
       "   'sooner': 29,\n",
       "   'warmer': 7,\n",
       "   'darker': 5,\n",
       "   'Better': 20,\n",
       "   'brighter': 9,\n",
       "   'slower': 20,\n",
       "   'Higher': 8,\n",
       "   'angrier': 1,\n",
       "   'stranger': 12,\n",
       "   'deadlier': 3,\n",
       "   'doper': 1,\n",
       "   'narrower': 6,\n",
       "   'quicker': 14,\n",
       "   'friendlier': 1,\n",
       "   'greener': 1,\n",
       "   'cleaner': 12,\n",
       "   'gloomier': 1,\n",
       "   'hotter': 5,\n",
       "   'firmer': 6,\n",
       "   'fresher': 2,\n",
       "   'Smaller': 3,\n",
       "   'healthier': 7,\n",
       "   'Lesser': 6,\n",
       "   'sharper': 3,\n",
       "   'hinder': 9,\n",
       "   'rarer': 2,\n",
       "   'leaner': 6,\n",
       "   'blander': 1,\n",
       "   'louder': 5,\n",
       "   'splashier': 2,\n",
       "   'liver': 6,\n",
       "   'colder': 2,\n",
       "   'Closer': 1,\n",
       "   'grittier': 5,\n",
       "   'blunter': 1,\n",
       "   'lonelier': 1,\n",
       "   'flashier': 1,\n",
       "   'riskier': 3,\n",
       "   'sticker': 12,\n",
       "   'dryer': 1,\n",
       "   'Archer': 2,\n",
       "   'wealthier': 4,\n",
       "   'tamer': 3,\n",
       "   'bolder': 7,\n",
       "   'Browner': 1,\n",
       "   'gamer': 2,\n",
       "   'frontier': 8,\n",
       "   'fuller': 3,\n",
       "   'smarter': 12,\n",
       "   'subtler': 1,\n",
       "   'livelier': 1,\n",
       "   'hardier': 1,\n",
       "   'tanner': 1,\n",
       "   'scruffier': 2,\n",
       "   'sillier': 1,\n",
       "   'shyer': 1,\n",
       "   'steeper': 3,\n",
       "   'richer': 7,\n",
       "   'Fuller': 8,\n",
       "   'Cooler': 1,\n",
       "   'simpler': 10,\n",
       "   'nicer': 3,\n",
       "   'damper': 3,\n",
       "   'Weller': 1,\n",
       "   'tidier': 1,\n",
       "   'fairer': 4,\n",
       "   'curiouser': 2,\n",
       "   'Stiller': 4,\n",
       "   'graver': 1,\n",
       "   'nearer': 4,\n",
       "   'bloodier': 1,\n",
       "   'sicker': 4,\n",
       "   'calmer': 3,\n",
       "   'happier': 6,\n",
       "   'duller': 1,\n",
       "   'Dumber': 1,\n",
       "   'Heavier': 1,\n",
       "   'meaner': 3,\n",
       "   'Elder': 3,\n",
       "   'rowdier': 1,\n",
       "   'smoother': 2,\n",
       "   'freer': 3,\n",
       "   'Butcher': 3,\n",
       "   'fitter': 1,\n",
       "   'Smarter': 1,\n",
       "   'prettier': 1,\n",
       "   'deader': 1,\n",
       "   'saltier': 1,\n",
       "   'butcher': 4,\n",
       "   'Cheaper': 2,\n",
       "   'wiser': 2,\n",
       "   'trimmer': 1,\n",
       "   'wilder': 2,\n",
       "   'emptier': 1,\n",
       "   'sounder': 1,\n",
       "   'kinder': 2,\n",
       "   'brisker': 1,\n",
       "   'fluffier': 1,\n",
       "   'Rainier': 1,\n",
       "   'funnier': 1,\n",
       "   'Larger': 3,\n",
       "   'Tangier': 1,\n",
       "   'pricier': 1,\n",
       "   'nastier': 1,\n",
       "   'uglier': 2,\n",
       "   'wearier': 1,\n",
       "   'crisper': 1,\n",
       "   'Farther': 2,\n",
       "   'scarcer': 1,\n",
       "   'finer': 1,\n",
       "   'Stranger': 2,\n",
       "   'Colder': 1,\n",
       "   'Bigger': 1,\n",
       "   'camper': 1,\n",
       "   'noisier': 1,\n",
       "   'bulgier': 1,\n",
       "   'warier': 1,\n",
       "   'thicker': 2,\n",
       "   'starker': 1,\n",
       "   'braver': 1,\n",
       "   'bluer': 1,\n",
       "   'softer': 4,\n",
       "   'frumpier': 1,\n",
       "   'heftier': 1,\n",
       "   'speedier': 1,\n",
       "   'murkier': 1,\n",
       "   'Keener': 1,\n",
       "   'steadier': 1,\n",
       "   'cheerier': 1,\n",
       "   'fainter': 1,\n",
       "   'Bossier': 2,\n",
       "   'Longer': 2,\n",
       "   'skinnier': 1,\n",
       "   'Sleeker': 1,\n",
       "   'odder': 1,\n",
       "   'sleeker': 1,\n",
       "   'duffer': 1,\n",
       "   'fiercer': 1,\n",
       "   'Louder': 1,\n",
       "   'plainer': 1,\n",
       "   'quieter': 1,\n",
       "   'wetter': 1,\n",
       "   'slicker': 1,\n",
       "   'LESSER': 1,\n",
       "   'SMALLER': 1,\n",
       "   'sexier': 1,\n",
       "   'milder': 1,\n",
       "   'dirtier': 1},\n",
       "  'modal_adverbs.txt': {'allegedly': 74,\n",
       "   'certainly': 120,\n",
       "   'likely': 441,\n",
       "   'really': 551,\n",
       "   'totally': 44,\n",
       "   'sure': 252,\n",
       "   'apparently': 75,\n",
       "   'clearly': 91,\n",
       "   'Clearly': 13,\n",
       "   'probably': 264,\n",
       "   'truly': 54,\n",
       "   'Maybe': 71,\n",
       "   'strictly': 21,\n",
       "   'obviously': 33,\n",
       "   'inevitably': 13,\n",
       "   'maybe': 114,\n",
       "   'assuredly': 1,\n",
       "   'actually': 194,\n",
       "   'Indeed': 30,\n",
       "   'Totally': 3,\n",
       "   'essentially': 58,\n",
       "   'indeed': 33,\n",
       "   'necessarily': 47,\n",
       "   'surely': 22,\n",
       "   'arguably': 16,\n",
       "   'perhaps': 151,\n",
       "   'possibly': 73,\n",
       "   'seemingly': 44,\n",
       "   'Unfortunately': 26,\n",
       "   'positively': 9,\n",
       "   'purportedly': 6,\n",
       "   'reportedly': 71,\n",
       "   'technically': 17,\n",
       "   'Actually': 18,\n",
       "   'plainly': 4,\n",
       "   'unfortunately': 12,\n",
       "   'Perhaps': 55,\n",
       "   'Sure': 23,\n",
       "   'Apparently': 16,\n",
       "   'definitely': 78,\n",
       "   'scarcely': 4,\n",
       "   'unquestionably': 2,\n",
       "   'Obviously': 28,\n",
       "   'undoubtedly': 13,\n",
       "   'Certainly': 18,\n",
       "   'presumably': 10,\n",
       "   'Fortunately': 11,\n",
       "   'Definitely': 2,\n",
       "   'Essentially': 3,\n",
       "   'Technically': 2,\n",
       "   'Really': 15,\n",
       "   'ostensibly': 5,\n",
       "   'literally': 16,\n",
       "   'unnecessarily': 4,\n",
       "   'undeniably': 4,\n",
       "   'statistically': 5,\n",
       "   'fortunately': 2,\n",
       "   'Literally': 2,\n",
       "   'Probably': 1,\n",
       "   'noticeably': 2,\n",
       "   'loosely': 5,\n",
       "   'Possibly': 4,\n",
       "   'Likely': 2,\n",
       "   'Inevitably': 2,\n",
       "   'credibly': 2,\n",
       "   'doubtless': 1,\n",
       "   'Presumably': 2,\n",
       "   'Surely': 7,\n",
       "   'impossibly': 1,\n",
       "   'unavoidably': 2,\n",
       "   'evidently': 6,\n",
       "   'needlessly': 1,\n",
       "   'transparently': 2,\n",
       "   'Seemingly': 2,\n",
       "   'conditionally': 1,\n",
       "   'conceivably': 1,\n",
       "   'reputedly': 1,\n",
       "   'believably': 1,\n",
       "   'Hypothetically': 1,\n",
       "   'Undoubtedly': 1,\n",
       "   'manifestly': 1,\n",
       "   'Ostensibly': 2,\n",
       "   'REALLY': 1},\n",
       "  'act_adverbs.txt': {'foolishly': 1,\n",
       "   'deliberately': 26,\n",
       "   'carefully': 58,\n",
       "   'accidentally': 8,\n",
       "   'freely': 27,\n",
       "   'delicately': 2,\n",
       "   'Carefully': 2,\n",
       "   'discreetly': 4,\n",
       "   'cleverly': 1},\n",
       "  'manner_adverbs.txt': {'well': 1214,\n",
       "   'Well': 60,\n",
       "   'hard': 437,\n",
       "   'finally': 131,\n",
       "   'especially': 300,\n",
       "   'completely': 82,\n",
       "   'simply': 155,\n",
       "   'purely': 12,\n",
       "   'clearly': 91,\n",
       "   'Clearly': 13,\n",
       "   'slightly': 111,\n",
       "   'Simply': 3,\n",
       "   'centrally': 4,\n",
       "   'Thus': 16,\n",
       "   'importantly': 11,\n",
       "   'otherwise': 58,\n",
       "   'similarly': 18,\n",
       "   'Exactly': 3,\n",
       "   'sufficiently': 8,\n",
       "   'likewise': 8,\n",
       "   'anyway': 37,\n",
       "   'consistently': 36,\n",
       "   'exactly': 97,\n",
       "   'briefly': 55,\n",
       "   'thus': 65,\n",
       "   'Frankly': 6,\n",
       "   'quite': 141,\n",
       "   'seriously': 108,\n",
       "   'frankly': 16,\n",
       "   'Likewise': 8,\n",
       "   'Hard': 6,\n",
       "   'positively': 9,\n",
       "   'suspiciously': 3,\n",
       "   'incredibly': 18,\n",
       "   'differently': 30,\n",
       "   'Similarly': 14,\n",
       "   'equally': 29,\n",
       "   'foolishly': 1,\n",
       "   'Especially': 8,\n",
       "   'deliberately': 26,\n",
       "   'understandably': 6,\n",
       "   'carefully': 58,\n",
       "   'accidentally': 8,\n",
       "   'Finally': 33,\n",
       "   'pleasantly': 5,\n",
       "   'honestly': 10,\n",
       "   'Otherwise': 22,\n",
       "   'profoundly': 4,\n",
       "   'freely': 27,\n",
       "   'precisely': 17,\n",
       "   'ironically': 6,\n",
       "   'Ironically': 4,\n",
       "   'Accordingly': 3,\n",
       "   'Slightly': 1,\n",
       "   'remarkably': 14,\n",
       "   'economically': 13,\n",
       "   'Equally': 4,\n",
       "   'delicately': 2,\n",
       "   'strikingly': 6,\n",
       "   'noticeably': 2,\n",
       "   'accordingly': 9,\n",
       "   'unbelievably': 2,\n",
       "   'Seriously': 3,\n",
       "   'Carefully': 2,\n",
       "   'habitually': 1,\n",
       "   'Honestly': 3,\n",
       "   'Anyway': 6,\n",
       "   'Incredibly': 1,\n",
       "   'Incidentally': 2,\n",
       "   'BRIEFLY': 1,\n",
       "   'discreetly': 4,\n",
       "   'horribly': 1,\n",
       "   'anyhow': 1,\n",
       "   'Customarily': 1,\n",
       "   'Economically': 2,\n",
       "   'mordantly': 1,\n",
       "   'Consistently': 1,\n",
       "   'Unbelievably': 1,\n",
       "   'deservedly': 2,\n",
       "   'chronologically': 2,\n",
       "   'incidentally': 2,\n",
       "   'customarily': 1,\n",
       "   'Quite': 5,\n",
       "   'truthfully': 2,\n",
       "   'cleverly': 1,\n",
       "   'Precisely': 1,\n",
       "   'WELL': 1,\n",
       "   'alarmingly': 1,\n",
       "   'embarrassingly': 1,\n",
       "   'summarily': 1,\n",
       "   'staggeringly': 1},\n",
       "  'superlative_forms.txt': {'saddest': 1,\n",
       "   'largest': 412,\n",
       "   'most': 1554,\n",
       "   'latest': 270,\n",
       "   'best': 700,\n",
       "   'biggest': 322,\n",
       "   'toughest': 29,\n",
       "   'least': 687,\n",
       "   'busiest': 11,\n",
       "   'tallest': 6,\n",
       "   'freest': 4,\n",
       "   'gentlest': 1,\n",
       "   'worst': 188,\n",
       "   'newest': 13,\n",
       "   'longest': 26,\n",
       "   'highest': 200,\n",
       "   'lowest': 68,\n",
       "   'greatest': 62,\n",
       "   'winningest': 1,\n",
       "   'Most': 210,\n",
       "   'fastest': 26,\n",
       "   'nearest': 7,\n",
       "   'strongest': 34,\n",
       "   'oldest': 39,\n",
       "   'smallest': 23,\n",
       "   'hardest': 30,\n",
       "   'proudest': 3,\n",
       "   'poorest': 13,\n",
       "   'richest': 18,\n",
       "   'hottest': 7,\n",
       "   'holiest': 9,\n",
       "   'weakest': 5,\n",
       "   'youngest': 35,\n",
       "   'deepest': 20,\n",
       "   'purest': 3,\n",
       "   'Toughest': 1,\n",
       "   'darkest': 6,\n",
       "   'earliest': 19,\n",
       "   'widest': 1,\n",
       "   'simplest': 1,\n",
       "   'cheapest': 6,\n",
       "   'scariest': 2,\n",
       "   'Biggest': 8,\n",
       "   'loveliest': 1,\n",
       "   'neediest': 1,\n",
       "   'Worst': 6,\n",
       "   'deadliest': 19,\n",
       "   'coolest': 3,\n",
       "   'wealthiest': 13,\n",
       "   'wildest': 2,\n",
       "   'closest': 27,\n",
       "   'Best': 47,\n",
       "   'unlikeliest': 1,\n",
       "   'brightest': 3,\n",
       "   'clearest': 5,\n",
       "   'quickest': 4,\n",
       "   'heaviest': 7,\n",
       "   'stiffest': 2,\n",
       "   'easiest': 8,\n",
       "   'smoothest': 2,\n",
       "   'finest': 5,\n",
       "   'quietest': 2,\n",
       "   'thorniest': 4,\n",
       "   'sharpest': 3,\n",
       "   'Greatest': 4,\n",
       "   'smartest': 5,\n",
       "   'fullest': 2,\n",
       "   'oddest': 1,\n",
       "   'steepest': 6,\n",
       "   'slightest': 4,\n",
       "   'fiercest': 3,\n",
       "   'coldest': 2,\n",
       "   'bloodiest': 7,\n",
       "   'eldest': 10,\n",
       "   'calmest': 1,\n",
       "   'cleanest': 2,\n",
       "   'slowest': 3,\n",
       "   'happiest': 7,\n",
       "   'safest': 9,\n",
       "   'starkest': 3,\n",
       "   'kindest': 1,\n",
       "   'loudest': 1,\n",
       "   'softest': 1,\n",
       "   'tamest': 1,\n",
       "   'breeziest': 1,\n",
       "   'craziest': 1,\n",
       "   'slimmest': 1,\n",
       "   'LEAST': 4,\n",
       "   'silliest': 1,\n",
       "   'broadest': 9,\n",
       "   'greenest': 1,\n",
       "   'angriest': 1,\n",
       "   'fakest': 1,\n",
       "   'strangest': 2,\n",
       "   'funnest': 1,\n",
       "   'surest': 2,\n",
       "   'bravest': 1,\n",
       "   'densest': 1,\n",
       "   'rawest': 1,\n",
       "   'fittest': 3,\n",
       "   'remotest': 1,\n",
       "   'sickest': 1,\n",
       "   'slyest': 1,\n",
       "   'cagiest': 1,\n",
       "   'baddest': 1,\n",
       "   'freshest': 1,\n",
       "   'soonest': 1,\n",
       "   'barest': 1,\n",
       "   'sweetest': 1,\n",
       "   'plumpest': 1,\n",
       "   'keenest': 1,\n",
       "   'healthiest': 1,\n",
       "   'tiniest': 2,\n",
       "   'sternest': 1,\n",
       "   'harshest': 1,\n",
       "   'BEST': 1,\n",
       "   'costliest': 1,\n",
       "   'Dirtiest': 1,\n",
       "   'rarest': 1,\n",
       "   'cheesiest': 1,\n",
       "   'vaguest': 1,\n",
       "   'warmest': 2,\n",
       "   'soundest': 1,\n",
       "   'weirdest': 1,\n",
       "   'Latest': 2,\n",
       "   'likeliest': 2,\n",
       "   'firmest': 1,\n",
       "   'thickest': 2,\n",
       "   'sexiest': 2,\n",
       "   'bluntest': 1,\n",
       "   'boldest': 1,\n",
       "   'Hottest': 2,\n",
       "   'grandest': 1,\n",
       "   'Least': 1,\n",
       "   'luckiest': 1,\n",
       "   'staunchest': 1,\n",
       "   'dearest': 1,\n",
       "   'narrowest': 1,\n",
       "   'Safest': 1,\n",
       "   'shortest': 1,\n",
       "   'strictest': 1,\n",
       "   'sincerest': 1,\n",
       "   'roughest': 1,\n",
       "   'savviest': 1}}}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 20 in total of dramatic final_words\n",
    "top_words = {}\n",
    "for i in [1,2,3,4]:\n",
    "    top_words[i] = {}\n",
    "    all_words_with_count_and_class = []\n",
    "    for category, words in final_words[i].items():\n",
    "        for word, count in words.items():\n",
    "            all_words_with_count_and_class.append((word, count, category))\n",
    "    \n",
    "    all_words_with_count_and_class = sorted(all_words_with_count_and_class, key=lambda x: x[1], reverse=True)\n",
    "    top_words[i] = all_words_with_count_and_class[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [('really', 1393, 'modal_adverbs.txt'),\n",
       "  ('most', 1190, 'superlative_forms.txt'),\n",
       "  ('reportedly', 1115, 'modal_adverbs.txt'),\n",
       "  ('well', 868, 'manner_adverbs.txt'),\n",
       "  ('best', 587, 'superlative_forms.txt'),\n",
       "  ('better', 475, 'comparative_forms.txt'),\n",
       "  ('sure', 471, 'modal_adverbs.txt'),\n",
       "  ('actually', 462, 'modal_adverbs.txt'),\n",
       "  ('number', 441, 'comparative_forms.txt'),\n",
       "  ('least', 437, 'superlative_forms.txt'),\n",
       "  ('hard', 432, 'manner_adverbs.txt'),\n",
       "  ('later', 417, 'comparative_forms.txt'),\n",
       "  ('completely', 383, 'manner_adverbs.txt'),\n",
       "  ('finally', 344, 'manner_adverbs.txt'),\n",
       "  ('probably', 329, 'modal_adverbs.txt'),\n",
       "  ('less', 304, 'comparative_forms.txt'),\n",
       "  ('simply', 281, 'manner_adverbs.txt'),\n",
       "  ('maybe', 266, 'modal_adverbs.txt'),\n",
       "  ('longer', 237, 'comparative_forms.txt'),\n",
       "  ('likely', 237, 'modal_adverbs.txt')],\n",
       " 2: [('most', 546, 'superlative_forms.txt'),\n",
       "  ('well', 392, 'manner_adverbs.txt'),\n",
       "  ('reportedly', 344, 'modal_adverbs.txt'),\n",
       "  ('really', 336, 'modal_adverbs.txt'),\n",
       "  ('actually', 298, 'modal_adverbs.txt'),\n",
       "  ('hard', 242, 'manner_adverbs.txt'),\n",
       "  ('later', 240, 'comparative_forms.txt'),\n",
       "  ('sure', 233, 'modal_adverbs.txt'),\n",
       "  ('better', 212, 'comparative_forms.txt'),\n",
       "  ('clearly', 199, 'modal_adverbs.txt'),\n",
       "  ('clearly', 199, 'manner_adverbs.txt'),\n",
       "  ('best', 186, 'superlative_forms.txt'),\n",
       "  ('number', 180, 'comparative_forms.txt'),\n",
       "  ('likely', 180, 'modal_adverbs.txt'),\n",
       "  ('Well', 174, 'manner_adverbs.txt'),\n",
       "  ('completely', 152, 'manner_adverbs.txt'),\n",
       "  ('simply', 146, 'manner_adverbs.txt'),\n",
       "  ('least', 146, 'superlative_forms.txt'),\n",
       "  ('finally', 145, 'manner_adverbs.txt'),\n",
       "  ('probably', 141, 'modal_adverbs.txt')],\n",
       " 3: [('most', 3590, 'superlative_forms.txt'),\n",
       "  ('well', 3259, 'manner_adverbs.txt'),\n",
       "  ('actually', 1734, 'modal_adverbs.txt'),\n",
       "  ('really', 1568, 'modal_adverbs.txt'),\n",
       "  ('number', 1531, 'comparative_forms.txt'),\n",
       "  ('least', 1312, 'superlative_forms.txt'),\n",
       "  ('better', 1175, 'comparative_forms.txt'),\n",
       "  ('less', 1124, 'comparative_forms.txt'),\n",
       "  ('likely', 1020, 'modal_adverbs.txt'),\n",
       "  ('further', 976, 'comparative_forms.txt'),\n",
       "  ('simply', 974, 'manner_adverbs.txt'),\n",
       "  ('best', 945, 'superlative_forms.txt'),\n",
       "  ('longer', 769, 'comparative_forms.txt'),\n",
       "  ('sure', 760, 'modal_adverbs.txt'),\n",
       "  ('hard', 741, 'manner_adverbs.txt'),\n",
       "  ('especially', 721, 'manner_adverbs.txt'),\n",
       "  ('Well', 647, 'manner_adverbs.txt'),\n",
       "  ('later', 642, 'comparative_forms.txt'),\n",
       "  ('worse', 637, 'comparative_forms.txt'),\n",
       "  ('higher', 628, 'comparative_forms.txt')],\n",
       " 4: [('most', 1554, 'superlative_forms.txt'),\n",
       "  ('well', 1214, 'manner_adverbs.txt'),\n",
       "  ('number', 774, 'comparative_forms.txt'),\n",
       "  ('best', 700, 'superlative_forms.txt'),\n",
       "  ('least', 687, 'superlative_forms.txt'),\n",
       "  ('less', 666, 'comparative_forms.txt'),\n",
       "  ('better', 616, 'comparative_forms.txt'),\n",
       "  ('later', 607, 'comparative_forms.txt'),\n",
       "  ('really', 551, 'modal_adverbs.txt'),\n",
       "  ('earlier', 504, 'comparative_forms.txt'),\n",
       "  ('likely', 441, 'modal_adverbs.txt'),\n",
       "  ('hard', 437, 'manner_adverbs.txt'),\n",
       "  ('largest', 412, 'superlative_forms.txt'),\n",
       "  ('further', 398, 'comparative_forms.txt'),\n",
       "  ('higher', 385, 'comparative_forms.txt'),\n",
       "  ('biggest', 322, 'superlative_forms.txt'),\n",
       "  ('lower', 321, 'comparative_forms.txt'),\n",
       "  ('especially', 300, 'manner_adverbs.txt'),\n",
       "  ('latest', 270, 'superlative_forms.txt'),\n",
       "  ('probably', 264, 'modal_adverbs.txt')]}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1381: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.49      0.53       750\n",
      "           2       0.56      0.20      0.29       750\n",
      "           3       0.43      0.65      0.52       750\n",
      "           4       0.54      0.70      0.61       750\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.53      0.51      0.49      3000\n",
      "weighted avg       0.53      0.51      0.49      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "custom_vocab_vectorizer = TfidfVectorizer(vocabulary=all_words.union(top_tokens))\n",
    "# fit and transform\n",
    "X_train = custom_vocab_vectorizer.fit_transform(x_train)\n",
    "y_train = train_df['Verdict']\n",
    "# we want to combine class 1,4 and  2,3 together\n",
    "# y_train = y_train.apply(lambda x: 0 if x in [1,4] else 1)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# test out\n",
    "X_test = custom_vocab_vectorizer.transform(test_df['Text'])\n",
    "y_test = test_df['Verdict']\n",
    "# y_test = y_test.apply(lambda x: 0 if x in [1,4] else 1)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Investigating Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE\n",
      "          count      mean       std  min  25%  50%   75%    max\n",
      "Verdict                                                        \n",
      "1        3981.0  3.933936  3.752909  0.0  1.0  3.0   5.0   42.0\n",
      "2        4014.0  1.570005  1.719404  0.0  0.0  1.0   2.0   21.0\n",
      "3        4008.0  7.257485  9.968259  0.0  1.0  4.0  10.0  146.0\n",
      "4        3997.0  7.950463  6.692521  0.0  3.0  6.0  11.0   74.0\n",
      "LANGUAGE\n",
      "          count      mean       std  min  25%  50%  75%   max\n",
      "Verdict                                                      \n",
      "1        3981.0  0.024868  0.198321  0.0  0.0  0.0  0.0   4.0\n",
      "2        4014.0  0.010463  0.186486  0.0  0.0  0.0  0.0   8.0\n",
      "3        4008.0  0.039920  0.288544  0.0  0.0  0.0  0.0   7.0\n",
      "4        3997.0  0.071554  0.453971  0.0  0.0  0.0  0.0  16.0\n",
      "GPE\n",
      "          count       mean        std  min  25%  50%   75%    max\n",
      "Verdict                                                          \n",
      "1        3981.0   2.059784   3.593537  0.0  0.0  1.0   2.0   69.0\n",
      "2        4014.0   2.196313   2.445382  0.0  1.0  2.0   3.0   55.0\n",
      "3        4008.0  11.105289  18.816423  0.0  1.0  4.0  14.0  277.0\n",
      "4        3997.0   8.575181   9.055947  0.0  2.0  6.0  12.0   85.0\n",
      "WORK_OF_ART\n",
      "          count      mean       std  min  25%  50%  75%   max\n",
      "Verdict                                                      \n",
      "1        3981.0  0.202210  0.639610  0.0  0.0  0.0  0.0  18.0\n",
      "2        4014.0  0.108122  0.373251  0.0  0.0  0.0  0.0   4.0\n",
      "3        4008.0  0.574601  1.086213  0.0  0.0  0.0  1.0  16.0\n",
      "4        3997.0  0.261696  1.025484  0.0  0.0  0.0  0.0  23.0\n",
      "NORP\n",
      "          count      mean        std  min  25%  50%  75%    max\n",
      "Verdict                                                        \n",
      "1        3981.0  1.037177   2.170988  0.0  0.0  0.0  1.0   22.0\n",
      "2        4014.0  1.557050   2.055572  0.0  0.0  1.0  2.0   31.0\n",
      "3        4008.0  5.164421  10.950197  0.0  0.0  1.0  5.0  288.0\n",
      "4        3997.0  3.155367   5.185993  0.0  0.0  1.0  4.0   70.0\n",
      "ORDINAL\n",
      "          count      mean       std  min  25%  50%  75%   max\n",
      "Verdict                                                      \n",
      "1        3981.0  0.541070  1.033185  0.0  0.0  0.0  1.0  14.0\n",
      "2        4014.0  0.292227  0.648988  0.0  0.0  0.0  0.0   6.0\n",
      "3        4008.0  1.158932  1.688476  0.0  0.0  1.0  2.0  19.0\n",
      "4        3997.0  1.022767  1.780843  0.0  0.0  0.0  1.0  23.0\n",
      "LOC\n",
      "          count      mean       std  min  25%  50%  75%   max\n",
      "Verdict                                                      \n",
      "1        3981.0  0.297664  0.890806  0.0  0.0  0.0  0.0  16.0\n",
      "2        4014.0  0.242152  0.580999  0.0  0.0  0.0  0.0   5.0\n",
      "3        4008.0  1.303892  2.836615  0.0  0.0  0.0  1.0  42.0\n",
      "4        3997.0  0.746310  1.536571  0.0  0.0  0.0  1.0  27.0\n",
      "CARDINAL\n",
      "          count      mean        std  min  25%  50%  75%    max\n",
      "Verdict                                                        \n",
      "1        3981.0  1.916604   2.520784  0.0  0.0  1.0  3.0   27.0\n",
      "2        4014.0  1.095167   1.504677  0.0  0.0  1.0  2.0   18.0\n",
      "3        4008.0  6.178144  10.217290  0.0  1.0  3.0  8.0  245.0\n",
      "4        3997.0  4.930698   5.759220  0.0  1.0  3.0  7.0  143.0\n",
      "FAC\n",
      "          count      mean       std  min  25%  50%  75%   max\n",
      "Verdict                                                      \n",
      "1        3981.0  0.242150  0.721627  0.0  0.0  0.0  0.0  22.0\n",
      "2        4014.0  0.150972  0.435330  0.0  0.0  0.0  0.0   4.0\n",
      "3        4008.0  0.343313  0.994068  0.0  0.0  0.0  0.0  24.0\n",
      "4        3997.0  0.389292  1.147991  0.0  0.0  0.0  0.0  25.0\n",
      "PERCENT\n",
      "          count      mean       std  min  25%  50%  75%   max\n",
      "Verdict                                                      \n",
      "1        3981.0  0.142427  0.552801  0.0  0.0  0.0  0.0   8.0\n",
      "2        4014.0  0.068261  0.384504  0.0  0.0  0.0  0.0   7.0\n",
      "3        4008.0  0.898703  2.732243  0.0  0.0  0.0  1.0  45.0\n",
      "4        3997.0  0.916187  2.414656  0.0  0.0  0.0  1.0  35.0\n",
      "LAW\n",
      "          count      mean       std  min  25%  50%  75%   max\n",
      "Verdict                                                      \n",
      "1        3981.0  0.039186  0.308134  0.0  0.0  0.0  0.0  10.0\n",
      "2        4014.0  0.089935  0.443277  0.0  0.0  0.0  0.0  10.0\n",
      "3        4008.0  0.504741  1.548799  0.0  0.0  0.0  0.0  27.0\n",
      "4        3997.0  0.071303  0.388356  0.0  0.0  0.0  0.0   8.0\n",
      "QUANTITY\n",
      "          count      mean       std  min  25%  50%  75%   max\n",
      "Verdict                                                      \n",
      "1        3981.0  0.217533  0.650013  0.0  0.0  0.0  0.0  10.0\n",
      "2        4014.0  0.036373  0.235568  0.0  0.0  0.0  0.0   4.0\n",
      "3        4008.0  0.279192  0.979779  0.0  0.0  0.0  0.0  24.0\n",
      "4        3997.0  0.471103  1.859687  0.0  0.0  0.0  0.0  70.0\n",
      "EVENT\n",
      "          count      mean       std  min  25%  50%  75%    max\n",
      "Verdict                                                       \n",
      "1        3981.0  0.173826  0.751165  0.0  0.0  0.0  0.0   15.0\n",
      "2        4014.0  0.067015  0.303223  0.0  0.0  0.0  0.0    4.0\n",
      "3        4008.0  0.373004  2.163481  0.0  0.0  0.0  0.0  123.0\n",
      "4        3997.0  0.298474  0.942400  0.0  0.0  0.0  0.0   12.0\n",
      "PERSON\n",
      "          count       mean        std  min  25%  50%   75%    max\n",
      "Verdict                                                          \n",
      "1        3981.0   6.938206   7.928652  0.0  2.0  4.0   8.0   68.0\n",
      "2        4014.0   5.000498   3.804793  0.0  2.0  4.0   7.0   35.0\n",
      "3        4008.0  10.505489  15.510640  0.0  2.0  6.0  13.0  316.0\n",
      "4        3997.0   8.933450  11.502908  0.0  2.0  5.0  12.0  217.0\n",
      "PRODUCT\n",
      "          count      mean       std  min  25%  50%  75%   max\n",
      "Verdict                                                      \n",
      "1        3981.0  0.201959  0.730805  0.0  0.0  0.0  0.0  16.0\n",
      "2        4014.0  0.117838  0.389644  0.0  0.0  0.0  0.0   5.0\n",
      "3        4008.0  0.442615  1.035531  0.0  0.0  0.0  1.0  12.0\n",
      "4        3997.0  0.238929  0.939728  0.0  0.0  0.0  0.0  29.0\n",
      "MONEY\n",
      "          count      mean       std  min  25%  50%  75%    max\n",
      "Verdict                                                       \n",
      "1        3981.0  0.256217  0.848685  0.0  0.0  0.0  0.0   13.0\n",
      "2        4014.0  0.174141  0.643020  0.0  0.0  0.0  0.0    8.0\n",
      "3        4008.0  1.158932  4.348775  0.0  0.0  0.0  1.0  128.0\n",
      "4        3997.0  1.025269  2.434448  0.0  0.0  0.0  1.0   34.0\n",
      "ORG\n",
      "          count       mean        std  min  25%   50%   75%    max\n",
      "Verdict                                                           \n",
      "1        3981.0   4.063552   5.101752  0.0  1.0   2.0   5.0   88.0\n",
      "2        4014.0   3.321873   2.938193  0.0  1.0   3.0   5.0   24.0\n",
      "3        4008.0  16.314122  21.102088  0.0  3.0  11.0  22.0  305.0\n",
      "4        3997.0   8.760821   8.797797  0.0  3.0   6.0  12.0  104.0\n",
      "TIME\n",
      "          count      mean       std  min  25%  50%  75%   max\n",
      "Verdict                                                      \n",
      "1        3981.0  0.774931  1.363591  0.0  0.0  0.0  1.0  14.0\n",
      "2        4014.0  0.172646  0.488430  0.0  0.0  0.0  0.0   4.0\n",
      "3        4008.0  0.496756  1.174553  0.0  0.0  0.0  1.0  20.0\n",
      "4        3997.0  0.678509  1.523907  0.0  0.0  0.0  1.0  20.0\n",
      "total_entities\n",
      "          count       mean        std  min   25%   50%   75%     max\n",
      "Verdict                                                             \n",
      "1        3981.0  23.063301  21.069197  0.0   9.0  14.0  33.0   182.0\n",
      "2        4014.0  16.271051   8.213436  0.0  11.0  15.0  21.0   109.0\n",
      "3        4008.0  64.099551  80.415929  0.0  15.0  44.0  85.0  1154.0\n",
      "4        3997.0  48.497373  36.871708  0.0  24.0  40.0  65.0   521.0\n",
      "[('DATE', 7.950462847135351), ('LANGUAGE', 0.07155366524893671), ('GPE', 11.105289421157684), ('WORK_OF_ART', 0.5746007984031936), ('NORP', 5.164421157684631), ('ORDINAL', 1.158932135728543), ('LOC', 1.3038922155688624), ('CARDINAL', 6.17814371257485), ('FAC', 0.38929196897673257), ('PERCENT', 0.9161871403552665), ('LAW', 0.5047405189620758), ('QUANTITY', 0.4711033274956217), ('EVENT', 0.37300399201596807), ('PERSON', 10.505489021956087), ('PRODUCT', 0.4426147704590818), ('MONEY', 1.158932135728543), ('ORG', 16.314121756487026), ('TIME', 0.7749309218789249), ('total_entities', 64.09955089820359)]\n",
      "[('total_entities', 64.09955089820359), ('ORG', 16.314121756487026), ('GPE', 11.105289421157684), ('PERSON', 10.505489021956087), ('DATE', 7.950462847135351), ('CARDINAL', 6.17814371257485), ('NORP', 5.164421157684631), ('LOC', 1.3038922155688624), ('ORDINAL', 1.158932135728543), ('MONEY', 1.158932135728543), ('PERCENT', 0.9161871403552665), ('TIME', 0.7749309218789249), ('WORK_OF_ART', 0.5746007984031936), ('LAW', 0.5047405189620758), ('QUANTITY', 0.4711033274956217), ('PRODUCT', 0.4426147704590818), ('FAC', 0.38929196897673257), ('EVENT', 0.37300399201596807), ('LANGUAGE', 0.07155366524893671)]\n"
     ]
    }
   ],
   "source": [
    "columns = ['DATE',\n",
    "       'LANGUAGE', 'GPE', 'WORK_OF_ART', 'NORP', 'ORDINAL', 'LOC', 'CARDINAL',\n",
    "       'FAC', 'PERCENT', 'LAW', 'QUANTITY', 'EVENT', 'PERSON', 'PRODUCT',\n",
    "       'MONEY', 'ORG', 'TIME', 'total_entities']\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "temp = []\n",
    "\n",
    "for column in columns:\n",
    "    print(column)\n",
    "    print(train_df.groupby('Verdict')[column].describe())\n",
    "    # store the highest mean among the classes\n",
    "    temp.append((column, train_df.groupby('Verdict')[column].mean().max()))\n",
    "\n",
    "print(temp)\n",
    "# sort\n",
    "temp = sorted(temp, key=lambda x: x[1], reverse=True)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_best = [('total_entities', 64.09955089820359), ('ORG', 16.314121756487026), ('GPE', 11.105289421157684), ('PERSON', 10.505489021956087), ('DATE', 7.950462847135351), ('CARDINAL', 6.17814371257485), ('NORP', 5.164421157684631), ('LOC', 1.3038922155688624), ('ORDINAL', 1.158932135728543), ('MONEY', 1.158932135728543), ('PERCENT', 0.9161871403552665), ('TIME', 0.7749309218789249), ('WORK_OF_ART', 0.5746007984031936), ('LAW', 0.5047405189620758), ('QUANTITY', 0.4711033274956217), ('PRODUCT', 0.4426147704590818), ('FAC', 0.38929196897673257), ('EVENT', 0.37300399201596807), ('LANGUAGE', 0.07155366524893671)]\n",
    "top_7_ner = [x[0] for x in ner_best[:7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propaganda and real news have the most number of entities. MONEY, ORG, PERSON, DATE being the highest ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['total_entities', 'ORG', 'GPE', 'PERSON', 'DATE', 'CARDINAL', 'NORP', 'LOC', 'ORDINAL', 'MONEY', 'PERCENT', 'TIME', 'WORK_OF_ART', 'LAW', 'QUANTITY', 'PRODUCT', 'FAC', 'EVENT', 'LANGUAGE']\n",
      "total_entities\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.15      0.19       750\n",
      "           2       0.23      0.39      0.29       750\n",
      "           3       0.26      0.25      0.26       750\n",
      "           4       0.25      0.18      0.21       750\n",
      "\n",
      "    accuracy                           0.24      3000\n",
      "   macro avg       0.25      0.24      0.24      3000\n",
      "weighted avg       0.25      0.24      0.24      3000\n",
      "\n",
      "ORG\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.05      0.08       750\n",
      "           2       0.25      0.50      0.33       750\n",
      "           3       0.38      0.42      0.40       750\n",
      "           4       0.24      0.16      0.19       750\n",
      "\n",
      "    accuracy                           0.28      3000\n",
      "   macro avg       0.27      0.28      0.25      3000\n",
      "weighted avg       0.27      0.28      0.25      3000\n",
      "\n",
      "GPE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       750\n",
      "           2       0.26      0.66      0.38       750\n",
      "           3       0.22      0.17      0.19       750\n",
      "           4       0.30      0.22      0.25       750\n",
      "\n",
      "    accuracy                           0.26      3000\n",
      "   macro avg       0.20      0.26      0.21      3000\n",
      "weighted avg       0.20      0.26      0.21      3000\n",
      "\n",
      "PERSON\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.08      0.14       750\n",
      "           2       0.22      0.48      0.30       750\n",
      "           3       0.19      0.26      0.22       750\n",
      "           4       0.27      0.06      0.10       750\n",
      "\n",
      "    accuracy                           0.22      3000\n",
      "   macro avg       0.26      0.22      0.19      3000\n",
      "weighted avg       0.26      0.22      0.19      3000\n",
      "\n",
      "DATE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      0.15      0.18       750\n",
      "           2       0.30      0.62      0.41       750\n",
      "           3       0.32      0.12      0.17       750\n",
      "           4       0.59      0.53      0.56       750\n",
      "\n",
      "    accuracy                           0.35      3000\n",
      "   macro avg       0.36      0.35      0.33      3000\n",
      "weighted avg       0.36      0.35      0.33      3000\n",
      "\n",
      "CARDINAL\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.19      0.09      0.12       750\n",
      "           2       0.30      0.61      0.40       750\n",
      "           3       0.37      0.43      0.40       750\n",
      "           4       0.26      0.08      0.13       750\n",
      "\n",
      "    accuracy                           0.30      3000\n",
      "   macro avg       0.28      0.30      0.26      3000\n",
      "weighted avg       0.28      0.30      0.26      3000\n",
      "\n",
      "NORP\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.63      0.41       750\n",
      "           2       0.21      0.12      0.15       750\n",
      "           3       0.18      0.19      0.18       750\n",
      "           4       0.17      0.06      0.08       750\n",
      "\n",
      "    accuracy                           0.25      3000\n",
      "   macro avg       0.22      0.25      0.21      3000\n",
      "weighted avg       0.22      0.25      0.21      3000\n",
      "\n",
      "LOC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       750\n",
      "           2       0.23      0.67      0.35       750\n",
      "           3       0.26      0.30      0.28       750\n",
      "           4       0.00      0.00      0.00       750\n",
      "\n",
      "    accuracy                           0.24      3000\n",
      "   macro avg       0.12      0.24      0.16      3000\n",
      "weighted avg       0.12      0.24      0.16      3000\n",
      "\n",
      "ORDINAL\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       750\n",
      "           2       0.26      0.66      0.37       750\n",
      "           3       0.28      0.41      0.33       750\n",
      "           4       0.00      0.00      0.00       750\n",
      "\n",
      "    accuracy                           0.27      3000\n",
      "   macro avg       0.13      0.27      0.18      3000\n",
      "weighted avg       0.13      0.27      0.18      3000\n",
      "\n",
      "MONEY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       750\n",
      "           2       0.27      0.85      0.41       750\n",
      "           3       0.27      0.24      0.25       750\n",
      "           4       0.00      0.00      0.00       750\n",
      "\n",
      "    accuracy                           0.27      3000\n",
      "   macro avg       0.13      0.27      0.17      3000\n",
      "weighted avg       0.13      0.27      0.17      3000\n",
      "\n",
      "PERCENT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       750\n",
      "           2       0.28      0.90      0.43       750\n",
      "           3       0.50      0.17      0.25       750\n",
      "           4       0.41      0.20      0.27       750\n",
      "\n",
      "    accuracy                           0.32      3000\n",
      "   macro avg       0.30      0.32      0.24      3000\n",
      "weighted avg       0.30      0.32      0.24      3000\n",
      "\n",
      "TIME\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.36      0.33       750\n",
      "           2       0.27      0.76      0.40       750\n",
      "           3       0.00      0.00      0.00       750\n",
      "           4       0.00      0.00      0.00       750\n",
      "\n",
      "    accuracy                           0.28      3000\n",
      "   macro avg       0.14      0.28      0.18      3000\n",
      "weighted avg       0.14      0.28      0.18      3000\n",
      "\n",
      "WORK_OF_ART\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       750\n",
      "           2       0.25      0.83      0.38       750\n",
      "           3       0.39      0.27      0.32       750\n",
      "           4       0.00      0.00      0.00       750\n",
      "\n",
      "    accuracy                           0.27      3000\n",
      "   macro avg       0.16      0.27      0.18      3000\n",
      "weighted avg       0.16      0.27      0.18      3000\n",
      "\n",
      "LAW\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.96      0.42       750\n",
      "           2       0.00      0.00      0.00       750\n",
      "           3       0.25      0.10      0.15       750\n",
      "           4       0.00      0.00      0.00       750\n",
      "\n",
      "    accuracy                           0.27      3000\n",
      "   macro avg       0.13      0.27      0.14      3000\n",
      "weighted avg       0.13      0.27      0.14      3000\n",
      "\n",
      "QUANTITY\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       750\n",
      "           2       0.27      0.93      0.42       750\n",
      "           3       0.00      0.00      0.00       750\n",
      "           4       0.37      0.20      0.26       750\n",
      "\n",
      "    accuracy                           0.28      3000\n",
      "   macro avg       0.16      0.28      0.17      3000\n",
      "weighted avg       0.16      0.28      0.17      3000\n",
      "\n",
      "PRODUCT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       750\n",
      "           2       0.23      0.74      0.35       750\n",
      "           3       0.26      0.19      0.22       750\n",
      "           4       0.00      0.00      0.00       750\n",
      "\n",
      "    accuracy                           0.23      3000\n",
      "   macro avg       0.12      0.23      0.14      3000\n",
      "weighted avg       0.12      0.23      0.14      3000\n",
      "\n",
      "FAC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       750\n",
      "           2       0.25      0.81      0.38       750\n",
      "           3       0.00      0.00      0.00       750\n",
      "           4       0.35      0.25      0.29       750\n",
      "\n",
      "    accuracy                           0.26      3000\n",
      "   macro avg       0.15      0.26      0.17      3000\n",
      "weighted avg       0.15      0.26      0.17      3000\n",
      "\n",
      "EVENT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       750\n",
      "           2       0.25      0.88      0.39       750\n",
      "           3       0.18      0.09      0.12       750\n",
      "           4       0.00      0.00      0.00       750\n",
      "\n",
      "    accuracy                           0.24      3000\n",
      "   macro avg       0.11      0.24      0.13      3000\n",
      "weighted avg       0.11      0.24      0.13      3000\n",
      "\n",
      "LANGUAGE\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       750\n",
      "           2       0.25      0.97      0.40       750\n",
      "           3       0.00      0.00      0.00       750\n",
      "           4       0.36      0.03      0.06       750\n",
      "\n",
      "    accuracy                           0.25      3000\n",
      "   macro avg       0.15      0.25      0.11      3000\n",
      "weighted avg       0.15      0.25      0.11      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "sorted_columns_to_test = [x[0] for x in temp]\n",
    "print(sorted_columns_to_test)\n",
    "\n",
    "for column in sorted_columns_to_test:\n",
    "    print(column)\n",
    "    train_and_test(train_df, test_df, [column], [1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.37      0.41       750\n",
      "           2       0.33      0.47      0.39       750\n",
      "           3       0.47      0.44      0.45       750\n",
      "           4       0.60      0.49      0.54       750\n",
      "\n",
      "    accuracy                           0.44      3000\n",
      "   macro avg       0.46      0.44      0.45      3000\n",
      "weighted avg       0.46      0.44      0.45      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_test(train_df, test_df, sorted_columns_to_test, [1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see clearly it best classifies class 4 and class 3, which is the real news class as it has the most named entity, and also hoax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it altogether, we have \n",
    "1. length related features are good at classifying 3,4\n",
    "2. Sentiment analysis is good at classifying 1,2 which is hoax and satire\n",
    "3. Readability score is good at classifying 2,3 from the rest\n",
    "4. Named Entity Recognition is good at classifying class 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.48      0.49       750\n",
      "           2       0.42      0.47      0.44       750\n",
      "           3       0.60      0.66      0.63       750\n",
      "           4       0.68      0.55      0.61       750\n",
      "\n",
      "    accuracy                           0.54      3000\n",
      "   macro avg       0.55      0.54      0.54      3000\n",
      "weighted avg       0.55      0.54      0.54      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "all_columns = ['sentiment_compound_score',\n",
    "       'number_of_words', 'number_of_characters', 'number_of_sentence',\n",
    "        'DATE',\n",
    "       'LANGUAGE', 'GPE', 'WORK_OF_ART', 'NORP', 'ORDINAL', 'LOC', 'CARDINAL',\n",
    "       'FAC', 'PERCENT', 'LAW', 'QUANTITY', 'EVENT', 'PERSON', 'PRODUCT',\n",
    "       'MONEY', 'ORG', 'TIME', 'total_entities', 'readability']\n",
    "train_and_test(train_df, test_df, all_columns, [1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "columns = all_columns\n",
    "features_train = get_feature_from_df(train_df, columns)\n",
    "features_train = list(map(list, zip(*features_train)))\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "features_train = scaler.fit_transform(features_train)\n",
    "\n",
    "X_train = features_train\n",
    "y_train = train_df['Verdict']\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "features_test = get_feature_from_df(test_df, columns)\n",
    "features_test = list(map(list, zip(*features_test)))\n",
    "\n",
    "features_test = scaler.transform(features_test)\n",
    "X_test = features_test\n",
    "y_test = test_df['Verdict']\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.48      0.49       750\n",
      "           2       0.42      0.47      0.44       750\n",
      "           3       0.60      0.66      0.63       750\n",
      "           4       0.68      0.55      0.61       750\n",
      "\n",
      "    accuracy                           0.54      3000\n",
      "   macro avg       0.55      0.54      0.54      3000\n",
      "weighted avg       0.55      0.54      0.54      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 (Satire) misclassified: 391\n",
      "Mispredicted as class 2 (Hoax): 350\n",
      "Mispredicted as class 3 (Propaganda): 6\n",
      "Mispredicted as class 4 (Reliable News): 35\n",
      "\n",
      "Class 2 (Hoax) misclassified: 395\n",
      "Mispredicted as class 1 (Satire): 123\n",
      "Mispredicted as class 3 (Propaganda): 194\n",
      "Mispredicted as class 4 (Reliable News): 78\n",
      "\n",
      "Class 3 (Propaganda) misclassified: 256\n",
      "Mispredicted as class 1 (Satire): 140\n",
      "Mispredicted as class 2 (Hoax): 36\n",
      "Mispredicted as class 4 (Reliable News): 80\n",
      "\n",
      "Class 4 (Reliable News) misclassified: 340\n",
      "Mispredicted as class 1 (Satire): 99\n",
      "Mispredicted as class 2 (Hoax): 107\n",
      "Mispredicted as class 3 (Propaganda): 134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = {1: 'Satire', 2: 'Hoax', 3: 'Propaganda', 4: 'Reliable News'}\n",
    "test_df[\"predicted\"] = y_pred\n",
    "misclassified = test_df[test_df[\"Verdict\"] != y_pred]\n",
    "\n",
    "for i in range(1,5):\n",
    "    misclassified_i =  misclassified[misclassified['Verdict'] == i]\n",
    "    print(f'Class {i} ({labels[i]}) misclassified: {len(misclassified_i)}')\n",
    "    for j in range(1,5):\n",
    "        if i == j:\n",
    "            continue\n",
    "        print(f'Mispredicted as class {j} ({labels[j]}): {len(misclassified_i[misclassified_i[\"predicted\"] == j])}')\n",
    "    \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate hyperlinks\n",
    "train_df[\"hyperlink_counts\"] = train_df[\"Text\"].apply(lambda x: x.count(\"http\"))\n",
    "train_df[\"capitalization_counts\"] = train_df[\"Text\"].apply(lambda x: sum(1 for c in x if c.isupper()))\n",
    "train_df[\"capitalization_ratio\"] = train_df[\"capitalization_counts\"] / train_df[\"number_of_words\"]\n",
    "train_df[\"hyperlink_ratio\"] = train_df[\"hyperlink_counts\"] / train_df[\"number_of_words\"]\n",
    "\n",
    "\n",
    "test_df[\"hyperlink_counts\"] = test_df[\"Text\"].apply(lambda x: x.count(\"http\"))\n",
    "test_df[\"capitalization_counts\"] = test_df[\"Text\"].apply(lambda x: sum(1 for c in x if c.isupper()))\n",
    "test_df[\"capitalization_ratio\"] = test_df[\"capitalization_counts\"] / test_df[\"number_of_words\"]\n",
    "test_df[\"hyperlink_ratio\"] = test_df[\"hyperlink_counts\"] / test_df[\"number_of_words\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Hyperlinks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperlink_counts\n",
      "          count      mean       std  min  25%  50%  75%   max\n",
      "Verdict                                                      \n",
      "1        3981.0  0.001507  0.050103  0.0  0.0  0.0  0.0   2.0\n",
      "2        4014.0  0.005730  0.100916  0.0  0.0  0.0  0.0   4.0\n",
      "3        4008.0  0.257984  1.128973  0.0  0.0  0.0  0.0  22.0\n",
      "4        3997.0  0.006255  0.145713  0.0  0.0  0.0  0.0   8.0\n",
      "hyperlink_ratio\n",
      "          count      mean       std  min  25%  50%  75%       max\n",
      "Verdict                                                          \n",
      "1        3981.0  0.000004  0.000149  0.0  0.0  0.0  0.0  0.007874\n",
      "2        4014.0  0.000056  0.001623  0.0  0.0  0.0  0.0  0.085106\n",
      "3        4008.0  0.000408  0.003901  0.0  0.0  0.0  0.0  0.157895\n",
      "4        3997.0  0.000019  0.000583  0.0  0.0  0.0  0.0  0.034483\n"
     ]
    }
   ],
   "source": [
    "columns =  ['hyperlink_counts', 'hyperlink_ratio']\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "for column in columns:\n",
    "    print(column)\n",
    "    print(train_df.groupby('Verdict')[column].describe())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can very clearly see that, number of words, and number of characters and number of sentence has is quite distinct for class 3(propaganda) and 4(reliable news) in comparison to the rest. So ideally, if we use these features, we should be able to perform better for than random guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       750\n",
      "           2       0.26      0.88      0.40       750\n",
      "           3       0.77      0.48      0.59       750\n",
      "           4       0.00      0.00      0.00       750\n",
      "\n",
      "    accuracy                           0.34      3000\n",
      "   macro avg       0.26      0.34      0.25      3000\n",
      "weighted avg       0.26      0.34      0.25      3000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       750\n",
      "           2       0.26      0.88      0.40       750\n",
      "           3       0.77      0.48      0.59       750\n",
      "           4       0.00      0.00      0.00       750\n",
      "\n",
      "    accuracy                           0.34      3000\n",
      "   macro avg       0.26      0.34      0.25      3000\n",
      "weighted avg       0.26      0.34      0.25      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "train_and_test(train_df, test_df, ['hyperlink_counts'], [1,2,3,4])\n",
    "train_and_test(train_df, test_df, ['hyperlink_ratio'], [1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is good in differentiating class 2 and class 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Capitalization Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capitalization_counts\n",
      "          count        mean         std  min   25%    50%    75%     max\n",
      "Verdict                                                                 \n",
      "1        3981.0   46.287867   45.167956  1.0  17.0   26.0   66.0   694.0\n",
      "2        4014.0   48.484056   17.572210  0.0  37.0   47.0   57.0   347.0\n",
      "3        4008.0  183.439122  246.440156  2.0  50.0  129.0  235.0  5128.0\n",
      "4        3997.0   85.460345   73.631762  0.0  38.0   67.0  113.0   821.0\n",
      "capitalization_ratio\n",
      "          count      mean       std       min       25%       50%       75%       max\n",
      "Verdict                                                                              \n",
      "1        3981.0  0.169902  0.109548  0.026316  0.111111  0.151515  0.200286  2.360000\n",
      "2        4014.0  0.268093  0.111387  0.000000  0.210898  0.251121  0.300669  2.250000\n",
      "3        4008.0  0.367140  0.385089  0.060943  0.164618  0.216317  0.310018  6.000000\n",
      "4        3997.0  0.217261  0.115778  0.000000  0.152807  0.191892  0.244992  1.553571\n"
     ]
    }
   ],
   "source": [
    "columns = ['capitalization_counts', 'capitalization_ratio']\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "for column in columns:\n",
    "    print(column)\n",
    "    print(train_df.groupby('Verdict')[column].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.07      0.12       750\n",
      "           2       0.20      0.39      0.27       750\n",
      "           3       0.33      0.35      0.34       750\n",
      "           4       0.26      0.20      0.22       750\n",
      "\n",
      "    accuracy                           0.25      3000\n",
      "   macro avg       0.30      0.25      0.24      3000\n",
      "weighted avg       0.30      0.25      0.24      3000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.66      0.36       750\n",
      "           2       0.36      0.17      0.23       750\n",
      "           3       0.05      0.01      0.02       750\n",
      "           4       0.26      0.15      0.19       750\n",
      "\n",
      "    accuracy                           0.25      3000\n",
      "   macro avg       0.23      0.25      0.20      3000\n",
      "weighted avg       0.23      0.25      0.20      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_test(train_df, test_df, ['capitalization_counts'], [1,2,3,4])\n",
    "train_and_test(train_df, test_df, ['capitalization_ratio'], [1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too useful - worst than random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.8 Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = {'anger': 0,\n",
    " 'anticipation': 0,\n",
    " 'disgust': 0,\n",
    " 'fear': 0,\n",
    " 'joy': 0,\n",
    " 'negative': 0,\n",
    " 'positive': 0,\n",
    " 'sadness': 0,\n",
    " 'surprise': 0,\n",
    " 'trust': 0}\n",
    "\n",
    "emotion_columns = list(emotion.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger\n",
      "          count       mean        std  min  25%  50%    75%    max\n",
      "Verdict                                                           \n",
      "1        3981.0   3.040191   3.790612  0.0  0.0  2.0   4.00   32.0\n",
      "2        4014.0   2.773543   2.521433  0.0  1.0  2.0   4.00   28.0\n",
      "3        4008.0  12.544910  18.276486  0.0  1.0  7.0  16.25  284.0\n",
      "4        3997.0   4.478109   5.451427  0.0  1.0  3.0   6.00   53.0\n",
      "anticipation\n",
      "          count       mean        std  min  25%   50%   75%    max\n",
      "Verdict                                                           \n",
      "1        3981.0   5.433811   5.367261  0.0  2.0   3.0   8.0   38.0\n",
      "2        4014.0   3.040857   2.438544  0.0  1.0   3.0   4.0   30.0\n",
      "3        4008.0  14.306138  18.028423  0.0  3.0  10.0  20.0  290.0\n",
      "4        3997.0   7.628972   7.015655  0.0  2.0   6.0  11.0   64.0\n",
      "disgust\n",
      "          count      mean        std  min  25%  50%  75%    max\n",
      "Verdict                                                        \n",
      "1        3981.0  2.087415   2.801901  0.0  0.0  1.0  3.0   28.0\n",
      "2        4014.0  1.369208   1.541908  0.0  0.0  1.0  2.0   17.0\n",
      "3        4008.0  6.918912  10.975921  0.0  1.0  4.0  9.0  210.0\n",
      "4        3997.0  2.131349   3.001086  0.0  0.0  1.0  3.0   32.0\n",
      "fear\n",
      "          count       mean        std  min  25%   50%   75%    max\n",
      "Verdict                                                           \n",
      "1        3981.0   3.985431   4.867056  0.0  1.0   2.0   5.0   36.0\n",
      "2        4014.0   3.417289   3.173449  0.0  1.0   3.0   5.0   38.0\n",
      "3        4008.0  19.019960  25.574889  0.0  3.0  12.0  25.0  317.0\n",
      "4        3997.0   6.696022   7.721920  0.0  1.0   5.0   9.0   90.0\n",
      "joy\n",
      "          count      mean        std  min  25%  50%   75%    max\n",
      "Verdict                                                         \n",
      "1        3981.0  4.116805   4.473897  0.0  1.0  3.0   6.0   33.0\n",
      "2        4014.0  2.053313   2.249157  0.0  1.0  1.0   3.0   32.0\n",
      "3        4008.0  9.496257  13.083632  0.0  1.0  6.0  13.0  204.0\n",
      "4        3997.0  4.872905   5.264558  0.0  1.0  3.0   7.0   43.0\n",
      "sadness\n",
      "          count       mean        std  min  25%  50%   75%    max\n",
      "Verdict                                                          \n",
      "1        3981.0   3.282844   3.892123  0.0  1.0  2.0   5.0   28.0\n",
      "2        4014.0   2.292725   2.150403  0.0  1.0  2.0   3.0   18.0\n",
      "3        4008.0  10.709830  15.054145  0.0  1.0  6.0  14.0  226.0\n",
      "4        3997.0   4.622967   5.239719  0.0  1.0  3.0   6.0   48.0\n",
      "surprise\n",
      "          count      mean       std  min  25%  50%  75%    max\n",
      "Verdict                                                       \n",
      "1        3981.0  2.495604  2.874475  0.0  0.0  2.0  4.0   27.0\n",
      "2        4014.0  1.386896  1.482362  0.0  0.0  1.0  2.0   17.0\n",
      "3        4008.0  6.289172  8.755587  0.0  1.0  4.0  8.0  128.0\n",
      "4        3997.0  3.077808  3.437734  0.0  1.0  2.0  4.0   30.0\n",
      "trust\n",
      "          count       mean        std  min  25%   50%   75%    max\n",
      "Verdict                                                           \n",
      "1        3981.0   7.190907   6.785680  0.0  2.0   5.0  10.0   53.0\n",
      "2        4014.0   4.357748   3.291558  0.0  2.0   4.0   6.0   41.0\n",
      "3        4008.0  22.689870  28.392431  0.0  5.0  16.0  31.0  432.0\n",
      "4        3997.0  11.068802   9.552632  0.0  4.0   9.0  16.0   72.0\n"
     ]
    }
   ],
   "source": [
    "columns = emotion_columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "for column in columns:\n",
    "    print(column)\n",
    "    print(train_df.groupby('Verdict')[column].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.16      0.20       750\n",
      "           2       0.24      0.47      0.32       750\n",
      "           3       0.26      0.23      0.25       750\n",
      "           4       0.25      0.14      0.18       750\n",
      "\n",
      "    accuracy                           0.25      3000\n",
      "   macro avg       0.26      0.25      0.24      3000\n",
      "weighted avg       0.26      0.25      0.24      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_test(train_df, test_df, emotion_columns, [1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining TF-IDF with our custom feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Assuming df[\"Notes\"] contains your textual data\n",
    "# and df[\"Class\"] contains your target variable with four classes\n",
    "df = pd.read_csv('./raw_data/xtrain.csv', names=['Verdict', \"Text\"])\n",
    "\n",
    "pickle1 = pd.read_pickle(\"./pickles/sentiment_ner_length_readability_related_readability.pkl\")\n",
    "pickle2 = pd.read_pickle(\"./pickles/sentiment_ner_length_related_test.pkl\")\n",
    "\n",
    "# # remove samples that has more less than 10 words or more than 10000 words\n",
    "# pickle1[\"Text\"] = pickle1[\"Text\"].apply(lambda x: x if len(x.split()) > 10 and len(x.split()) < 10000 else None)\n",
    "# pickle1 = pickle1.dropna()\n",
    "# df[\"Text\"] = df[\"Text\"].apply(lambda x: x if len(x.split()) > 10 and len(x.split()) < 10000 else None)\n",
    "# df = df.dropna()\n",
    "\n",
    "# Investigate hyperlinks\n",
    "# pickle1[\"hyperlink_counts\"] = pickle1[\"Text\"].apply(lambda x: x.count(\"http\"))\n",
    "# pickle1[\"capitalization_counts\"] = pickle1[\"Text\"].apply(lambda x: sum(1 for c in x if c.isupper()))\n",
    "# pickle1[\"capitalization_ratio\"] = pickle1[\"capitalization_counts\"] / pickle1[\"number_of_words\"]\n",
    "# pickle1[\"hyperlink_ratio\"] = pickle1[\"hyperlink_counts\"] / pickle1[\"number_of_words\"]\n",
    "\n",
    "\n",
    "# pickle2[\"hyperlink_counts\"] = pickle2[\"Text\"].apply(lambda x: x.count(\"http\"))\n",
    "# pickle2[\"capitalization_counts\"] = pickle2[\"Text\"].apply(lambda x: sum(1 for c in x if c.isupper()))\n",
    "# pickle2[\"capitalization_ratio\"] = pickle2[\"capitalization_counts\"] / pickle2[\"number_of_words\"]\n",
    "# pickle2[\"hyperlink_ratio\"] = pickle2[\"hyperlink_counts\"] / pickle2[\"number_of_words\"]\n",
    "\n",
    "\n",
    "\n",
    "def get_feature_from_df(df):\n",
    "    columns = ['sentiment_compound_score',\n",
    "       'number_of_words', 'number_of_characters', 'number_of_sentence',\n",
    "        'DATE', \n",
    "       'LANGUAGE', 'GPE', 'WORK_OF_ART', 'NORP', 'ORDINAL', 'LOC', 'CARDINAL',\n",
    "       'FAC', 'PERCENT', 'LAW', 'QUANTITY', 'EVENT', 'PERSON', 'PRODUCT',\n",
    "       'MONEY', 'ORG', 'TIME', 'total_entities', 'readability']\n",
    "\n",
    "    features = []\n",
    "    for col in columns:\n",
    "        features.append(list(df[col]))\n",
    "    # features.append(list(number_of_capitalized))\n",
    "    return features\n",
    "df = df.loc[:,~df.columns.duplicated()].copy()\n",
    "features_train = get_feature_from_df(pickle1)\n",
    "\n",
    "# we need to reshape it to become (n_samples, n_features)\n",
    "features_train = list(map(list, zip(*features_train)))\n",
    "scaler = MinMaxScaler()\n",
    "features_train = scaler.fit_transform(features_train)\n",
    "\n",
    "# Step 1: Convert texts to TF-IDF features\n",
    "vectorizer = TfidfVectorizer(stop_words='english', lowercase=True)\n",
    "tfidf_train = vectorizer.fit_transform(df[\"Text\"])\n",
    "\n",
    "# Combine the text features with the extracted features\n",
    "from scipy.sparse import hstack\n",
    "X = hstack([tfidf_train, features_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_train start from 113852 to 113876\n"
     ]
    }
   ],
   "source": [
    "print(\"features_train start from \" + str(tfidf_train.shape[1]) + \" to \" + str(X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Apply Chi-squared test\n",
    "chi2score = chi2(X, df['Verdict'])\n",
    "\n",
    "# Step 3: Select the top 60k features\n",
    "chi2_selector = SelectKBest(chi2, k=60000)\n",
    "X_kbest_features = chi2_selector.fit_transform(X, df['Verdict'])\n",
    "# X_kbest_features = X\n",
    "\n",
    "# get the selected feature names\n",
    "\n",
    "feature_names = chi2_selector.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf: x113852\n",
      "tfidf: x113853\n",
      "tfidf: x113854\n",
      "tfidf: x113855\n",
      "tfidf: x113856\n",
      "tfidf: x113857\n",
      "tfidf: x113858\n",
      "tfidf: x113859\n",
      "tfidf: x113860\n",
      "tfidf: x113861\n",
      "tfidf: x113862\n",
      "tfidf: x113863\n",
      "tfidf: x113864\n",
      "tfidf: x113865\n",
      "tfidf: x113866\n",
      "tfidf: x113867\n",
      "tfidf: x113868\n",
      "tfidf: x113869\n",
      "tfidf: x113870\n",
      "tfidf: x113871\n",
      "tfidf: x113872\n",
      "tfidf: x113873\n",
      "tfidf: x113874\n",
      "tfidf: x113875\n"
     ]
    }
   ],
   "source": [
    "feature_cols = ['sentiment_compound_score',\n",
    "       'number_of_words', 'number_of_characters', 'number_of_sentence',\n",
    "        'DATE', \n",
    "       'LANGUAGE', 'GPE', 'WORK_OF_ART', 'NORP', 'ORDINAL', 'LOC', 'CARDINAL',\n",
    "       'FAC', 'PERCENT', 'LAW', 'QUANTITY', 'EVENT', 'PERSON', 'PRODUCT',\n",
    "       'MONEY', 'ORG', 'TIME', 'total_entities', 'readability']\n",
    "# see the selected features\n",
    "for i in range(len(feature_names)):\n",
    "    name = feature_names[i]\n",
    "    number = name.split('x')[1]\n",
    "    if int(number) in range(tfidf_train.shape[1], X.shape[1]):\n",
    "        print(\"tfidf: \" + str(feature_names[i]))\n",
    "\n",
    "        # index = int(str(feature_names[i]).split('x')[1]) - tfidf_train.shape[1]\n",
    "        # print(feature_cols[index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/cs4248/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.72      0.77       750\n",
      "           2       0.74      0.70      0.72       750\n",
      "           3       0.75      0.83      0.79       750\n",
      "           4       0.83      0.89      0.86       750\n",
      "\n",
      "    accuracy                           0.79      3000\n",
      "   macro avg       0.79      0.79      0.78      3000\n",
      "weighted avg       0.79      0.79      0.78      3000\n",
      "\n",
      "0.7843630006585706\n"
     ]
    }
   ],
   "source": [
    "class_weights = {1: 2,  # Class 0\n",
    "                 2: 4,  # Class 1\n",
    "                 3: 2, # Class 2 (Assuming this is the underrepresented class)\n",
    "                 4: 2}  # Class 3\n",
    "model = LogisticRegression(class_weight=class_weights)\n",
    "model.fit(X_kbest_features, df['Verdict'])\n",
    "# Now you can use this model to predict the class of new texts\n",
    "\n",
    "# Assuming df_test[\"Notes\"] contains the new textual data\n",
    "df_test = pd.read_csv('./raw_data/balancedtest.csv', names=['Verdict', \"Text\"])\n",
    "\n",
    "# Step 1: Convert texts to TF-IDF features\n",
    "X_test = vectorizer.transform(df_test[\"Text\"])\n",
    "features_test = get_feature_from_df(pickle2)\n",
    "\n",
    "# we need to reshape it to become (n_samples, n_features)\n",
    "features_test = list(map(list, zip(*features_test)))\n",
    "features_test = scaler.transform(features_test)\n",
    "\n",
    "X_test = hstack([X_test, features_test])\n",
    "\n",
    "# Get the top 1000 features as above\n",
    "X_test_kbest_features = chi2_selector.transform(X_test)\n",
    "# X_test_kbest_features = X_test\n",
    "\n",
    "# Step 4: Predict the class of the new texts\n",
    "predicted_classes = model.predict(X_test_kbest_features)\n",
    "\n",
    "# Assuming df_test[\"Class\"] contains the true class of the new texts\n",
    "print(classification_report(df_test[\"Verdict\"], predicted_classes))\n",
    "print(f1_score(df_test[\"Verdict\"], predicted_classes, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verdict</th>\n",
       "      <th>Text</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>When so many actors seem content to churn out ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>In what football insiders are calling an unex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>In a freak accident following Game 3 of the N....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>North Koreas official news agency announced to...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The former Alaska Governor Sarah Palin would b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>4</td>\n",
       "      <td>The Air Force mistakenly gave rival companies ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>4</td>\n",
       "      <td>The United Nations climate chief on Friday cha...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>4</td>\n",
       "      <td>River Plate midfielder Diego Buonanotte has un...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>4</td>\n",
       "      <td>Lawmakers were on the brink Tuesday of exempti...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>4</td>\n",
       "      <td>The Pentagon, which is processing bids on a ne...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Verdict                                               Text  predicted\n",
       "0           1  When so many actors seem content to churn out ...          1\n",
       "1           1   In what football insiders are calling an unex...          1\n",
       "2           1  In a freak accident following Game 3 of the N....          1\n",
       "3           1  North Koreas official news agency announced to...          4\n",
       "4           1  The former Alaska Governor Sarah Palin would b...          1\n",
       "...       ...                                                ...        ...\n",
       "2995        4  The Air Force mistakenly gave rival companies ...          4\n",
       "2996        4  The United Nations climate chief on Friday cha...          4\n",
       "2997        4  River Plate midfielder Diego Buonanotte has un...          4\n",
       "2998        4  Lawmakers were on the brink Tuesday of exempti...          4\n",
       "2999        4  The Pentagon, which is processing bids on a ne...          4\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 (Satire) misclassified: 211\n",
      "Mispredicted as class 2 (Hoax): 154\n",
      "Mispredicted as class 3 (Propaganda): 30\n",
      "Mispredicted as class 4 (Reliable News): 27\n",
      "\n",
      "Class 2 (Hoax) misclassified: 222\n",
      "Mispredicted as class 1 (Satire): 38\n",
      "Mispredicted as class 3 (Propaganda): 153\n",
      "Mispredicted as class 4 (Reliable News): 31\n",
      "\n",
      "Class 3 (Propaganda) misclassified: 129\n",
      "Mispredicted as class 1 (Satire): 34\n",
      "Mispredicted as class 2 (Hoax): 16\n",
      "Mispredicted as class 4 (Reliable News): 79\n",
      "\n",
      "Class 4 (Reliable News) misclassified: 81\n",
      "Mispredicted as class 1 (Satire): 36\n",
      "Mispredicted as class 2 (Hoax): 17\n",
      "Mispredicted as class 3 (Propaganda): 28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = {1: 'Satire', 2: 'Hoax', 3: 'Propaganda', 4: 'Reliable News'}\n",
    "df_test[\"predicted\"] = predicted_classes\n",
    "misclassified = df_test[df_test[\"Verdict\"] != df_test[\"predicted\"]]\n",
    "for i in range(1,5):\n",
    "    misclassified_i =  misclassified[misclassified['Verdict'] == i]\n",
    "    print(f'Class {i} ({labels[i]}) misclassified: {len(misclassified_i)}')\n",
    "    for j in range(1,5):\n",
    "        if i == j:\n",
    "            continue\n",
    "        print(f'Mispredicted as class {j} ({labels[j]}): {len(misclassified_i[misclassified_i[\"predicted\"] == j])}')\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4248",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
